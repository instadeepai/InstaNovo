name: CI Pipeline

# Consolidated triggers for all jobs
on:
  # For main CI/CD on main branches
  push:
    branches:
      - main
      - test_ci
  # For validation on pull requests (excluding drafts)
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
  # Allows manual triggering
  workflow_dispatch:

# Concurrency control to cancel stale runs
concurrency:
  # If it's a PR, group by PR number. If it's a push to main, group by branch ref.
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

# Environment variables available to all jobs
env:
  COVERAGE_THRESHOLD: ${{ vars.COVERAGE_THRESHOLD || 60 }}

jobs:
  # Job 1a: Build Docker images for private repositories
  # This manually replicates the logic of 'instadeepai/mlops-reusable-ci'
  docker_build_private:
    if: github.event.repository.private == true
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    runs-on: instadeep-ci
    # 1. The internal runner requires a container context
    container:
      image: ubuntu:22.04
    permissions:
      contents: read
      packages: write
    steps:
      # 2. We must install the Docker CLI so the 'docker login' step works
      #    We also need git/curl for checkout.
      - name: Install build dependencies
        run: |
          apt-get update && apt-get install -y git curl docker.io

      - name: Checkout repository
        uses: actions/checkout@v6

      # 3. Configure Remote BuildKit (matches the internal reusable workflow logic)
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        id: buildx
        with:
          version: v0.28.0
          driver: remote
          endpoint: tcp://buildkit-buildkit-service.buildkit:1234

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Log in to Docker Hub
        if: vars.DOCKERHUB_USERNAME != ''
        uses: docker/login-action@v3
        with:
          username: ${{ vars.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.ci
          push: true
          tags: ghcr.io/instadeepai/instanovo-internal/ci-py${{ matrix.python-version }}:latest
          # 4. We pass the GPU build arg here (cu126) for internal builds
          build-args: |
            PYTHON_VERSION=${{ matrix.python-version }}
            INSTALL_EXTRA=cu126
          cache-from: type=registry,ref=ghcr.io/instadeepai/instanovo-internal/ci-py${{ matrix.python-version }}/cache${{ github.event_name == 'pull_request' && format('-pr-{0}', github.event.pull_request.number) || '' }}
          cache-to: type=registry,ref=ghcr.io/instadeepai/instanovo-internal/ci-py${{ matrix.python-version }}/cache${{ github.event_name == 'pull_request' && format('-pr-{0}', github.event.pull_request.number) || '' }},mode=max

  # Job 1b: Build Docker images for public repositories directly
  docker_build_public:
    if: github.event.repository.private == false
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      # Public builds use standard local buildx
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/instadeepai/instanovo/ci-py${{ matrix.python-version }}
          tags: |
            type=sha,prefix=,format=long
            type=ref,event=branch
            type=ref,event=pr

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.ci
          push: true
          tags: |
            ghcr.io/instadeepai/instanovo/ci-py${{ matrix.python-version }}:${{ github.sha }}
            ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          # 5. We pass the CPU build arg here because public builds cannot use GPUs
          build-args: |
            PYTHON_VERSION=${{ matrix.python-version }}
            INSTALL_EXTRA=cpu
          cache-from: type=registry,ref=ghcr.io/instadeepai/instanovo/ci-py${{ matrix.python-version }}/cache${{ github.event_name == 'pull_request' && format('-pr-{0}', github.event.pull_request.number) || '' }}
          cache-to: type=registry,ref=ghcr.io/instadeepai/instanovo/ci-py${{ matrix.python-version }}/cache${{ github.event_name == 'pull_request' && format('-pr-{0}', github.event.pull_request.number) || '' }},mode=max

  # Job 2: Run linting on Linux (in parallel)
  linux_lint:
    if: |
      always() &&
      (needs.docker_build_private.result == 'success' || needs.docker_build_public.result == 'success')
    needs: [docker_build_private, docker_build_public]
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    runs-on: ${{ github.event.repository.private == true && 'instadeep-ci-8-highmem' || 'ubuntu-latest' }}
    container:
      image: ${{ github.event.repository.private == true && 'ghcr.io/instadeepai/instanovo-internal' || 'ghcr.io/instadeepai/instanovo' }}/ci-py${{ matrix.python-version }}:${{ github.event.repository.private == true && 'latest' || github.sha }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
      - run: git config --system --add safe.directory $GITHUB_WORKSPACE

      - name: Verify environment
        run: |
          echo "Python version: $(python --version)"
          uv pip list

      - name: Run pre-commit hooks
        run: |
          pre-commit install
          pre-commit run --all-files

  # Job 3: Run main tests on Linux (in parallel)
  linux_test:
    if: |
      always() &&
      (needs.docker_build_private.result == 'success' || needs.docker_build_public.result == 'success')
    needs: [docker_build_private, docker_build_public]
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    runs-on: ${{ github.event.repository.private == true && 'instadeep-ci-8-highmem' || 'ubuntu-latest' }}
    container:
      image: ${{ github.event.repository.private == true && 'ghcr.io/instadeepai/instanovo-internal' || 'ghcr.io/instadeepai/instanovo' }}/ci-py${{ matrix.python-version }}:${{ github.event.repository.private == true && 'latest' || github.sha }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - run: git config --system --add safe.directory $GITHUB_WORKSPACE

      - name: Restore test resources from Docker image
        run: cp -r /app/tests/instanovo_test_resources ./tests/

      - name: Run tests with coverage
        run: |
          pytest -v \
            --alluredir=allure_results \
            --cov \
            --cov-report=html:docs/coverage \
            --cov-report=xml \
            --random-order
          coverage report -m --fail-under=${COVERAGE_THRESHOLD}

      - name: Upload coverage results
        if: matrix.python-version == '3.13'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-results-py3.13
          path: |
            ./docs/coverage/
            ./coverage.xml
          retention-days: 1

      - name: Upload Allure results
        if: matrix.python-version == '3.13'
        uses: actions/upload-artifact@v4
        with:
          name: allure-results-py${{ matrix.python-version }}
          path: allure_results
          retention-days: 1

      - name: Test notebooks
        if: matrix.python-version == '3.13'
        run: |
          sed -i 's/test\[:1%\]/test[:3]/g' notebooks/getting_started_with_instanovo.ipynb
          sed -i 's/num_beams = 5/num_beams = 1/g' notebooks/getting_started_with_instanovo.ipynb
          python -c "
          import json
          with open('notebooks/getting_started_with_instanovo.ipynb', 'r') as f:
              nb = json.load(f)
          for cell in nb['cells']:
              if cell['cell_type'] == 'code' and any('_setup_knapsack' in line for line in cell.get('source', [])):
                  cell['source'] = ['# Skipped for CI\n', 'pass']
                  break
          with open('notebooks/getting_started_with_instanovo.ipynb', 'w') as f:
              json.dump(nb, f, indent=1)
          "
          python -m ipykernel install --user --name instanovo
          PYDEVD_DISABLE_FILE_VALIDATION=1 pytest \
            --nbmake "./notebooks/getting_started_with_instanovo.ipynb" \
            --nbmake-kernel=instanovo \
            --nbmake-timeout=10000
  # Job 4: Build Docs, Generate Reports, and Deploy
  docs:
    needs: linux_test
    # Check for linux_test success to ignore upstream skipped jobs
    if: always() && needs.linux_test.result == 'success'
    runs-on: ${{ github.event.repository.private == true && 'instadeep-ci-4' || 'ubuntu-latest' }}
    permissions:
      contents: write  # Required for committing badges and checking out code
      packages: read   # Required to pull the ghcr.io container image
    container:
      image: ${{ github.event.repository.private == true && 'ghcr.io/instadeepai/instanovo-internal' || 'ghcr.io/instadeepai/instanovo' }}/ci-py3.13:${{ github.event.repository.private == true && 'latest' || github.sha }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - name: Checkout main branch code
        uses: actions/checkout@v6
        with:
          # Fetch all history for plugins that rely on Git history
          fetch-depth: 0
          # Enable write access for committing coverage badge
          token: ${{ secrets.GITHUB_TOKEN }}

      - run: git config --system --add safe.directory $GITHUB_WORKSPACE

      - name: Generate terminal images with rich-codex
        run: |
          script -e -c "rich-codex \
            --search-include 'docs/**/*.md' \
            --timeout 30 \
            --terminal-theme MONOKAI \
            --terminal-width 160 \
            --use-pty \
            --no-confirm \
            --min-pct-diff 10" /dev/null

      - name: Download coverage results
        uses: actions/download-artifact@v4
        with:
          name: coverage-results-py3.13
          path: .

      - name: Download Allure results
        uses: actions/download-artifact@v4
        with:
          name: allure-results-py3.13
          path: allure_results
      
      - name: Generate coverage badge
        run: |
          if [ -f "coverage.xml" ]; then
            echo "Generating coverage badge..."
            mkdir -p docs/assets
            genbadge coverage -i coverage.xml -o docs/assets/coverage.svg
          else
            echo "Warning: coverage.xml not found, skipping badge generation"
          fi
      
      - name: Commit coverage badge to repository
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: |
          if [ -f "docs/assets/coverage.svg" ]; then
            git config user.name "github-actions[bot]"
            git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git add docs/assets/coverage.svg
            git diff --staged --quiet || git commit -m "docs: update coverage badge [skip ci]"
            git push origin main || echo "No changes to commit or push failed"
          fi
      
      - name: Checkout gh-pages branch for Allure history
        uses: actions/checkout@v6
        with:
          ref: gh-pages
          path: gh-pages
        continue-on-error: true # Continue if gh-pages doesn't exist yet

      - name: Copy Allure history
        run: |
          # Copy history from the temporary checkout to the allure_results directory
          if [ -d "gh-pages/allure-report/history" ]; then
              echo "Copying history from previous report on gh-pages..."
              mkdir -p allure_results/history
              cp -r gh-pages/allure-report/history/* allure_results/history/
          fi
          # Remove the temporary checkout *before* the mkdocs build
          echo "Cleaning up temporary gh-pages directory..."
          rm -rf gh-pages
      
      - name: Generate Allure report
        run: |
          echo "Generating Allure report..."
          allure generate allure_results -o allure-report --clean
      
      - name: Build the MkDocs site
        run: |
          python ./docs/gen_ref_nav.py
          mkdocs build --verbose --site-dir docs_public
      
      - name: Move reports into the built docs_public directory
        run: |
          echo "Placing Allure report..."
          mv allure-report docs_public/allure-report
          echo "Placing coverage report..."
          if [ -d "docs/coverage" ]; then 
            mv docs/coverage docs_public/coverage
          fi

      - name: Deploy to GitHub Pages (PR Preview)
        if: github.event_name == 'pull_request'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs_public
          destination_dir: pr-${{ github.event.pull_request.number }}
          keep_files: true  # Don't remove other PR previews

      - name: Show Preview URL
        if: github.event_name == 'pull_request'
        run: |
          PR_NUM="${{ github.event.pull_request.number }}"
          IS_PRIVATE="${{ github.event.repository.private }}"
          
          if [ "$IS_PRIVATE" == "true" ]; then
            # Private Repo URL
            URL="https://cuddly-adventure-n2v5ryv.pages.github.io/pr-$PR_NUM/"
          else
            # Public Repo URL (Standard format)
            URL="https://instadeepai.github.io/InstaNovo/pr-$PR_NUM/"
          fi
          echo "Documentation Preview deployed successfully!"
          echo "URL: $URL"
          echo "This preview will be deleted after 7 days."
      
      - name: Clean up old previews (>7 days)
        if: github.event_name == 'pull_request'
        run: |
          echo "Cleaning up previews older than 7 days..."
          # Checkout gh-pages branch in a separate directory
          git fetch origin gh-pages || echo "gh-pages branch not found, skipping cleanup"
          
          # Use worktree to checkout gh-pages without affecting current directory
          if git show-ref --verify --quiet refs/remotes/origin/gh-pages; then
            git worktree add gh-pages-cleanup origin/gh-pages 2>/dev/null || (git worktree remove gh-pages-cleanup --force 2>/dev/null; git worktree add gh-pages-cleanup origin/gh-pages)
            
            if [ -d "gh-pages-cleanup" ]; then
              cd gh-pages-cleanup
              
              # Find and remove directories older than 7 days
              REMOVED_COUNT=0
              for dir in pr-*/; do
                if [ -d "$dir" ]; then
                  # Get the directory's modification time and check if it's older than 7 days
                  DIR_MTIME=$(stat -c %Y "$dir" 2>/dev/null || stat -f %m "$dir" 2>/dev/null || echo "0")
                  CURRENT_TIME=$(date +%s)
                  AGE_DAYS=$(( (CURRENT_TIME - DIR_MTIME) / 86400 ))
                  
                  if [ $AGE_DAYS -gt 7 ]; then
                    echo "Removing old preview: $dir (age: ${AGE_DAYS} days)"
                    rm -rf "$dir"
                    REMOVED_COUNT=$((REMOVED_COUNT + 1))
                  fi
                fi
              done
              
              if [ $REMOVED_COUNT -gt 0 ]; then
                git config user.name "github-actions[bot]"
                git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
                # Only stage deletions, not new files
                git add -u
                if ! git diff --staged --quiet; then
                  git commit -m "Clean old PR previews (older than 7 days)"
                  git push origin gh-pages || echo "Push failed"
                  echo "Removed $REMOVED_COUNT old preview(s)"
                else
                  echo "No changes to commit"
                fi
              else
                echo "No old previews to remove"
              fi
              
              cd ..
              git worktree remove gh-pages-cleanup --force || true
            fi
          else
            echo "gh-pages branch does not exist yet, skipping cleanup"
          fi
      
      - name: Deploy to GitHub Pages (Main)
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.CI_DEPLOY_TOKEN }}
          publish_dir: ./docs_public
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'

  # Job 5: Run tests on Windows for public repositories
  windows_test:
    if: github.event.repository.private == false
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    runs-on: windows-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Install uv and set up Python ${{ matrix.python-version }}
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: uv sync --extra cpu --all-groups

      - name: Cache pre-commit environments
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-

      - name: Lint with pre-commit
        run: |
          uv run pre-commit install
          uv run pre-commit run --all-files -c .pre-commit-config.yaml

      - name: Test with pytest
        run: |
          uv run python -m instanovo.scripts.get_zenodo_record
          uv run pytest -v `
            --cov `
            --cov-report=html `
            --cov-report=term `
            --random-order
          uv run coverage report -m --fail-under=$env:COVERAGE_THRESHOLD
        shell: pwsh

      - name: Test notebooks (Python 3.13 only)
        if: matrix.python-version == '3.13'
        run: |
          (Get-Content "notebooks/getting_started_with_instanovo.ipynb") -replace 'test\[:1%\]', 'test[:3]' | Set-Content "notebooks/getting_started_with_instanovo.ipynb"
          (Get-Content "notebooks/getting_started_with_instanovo.ipynb") -replace 'num_beams = 5', 'num_beams = 1' | Set-Content "notebooks/getting_started_with_instanovo.ipynb"
          uv run python -c @"
          import json
          with open('notebooks/getting_started_with_instanovo.ipynb', 'r') as f:
              nb = json.load(f)
          for cell in nb['cells']:
              if cell['cell_type'] == 'code' and any('_setup_knapsack' in line for line in cell.get('source', [])):
                  cell['source'] = ['# Skipped for CI\n', 'pass']
                  break
          with open('notebooks/getting_started_with_instanovo.ipynb', 'w') as f:
              json.dump(nb, f, indent=1)
          "@
          uv run python -m ipykernel install --user --name instanovo
          $env:PYDEVD_DISABLE_FILE_VALIDATION = "1"
          uv run pytest `
            --nbmake "./notebooks/getting_started_with_instanovo.ipynb" `
            --nbmake-kernel=instanovo `
            --nbmake-timeout=10000
        shell: pwsh

  # Job 6: Run tests on macOS for public repositories
  macos_test:
    if: github.event.repository.private == false
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12", "3.13"]
    runs-on: macos-latest
    # Environment variable to use the CPU as a fallback for unsupported MPS operations
    env:
      PYTORCH_ENABLE_MPS_FALLBACK: "1"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Install uv and set up Python ${{ matrix.python-version }}
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: uv sync --extra cpu --all-groups

      - name: Cache pre-commit environments
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ runner.os }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-

      - name: Lint with pre-commit
        run: |
          uv run pre-commit install
          uv run pre-commit run --all-files -c .pre-commit-config.yaml

      - name: Test with pytest
        run: |
          uv run python -m instanovo.scripts.get_zenodo_record
          uv run pytest -v \
            --cov \
            --cov-report=html \
            --cov-report=term \
            --random-order
          uv run coverage report -m --fail-under=${COVERAGE_THRESHOLD}

      - name: Test notebooks (Python 3.13 only)
        if: matrix.python-version == '3.13'
        run: |
          sed -i '' 's/test\[:1%\]/test[:3]/g' notebooks/getting_started_with_instanovo.ipynb
          sed -i '' 's/num_beams = 5/num_beams = 1/g' notebooks/getting_started_with_instanovo.ipynb
          uv run python -c "
          import json
          with open('notebooks/getting_started_with_instanovo.ipynb', 'r') as f:
              nb = json.load(f)
          for cell in nb['cells']:
              if cell['cell_type'] == 'code' and any('_setup_knapsack' in line for line in cell.get('source', [])):
                  cell['source'] = ['# Skipped for CI\n', 'pass']
                  break
          with open('notebooks/getting_started_with_instanovo.ipynb', 'w') as f:
              json.dump(nb, f, indent=1)
          "
          uv run python -m ipykernel install --user --name instanovo
          PYDEVD_DISABLE_FILE_VALIDATION=1 uv run pytest \
            --nbmake "./notebooks/getting_started_with_instanovo.ipynb" \
            --nbmake-kernel=instanovo \
            --nbmake-timeout=10000

  # Job 7: Run GPU-specific tests on private infrastructure
  linux_test_gpu:
    # Run only when PR is merged to main (push to main after merge) or when manually triggered:
    if: github.event.repository.private == true && ((github.event_name == 'push' && github.ref == 'refs/heads/main') || github.event_name == 'workflow_dispatch')
    needs: docker_build_private
    runs-on: instadeep-ci
    container:
      image: ghcr.io/instadeepai/instanovo-internal/ci-py3.13:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - run: git config --system --add safe.directory $GITHUB_WORKSPACE

      - name: Authenticate with AIchor
        run: aichor auth key --apikey ${{ secrets.AICHOR_API_KEY }}
        env:
          AICHOR_API_KEY: ${{ secrets.AICHOR_API_KEY }}

      - name: Update manifest.yaml command
        run: python scripts/update_manifest.py --command "make tests" --gpu 1

      - name: Submit GPU experiment to AIchor
        run: |
          COMMIT_SHORT=$(echo "${{ github.sha }}" | cut -c1-7)
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            MESSAGE="exp: CI GPU test - PR #${{ github.event.pull_request.number }} - $COMMIT_SHORT"
          else
            MESSAGE="exp: CI GPU test - $COMMIT_SHORT"
          fi
          echo "Submitting experiment with message: $MESSAGE"
          EXPERIMENT_OUTPUT=$(aichor submit local experiment \
            --repo-dir . \
            --message "$MESSAGE" \
            --project-name "DTU Denovo Sequencing")
          echo "$EXPERIMENT_OUTPUT"
          EXPERIMENT_ID=$(echo "$EXPERIMENT_OUTPUT" | grep "Experiment ID:" | awk '{print $4}')
          echo "EXPERIMENT_ID=$EXPERIMENT_ID" >> $GITHUB_ENV

      - name: Monitor experiment status
        shell: bash
        run: |
          chmod +x scripts/monitor_experiment.sh
          ./scripts/monitor_experiment.sh "$EXPERIMENT_ID"