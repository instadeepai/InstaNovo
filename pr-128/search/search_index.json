{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#de-novo-peptide-sequencing-with-instanovo","title":"De novo peptide sequencing with InstaNovo","text":"<p>InstaNovo is a transformer neural network with the ability to translate fragment ion peaks into the sequence of amino acids that make up the studied peptide(s). InstaNovo+, inspired by human intuition, is a multinomial diffusion model that further improves performance by iterative refinement of predicted sequences.</p> <p>This documentation will help you get started with InstaNovo. It is divided into the following sections:</p> <ul> <li>Tutorials<ul> <li>How to install InstaNovo, make your first prediction and evaluate InstaNovo's performance.</li> <li>An end-to-end starter notebook that you can run in Google Colab .</li> </ul> </li> <li>How-to guides:<ul> <li>How to perform predictions with InstaNovo with iterative refinement of InstaNovo+, or how to use each model separately.</li> <li>Guide for preparing your own data for use with InstaNovo and InstaNovo+.</li> <li>Details how to train your own InstaNovo and InstaNovo+ models.</li> </ul> </li> <li>Reference:<ul> <li>Overview of the <code>instanovo</code> command-line interface.</li> <li>List of the supported post translational modifications.</li> <li>Description of the columns in the prediction output CSV</li> <li>Code reference API</li> </ul> </li> <li>Explanation:<ul> <li>Explains our performance metrics and benchmarking results</li> <li>A detailed explanation of the <code>SpectrumDataFrame</code> class and its features.</li> </ul> </li> <li>Blog:<ul> <li>Introducing the next generation of InstaNovo models</li> <li>Introducing InstaNovo-P</li> <li>Winnow: calibrated confidence and FDR control for de novo sequencing</li> </ul> </li> <li>For Developers:<ul> <li>How to set up a development environment.</li> <li>How to run the tests and lint the code.</li> <li>View the test coverage and test report.</li> </ul> </li> <li>How to Cite:<ul> <li>Bibtex references for our peer-reviewed publication on InstaNovo and InstaNovo+ and our preprints on InstaNovo-P, InstaNexus and Winnow.</li> </ul> </li> <li>License:<ul> <li>Code is licensed under the Apache License, Version 2.0</li> <li>The model checkpoints are licensed under Creative Commons Non-Commercial (CC BY-NC-SA 4.0)</li> </ul> </li> </ul> <p>Developed by:</p> <ul> <li>InstaDeep</li> <li>The Department of Biotechnology and Biomedicine -   Technical University of Denmark</li> </ul>"},{"location":"citation/","title":"How to cite?","text":""},{"location":"citation/#instanovo-instanovo","title":"InstaNovo &amp; InstaNovo+","text":"<p>If you use <code>InstaNovo</code> or <code>InstaNovo+</code> in your research, please cite our publication in Nature Machine Intelligence: InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale proteomics experiments:</p> <pre><code>@article{eloff_kalogeropoulos_2025_instanovo,\n        title        = {InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale\n                        proteomics experiments},\n        author       = {Eloff, Kevin and Kalogeropoulos, Konstantinos and Mabona, Amandla and Morell,\n                        Oliver and Catzel, Rachel and Rivera-de-Torre, Esperanza and Berg Jespersen,\n                        Jakob and Williams, Wesley and van Beljouw, Sam P. B. and Skwark, Marcin J.\n                        and Laustsen, Andreas Hougaard and Brouns, Stan J. J. and Ljungars,\n                        Anne and Schoof, Erwin M. and Van Goey, Jeroen and auf dem Keller, Ulrich and\n                        Beguir, Karim and Lopez Carranza, Nicolas and Jenkins, Timothy P.},\n        year         = 2025,\n        month        = {Mar},\n        day          = 31,\n        journal      = {Nature Machine Intelligence},\n        doi          = {10.1038/s42256-025-01019-5},\n        issn         = {2522-5839},\n        url          = {https://doi.org/10.1038/s42256-025-01019-5}\n}\n</code></pre>"},{"location":"citation/#instanovo-p","title":"InstaNovo-P","text":"<p>If you use our <code>InstaNovo-P</code> model, finetuned on phosphorylated data, please cite our preprint: InstaNovo-P: A de novo peptide sequencing model for phosphoproteomics:</p> <pre><code>@article {Lauridsen_2025_instanovo-p,\n    author = {Lauridsen, Jesper and Ramasamy, Pathmanaban and Catzel, Rachel and Canbay, Vahap\n        and Mabona, Amandla and Eloff, Kevin and Fullwood, Paul and Ferguson, Jennifer and\n        Kirketerp-M{\\o}ller, Annekatrine and Goldschmidt, Ida Sofie and Claeys, Tine and van\n        Puyenbroeck, Sam and Lopez Carranza, Nicolas and Schoof, Erwin M. and Martens, Lennart and\n        Van Goey, Jeroen and Francavilla, Chiara and Jenkins, Timothy Patrick and Kalogeropoulos,\n        Konstantinos},\n    title = {InstaNovo-P: A de novo peptide sequencing model for phosphoproteomics},\n    elocation-id = {2025.05.14.654049},\n    year = {2025},\n    doi = {10.1101/2025.05.14.654049},\n    publisher = {Cold Spring Harbor Laboratory},\n    URL = {https://www.biorxiv.org/content/early/2025/05/18/2025.05.14.654049},\n    eprint = {https://www.biorxiv.org/content/early/2025/05/18/2025.05.14.654049.full.pdf},\n    journal = {bioRxiv}\n}\n</code></pre>"},{"location":"citation/#instanexus","title":"InstaNexus","text":"<p>If you use our generalizable, end-to-end workflow for direct protein sequencing, <code>InstaNexus</code>, please cite our preprint: Generalizable direct protein sequencing with InstaNexus:</p> <pre><code>@article {Reverenna_2025_instanexus,\n    author = {Reverenna, Marco and Wennekers Nielsen, Maike and Wolff, Darian Stephan and Lytra,\n        Elpida and Colaianni, Pasquale D. and Ljungars, Anne and Laustsen, Andreas H. and Schoof,\n        Erwin M. and Van Goey, Jeroen and Jenkins, Timothy P. and Lukassen, Marie V. and Santos,\n        Alberto and Kalogeropoulos, Konstantinos},\n    title = {Generalizable direct protein sequencing with InstaNexus},\n    elocation-id = {2025.07.25.666861},\n    year = {2025},\n    doi = {10.1101/2025.07.25.666861},\n    publisher = {Cold Spring Harbor Laboratory},\n    URL = {https://www.biorxiv.org/content/early/2025/07/31/2025.07.25.666861},\n    eprint = {https://www.biorxiv.org/content/early/2025/07/31/2025.07.25.666861.full.pdf},\n    journal = {bioRxiv}\n}\n</code></pre>"},{"location":"citation/#winnow","title":"Winnow","text":"<p>If you use our model-agnostic framework for estimating FDR from calibrated de novo sequencing output, <code>Winnow</code>, please cite our preprint: De novo peptide sequencing rescoring and FDR estimation with Winnow:</p> <pre><code>@article{mabona2025novopeptidesequencingrescoring,\n        title={De novo peptide sequencing rescoring and FDR estimation with Winnow},\n        author={Amandla Mabona and Jemma Daniel and Henrik Servais Janssen Knudsen and Rachel Catzel\n        and Kevin Michael Eloff and Erwin M. Schoof and Nicolas Lopez Carranza and Timothy P. Jenkins\n        and Jeroen Van Goey and Konstantinos Kalogeropoulos},\n        year={2025},\n        eprint={2509.24952},\n        archivePrefix={arXiv},\n        primaryClass={q-bio.QM},\n        url={https://arxiv.org/abs/2509.24952},\n}\n</code></pre>"},{"location":"gen_ref_nav/","title":"Gen ref nav","text":"In\u00a0[\u00a0]: Copied! <pre># /// script\n# requires-python = \"&gt;=3.10\"\n# dependencies = [\n#     \"mkdocs-autorefs\",\n#     \"mkdocs-gen-files\",\n#     \"mkdocs-git-revision-date-plugin\",\n#     \"mkdocs-include-markdown-plugin\",\n#     \"mkdocs-material\",\n#     \"mkdocs-pymdownx-material-extras\",\n#     \"mkdocstrings\",\n#     \"mkdocstrings-python\",\n#     \"pymdown-extensions\",\n# ]\n# ///\n\"\"\"Generate the code API pages and navigation.\"\"\"\n</pre> # /// script # requires-python = \"&gt;=3.10\" # dependencies = [ #     \"mkdocs-autorefs\", #     \"mkdocs-gen-files\", #     \"mkdocs-git-revision-date-plugin\", #     \"mkdocs-include-markdown-plugin\", #     \"mkdocs-material\", #     \"mkdocs-pymdownx-material-extras\", #     \"mkdocstrings\", #     \"mkdocstrings-python\", #     \"pymdown-extensions\", # ] # /// \"\"\"Generate the code API pages and navigation.\"\"\" In\u00a0[\u00a0]: Copied! <pre># This script is used by the mkdocs-gen-files plugin (https://oprypin.github.io/mkdocs-gen-files/)\n# for MkDocs (https://www.mkdocs.org/). It creates for each module in the code a stub page\n# and it creates a \"docs/API/summary.md\" page which contains a Table of Contents with links to\n# all the stub pages. When MkDocs runs, it will populate the stub pages with the documentation\n# pulled from the docstrings\nfrom __future__ import annotations\n</pre> # This script is used by the mkdocs-gen-files plugin (https://oprypin.github.io/mkdocs-gen-files/) # for MkDocs (https://www.mkdocs.org/). It creates for each module in the code a stub page # and it creates a \"docs/API/summary.md\" page which contains a Table of Contents with links to # all the stub pages. When MkDocs runs, it will populate the stub pages with the documentation # pulled from the docstrings from __future__ import annotations In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n</pre> from pathlib import Path In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre># Folders for which we don't want to create code documentation but which can contain *.py files\nIGNORE_DIRS = (\"build\", \"data\", \"docs_public\", \"docs\", \"tests\", \"scripts\", \"utils\", \".venv\", \"contrastive\", \"search\")\n</pre> # Folders for which we don't want to create code documentation but which can contain *.py files IGNORE_DIRS = (\"build\", \"data\", \"docs_public\", \"docs\", \"tests\", \"scripts\", \"utils\", \".venv\", \"contrastive\", \"search\") In\u00a0[\u00a0]: Copied! <pre>def is_ignored_directory(module_path: Path) -&gt; bool:\n    \"\"\"Check if the module path is within any ignored directory.\"\"\"\n    return any(part in IGNORE_DIRS for part in module_path.parts)\n</pre> def is_ignored_directory(module_path: Path) -&gt; bool:     \"\"\"Check if the module path is within any ignored directory.\"\"\"     return any(part in IGNORE_DIRS for part in module_path.parts) In\u00a0[\u00a0]: Copied! <pre>def is_ignored_file(module_path: Path) -&gt; bool:\n    \"\"\"Check if the file is a test file or ignored file.\"\"\"\n    return module_path.parts[-1].endswith(\"_test\") or module_path.parts[-1] in (\n        \"mlflow_auth\",\n        \"types\",\n        \"constants\",\n        \"cli\",\n    )\n</pre> def is_ignored_file(module_path: Path) -&gt; bool:     \"\"\"Check if the file is a test file or ignored file.\"\"\"     return module_path.parts[-1].endswith(\"_test\") or module_path.parts[-1] in (         \"mlflow_auth\",         \"types\",         \"constants\",         \"cli\",     ) In\u00a0[\u00a0]: Copied! <pre>def process_python_files(source_directory: str, module_name: str) -&gt; None:\n    \"\"\"Generate documentation paths for Python files in the source directory.\"\"\"\n    nav = mkdocs_gen_files.Nav()\n\n    for python_file in sorted(Path(source_directory).rglob(\"*.py\")):\n        relative_module_path = python_file.relative_to(source_directory).with_suffix(\"\")\n\n        if not is_ignored_directory(relative_module_path) and not is_ignored_file(relative_module_path):\n            doc_path = python_file.relative_to(Path(source_directory) / module_name).with_suffix(\".md\")\n            full_doc_path = Path(\"API\", doc_path)\n\n            parts = tuple(relative_module_path.parts)\n\n            if parts[-1] == \"__init__\":\n                parts = parts[:-1]\n                doc_path = doc_path.with_name(\"index.md\")\n                full_doc_path = full_doc_path.with_name(\"index.md\")\n            elif parts[-1] == \"__main__\":\n                continue\n\n            nav[parts] = doc_path.as_posix()\n\n            with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:\n                ident = \".\".join(parts)\n                fd.write(f\"::: {ident}\")\n\n            mkdocs_gen_files.set_edit_path(full_doc_path, \"..\" / python_file)\n\n    with mkdocs_gen_files.open(\"API/summary.md\", \"w\") as nav_file:\n        nav_file.writelines(nav.build_literate_nav())\n</pre> def process_python_files(source_directory: str, module_name: str) -&gt; None:     \"\"\"Generate documentation paths for Python files in the source directory.\"\"\"     nav = mkdocs_gen_files.Nav()      for python_file in sorted(Path(source_directory).rglob(\"*.py\")):         relative_module_path = python_file.relative_to(source_directory).with_suffix(\"\")          if not is_ignored_directory(relative_module_path) and not is_ignored_file(relative_module_path):             doc_path = python_file.relative_to(Path(source_directory) / module_name).with_suffix(\".md\")             full_doc_path = Path(\"API\", doc_path)              parts = tuple(relative_module_path.parts)              if parts[-1] == \"__init__\":                 parts = parts[:-1]                 doc_path = doc_path.with_name(\"index.md\")                 full_doc_path = full_doc_path.with_name(\"index.md\")             elif parts[-1] == \"__main__\":                 continue              nav[parts] = doc_path.as_posix()              with mkdocs_gen_files.open(full_doc_path, \"w\") as fd:                 ident = \".\".join(parts)                 fd.write(f\"::: {ident}\")              mkdocs_gen_files.set_edit_path(full_doc_path, \"..\" / python_file)      with mkdocs_gen_files.open(\"API/summary.md\", \"w\") as nav_file:         nav_file.writelines(nav.build_literate_nav()) In\u00a0[\u00a0]: Copied! <pre>process_python_files(source_directory=\".\", module_name=\"instanovo\")\n</pre> process_python_files(source_directory=\".\", module_name=\"instanovo\")"},{"location":"license/","title":"License","text":"<p>Code is licensed under the Apache License, Version 2.0</p> <p>The model checkpoints are licensed under Creative Commons Non-Commercial (CC BY-NC-SA 4.0)</p>"},{"location":"license/#apache-license","title":"Apache License","text":"<p>Version 2.0, January 2004 &lt;http://www.apache.org/licenses/&gt;</p>"},{"location":"license/#terms-and-conditions-for-use-reproduction-and-distribution","title":"Terms and Conditions for use, reproduction, and distribution","text":""},{"location":"license/#1-definitions","title":"1. Definitions","text":"<p>\u201cLicense\u201d shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.</p> <p>\u201cLicensor\u201d shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.</p> <p>\u201cLegal Entity\u201d shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u201ccontrol\u201d means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\u201cYou\u201d (or \u201cYour\u201d) shall mean an individual or Legal Entity exercising permissions granted by this License.</p> <p>\u201cSource\u201d form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.</p> <p>\u201cObject\u201d form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.</p> <p>\u201cWork\u201d shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).</p> <p>\u201cDerivative Works\u201d shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.</p> <p>\u201cContribution\u201d shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u201csubmitted\u201d means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u201cNot a Contribution.\u201d</p> <p>\u201cContributor\u201d shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.</p>"},{"location":"license/#2-grant-of-copyright-license","title":"2. Grant of Copyright License","text":"<p>Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.</p>"},{"location":"license/#3-grant-of-patent-license","title":"3. Grant of Patent License","text":"<p>Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.</p>"},{"location":"license/#4-redistribution","title":"4. Redistribution","text":"<p>You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:</p> <ul> <li>(a) You must give any other recipients of the Work or Derivative Works a copy of this License;   and</li> <li>(b) You must cause any modified files to carry prominent notices stating that You changed the   files; and</li> <li>(c) You must retain, in the Source form of any Derivative Works that You distribute, all   copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding   those notices that do not pertain to any part of the Derivative Works; and</li> <li>(d) If the Work includes a \u201cNOTICE\u201d text file as part of its distribution, then any Derivative   Works that You distribute must include a readable copy of the attribution notices contained within   such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works,   in at least one of the following places: within a NOTICE text file distributed as part of the   Derivative Works; within the Source form or documentation, if provided along with the Derivative   Works; or, within a display generated by the Derivative Works, if and wherever such third-party   notices normally appear. The contents of the NOTICE file are for informational purposes only and   do not modify the License. You may add Your own attribution notices within Derivative Works that   You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such   additional attribution notices cannot be construed as modifying the License.</li> </ul> <p>You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.</p>"},{"location":"license/#5-submission-of-contributions","title":"5. Submission of Contributions","text":"<p>Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.</p>"},{"location":"license/#6-trademarks","title":"6. Trademarks","text":"<p>This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.</p>"},{"location":"license/#7-disclaimer-of-warranty","title":"7. Disclaimer of Warranty","text":"<p>Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.</p>"},{"location":"license/#8-limitation-of-liability","title":"8. Limitation of Liability","text":"<p>In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.</p>"},{"location":"license/#9-accepting-warranty-or-additional-liability","title":"9. Accepting Warranty or Additional Liability","text":"<p>While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.</p> <p>END OF TERMS AND CONDITIONS</p>"},{"location":"license/#appendix-how-to-apply-the-apache-license-to-your-work","title":"APPENDIX: How to apply the Apache License to your work","text":"<p>To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets <code>[]</code> replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \u201cprinted page\u201d as the copyright notice for easier identification within third-party archives.</p> <pre><code>Copyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"license/#creative-commons-attribution-noncommercial-sharealike-40-international","title":"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International","text":"<p>Creative Commons Corporation (\u201cCreative Commons\u201d) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \u201cas-is\u201d basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <ul> <li> <p>Considerations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors.</p> </li> <li> <p>Considerations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor\u2019s permission is not necessary for any reason\u2013for example, because of any applicable exception or limitation to copyright\u2013then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public.</p> </li> </ul>"},{"location":"license/#creative-commons-attribution-noncommercial-sharealike-40-international-public-license","title":"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License","text":"<p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p>"},{"location":"license/#section-1-definitions","title":"Section 1 \u2013 Definitions.","text":"<p>a. Adapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.</p> <p>c. BY-NC-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.</p> <p>d. Copyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.</p> <p>e. Effective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.</p> <p>f. Exceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.</p> <p>g. License Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution, NonCommercial, and ShareAlike.</p> <p>h. Licensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.</p> <p>i. Licensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.</p> <p>j. Licensor means the individual(s) or entity(ies) granting rights under this Public License.</p> <p>k. NonCommercial means not primarily intended for or directed towards commercial advantage or monetary compensation. For purposes of this Public License, the exchange of the Licensed Material for other material subject to Copyright and Similar Rights by digital file-sharing or similar means is NonCommercial provided there is no payment of monetary compensation in connection with the exchange.</p> <p>l. Share means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.</p> <p>m. Sui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.</p> <p>n. You means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.</p>"},{"location":"license/#section-2-scope","title":"Section 2 \u2013 Scope.","text":"<p>a. License grant.</p> <ol> <li> <p>Subject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:</p> <pre><code>A. reproduce and Share the Licensed Material, in whole or in part, for NonCommercial purposes only; and\n\nB. produce, reproduce, and Share Adapted Material for NonCommercial purposes only.\n</code></pre> </li> <li> <p>Exceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.</p> </li> <li> <p>Term. The term of this Public License is specified in Section 6(a).</p> </li> <li> <p>Media and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.</p> </li> <li> <p>Downstream recipients.</p> <pre><code>A. __Offer from the Licensor \u2013 Licensed Material.__ Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\n\nB. __Additional offer from the Licensor \u2013 Adapted Material.__ Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter\u2019s License You apply.\n\nC. __No downstream restrictions.__ You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\n</code></pre> </li> <li> <p>No endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).</p> </li> </ol> <p>b. Other rights.</p> <ol> <li> <p>Moral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.</p> </li> <li> <p>Patent and trademark rights are not licensed under this Public License.</p> </li> <li> <p>To the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties, including when the Licensed Material is used other than for NonCommercial purposes.</p> </li> </ol>"},{"location":"license/#section-3-license-conditions","title":"Section 3 \u2013 License Conditions.","text":"<p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <ol> <li> <p>If You Share the Licensed Material (including in modified form), You must:</p> <p>A. retain the following if it is supplied by the Licensor with the Licensed Material:</p> <pre><code> i. identification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\n\n ii. a copyright notice;\n\n iii. a notice that refers to this Public License;\n\n iv. a notice that refers to the disclaimer of warranties;\n\n v. a URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n</code></pre> <p>B. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and</p> <p>C. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.</p> </li> <li> <p>You may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.</p> </li> <li> <p>If requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.</p> </li> </ol> <p>b. ShareAlike.</p> <p>In addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.</p> <ol> <li> <p>The Adapter\u2019s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-NC-SA Compatible License.</p> </li> <li> <p>You must include the text of, or the URI or hyperlink to, the Adapter's License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.</p> </li> <li> <p>You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter's License You apply.</p> </li> </ol>"},{"location":"license/#section-4-sui-generis-database-rights","title":"Section 4 \u2013 Sui Generis Database Rights.","text":"<p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database for NonCommercial purposes only;</p> <p>b. if You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p>"},{"location":"license/#section-5-disclaimer-of-warranties-and-limitation-of-liability","title":"Section 5 \u2013 Disclaimer of Warranties and Limitation of Liability.","text":"<p>a. Unless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.</p> <p>b. To the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.</p> <p>c. The disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.</p>"},{"location":"license/#section-6-term-and-termination","title":"Section 6 \u2013 Term and Termination.","text":"<p>a. This Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:</p> <ol> <li> <p>automatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or</p> </li> <li> <p>upon express reinstatement by the Licensor.</p> </li> </ol> <p>For the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.</p> <p>c. For the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public License.</p>"},{"location":"license/#section-7-other-terms-and-conditions","title":"Section 7 \u2013 Other Terms and Conditions.","text":"<p>a. The Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.</p>"},{"location":"license/#section-8-interpretation","title":"Section 8 \u2013 Interpretation.","text":"<p>a. For the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.</p> <p>c. No term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \u201cCreative Commons\u201d or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org</p>"},{"location":"API/","title":"Index","text":""},{"location":"API/#instanovo","title":"<code>instanovo</code>","text":""},{"location":"API/#instanovo.__version__","title":"<code>__version__ = '1.2.2'</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.cgroup_max_mem_limit_path","title":"<code>cgroup_max_mem_limit_path = '/sys/fs/cgroup/memory.max'</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.cgroup_high_mem_limit_path","title":"<code>cgroup_high_mem_limit_path = '/sys/fs/cgroup/memory.high'</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.high_limit","title":"<code>high_limit = open(cgroup_high_mem_limit_path).read()</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.max_limit","title":"<code>max_limit = open(cgroup_max_mem_limit_path).read()</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.hard_limit","title":"<code>hard_limit = resource.RLIM_INFINITY if max_limit == 'max\\n' else int(max_limit)</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.soft_limit","title":"<code>soft_limit = hard_limit if high_limit == 'max\\n' else int(high_limit)</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.terminal_width","title":"<code>terminal_width = shutil.get_terminal_size(fallback=(175, 24)).columns</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.console","title":"<code>console = Console(width=terminal_width)</code>  <code>module-attribute</code>","text":""},{"location":"API/#instanovo.get_rank","title":"<code>get_rank() -&gt; int | None</code>","text":"<p>Get the current process rank in distributed training.</p> RETURNS DESCRIPTION <code>int | None</code> <p>int | None: The process rank if in distributed training, None otherwise</p>"},{"location":"API/#instanovo.set_rank","title":"<code>set_rank(rank: int | None) -&gt; None</code>","text":"<p>Set the current process rank for distributed training.</p> PARAMETER DESCRIPTION <code>rank</code> <p>The process rank to set, or None for non-distributed training</p> <p> TYPE: <code>int | None</code> </p> RAISES DESCRIPTION <code>RuntimeError</code> <p>If the rank has already been set</p>"},{"location":"API/summary/","title":"API","text":"<ul> <li>instanovo<ul> <li>common<ul> <li>dataset</li> <li>predictor</li> <li>scheduler</li> <li>trainer</li> </ul> </li> <li>diffusion<ul> <li>layers</li> <li>model</li> <li>multinomial_diffusion</li> <li>predict</li> <li>train</li> </ul> </li> <li>inference<ul> <li>beam_search</li> <li>diffusion</li> <li>greedy_search</li> <li>interfaces</li> <li>knapsack</li> <li>knapsack_beam_search</li> </ul> </li> <li>transformer<ul> <li>layers</li> <li>model</li> <li>predict</li> <li>train</li> </ul> </li> </ul> </li> </ul>"},{"location":"API/common/","title":"Index","text":""},{"location":"API/common/#instanovo.common","title":"<code>common</code>","text":""},{"location":"API/common/#instanovo.common.__all__","title":"<code>__all__ = ['DataProcessor', 'AccelerateDeNovoTrainer', 'AccelerateDeNovoPredictor', 'FinetuneScheduler', 'WarmupScheduler', 'CosineWarmupScheduler', 'NeptuneSummaryWriter', 'TrainingState', 'Timer']</code>  <code>module-attribute</code>","text":""},{"location":"API/common/#instanovo.common.DataProcessor","title":"<code>DataProcessor(metadata_columns: list[str] | set[str] | None = None)</code>","text":"<p>Data processor abstract class.</p> <p>This class is used to process the data before it is used in the model. It is designed to be used with the <code>Dataset</code> class from the HuggingFace <code>datasets</code> library.</p> <p>It includes two main methods: - <code>process_row</code>: Processes a row of data. - <code>collate_fn</code>: Collates a batch of data. To be passed to the <code>DataLoader</code> class.</p> <p>Additionally, it includes a way to pass metadata columns that will be kept after processing a dataset. These metadata columns will also bypass the <code>collate_fn</code>.</p> <p>Initialize the data processor.</p> PARAMETER DESCRIPTION <code>metadata_columns</code> <p>The metadata columns to add to the expected columns.</p> <p> TYPE: <code>list[str] | set[str] | None</code> DEFAULT: <code>None</code> </p>"},{"location":"API/common/#instanovo.common.DataProcessor.metadata_columns","title":"<code>metadata_columns: set[str]</code>  <code>property</code>","text":"<p>Get the metadata columns.</p> <p>These columns are kept after processing a dataset.</p> RETURNS DESCRIPTION <code>set[str]</code> <p>list[str]: The metadata columns.</p>"},{"location":"API/common/#instanovo.common.DataProcessor.process_row","title":"<code>process_row(row: dict[str, Any]) -&gt; dict[str, Any]</code>  <code>abstractmethod</code>","text":"<p>Process a single row of data.</p> PARAMETER DESCRIPTION <code>row</code> <p>The row of data to process in dict format.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: The processed row with resulting columns.</p>"},{"location":"API/common/#instanovo.common.DataProcessor.process_dataset","title":"<code>process_dataset(dataset: Dataset, return_format: str | None = 'torch') -&gt; Dataset</code>","text":"<p>Process a dataset by mapping the <code>process_row</code> method.</p> <p>The resulting dataset has the columns expected by the <code>collate_fn</code> method.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>The dataset to process.</p> <p> TYPE: <code>Dataset</code> </p> <code>return_format</code> <p>The format to return the dataset in. Default is \"torch\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>'torch'</code> </p> RETURNS DESCRIPTION <code>Dataset</code> <p>The processed dataset.</p> <p> TYPE: <code>Dataset</code> </p>"},{"location":"API/common/#instanovo.common.DataProcessor.collate_fn","title":"<code>collate_fn(batch: list[dict[str, Any]]) -&gt; dict[str, Any]</code>","text":"<p>Collate a batch.</p> <p>Metadata columns are added after collation.</p> PARAMETER DESCRIPTION <code>batch</code> <p>The batch to collate.</p> <p> TYPE: <code>list[dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: The collated batch with metadata.</p>"},{"location":"API/common/#instanovo.common.DataProcessor.get_expected_columns","title":"<code>get_expected_columns() -&gt; list[str]</code>","text":"<p>Get the expected columns to be kept in the dataset after processing.</p> <p>These columns are expected by the <code>collate_fn</code> method and include both data and metadata columns.</p> RETURNS DESCRIPTION <code>list[str]</code> <p>list[str]: The expected columns.</p>"},{"location":"API/common/#instanovo.common.DataProcessor.add_metadata_columns","title":"<code>add_metadata_columns(columns: list[str] | set[str]) -&gt; None</code>","text":"<p>Add expected metadata columns.</p> PARAMETER DESCRIPTION <code>columns</code> <p>The columns to add.</p> <p> TYPE: <code>list[str] | set[str]</code> </p>"},{"location":"API/common/#instanovo.common.DataProcessor.remove_modifications","title":"<code>remove_modifications(peptide: str, replace_isoleucine_with_leucine: bool = True) -&gt; str</code>  <code>staticmethod</code>","text":"<p>Remove modifications and optionally replace Isoleucine with Leucine.</p> PARAMETER DESCRIPTION <code>peptide</code> <p>The peptide to remove modifications from.</p> <p> TYPE: <code>str</code> </p> <code>replace_isoleucine_with_leucine</code> <p>Whether to replace Isoleucine with Leucine.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The peptide with modifications removed.</p> <p> TYPE: <code>str</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor","title":"<code>AccelerateDeNovoPredictor(config: DictConfig)</code>","text":"<p>Predictor class that uses the Accelerate library.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.s3","title":"<code>s3: S3FileHandler</code>  <code>property</code>","text":"<p>Get the S3 file handler.</p> RETURNS DESCRIPTION <code>S3FileHandler</code> <p>The S3 file handler</p> <p> TYPE: <code>S3FileHandler</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.config","title":"<code>config = config</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.targets","title":"<code>targets: list | None = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.output_path","title":"<code>output_path = self.config.get('output_path', None)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.pred_df","title":"<code>pred_df: pd.DataFrame | None = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.results_dict","title":"<code>results_dict: dict | None = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.prediction_tokenised_col","title":"<code>prediction_tokenised_col = self.config.get('prediction_tokenised_col', 'predictions_tokenised')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.prediction_col","title":"<code>prediction_col = self.config.get('prediction_col', 'predictions')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.log_probs_col","title":"<code>log_probs_col = self.config.get('log_probs_col', 'log_probs')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.token_log_probs_col","title":"<code>token_log_probs_col = self.config.get('token_log_probs_col', 'token_log_probs')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.save_encoder_outputs","title":"<code>save_encoder_outputs = config.get('save_encoder_outputs', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.encoder_output_path","title":"<code>encoder_output_path = config.get('encoder_output_path', None)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.encoder_output_reduction","title":"<code>encoder_output_reduction = config.get('encoder_output_reduction', 'mean')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.accelerator","title":"<code>accelerator = self.setup_accelerator()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.denovo","title":"<code>denovo = self.config.get('denovo', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.model","title":"<code>model = self.model.eval()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.residue_set","title":"<code>residue_set = self.model.residue_set</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.test_dataset","title":"<code>test_dataset = self.load_dataset()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.test_dataloader","title":"<code>test_dataloader = self.build_dataloader(self.test_dataset)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.decoder","title":"<code>decoder = self.setup_decoder()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.metrics","title":"<code>metrics = self.setup_metrics()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.running_loss","title":"<code>running_loss = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.steps_per_inference","title":"<code>steps_per_inference = len(self.test_dataloader)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.load_model","title":"<code>load_model() -&gt; Tuple[nn.Module, DictConfig]</code>  <code>abstractmethod</code>","text":"<p>Load the model.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>  <code>abstractmethod</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.setup_data_processor","title":"<code>setup_data_processor() -&gt; DataProcessor</code>  <code>abstractmethod</code>","text":"<p>Setup the data processor.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; dict[str, Any]</code>  <code>abstractmethod</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.postprocess_dataset","title":"<code>postprocess_dataset(dataset: Dataset) -&gt; Dataset</code>","text":"<p>Postprocess the dataset.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.load_dataset","title":"<code>load_dataset() -&gt; Dataset</code>","text":"<p>Load the test dataset.</p> RETURNS DESCRIPTION <code>Dataset</code> <p>The test dataset</p> <p> TYPE: <code>Dataset</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.print_sample_batch","title":"<code>print_sample_batch() -&gt; None</code>","text":"<p>Print a sample batch of the training data.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.setup_metrics","title":"<code>setup_metrics() -&gt; Metrics</code>","text":"<p>Setup the metrics.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.setup_accelerator","title":"<code>setup_accelerator() -&gt; Accelerator</code>","text":"<p>Setup the accelerator.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.build_dataloader","title":"<code>build_dataloader(test_dataset: Dataset) -&gt; torch.utils.data.DataLoader</code>","text":"<p>Setup the dataloaders.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.predict","title":"<code>predict() -&gt; pd.DataFrame</code>","text":"<p>Predict the test dataset.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.predictions_to_df","title":"<code>predictions_to_df(predictions: dict[str, list]) -&gt; pd.DataFrame</code>","text":"<p>Convert the predictions to a pandas DataFrame.</p> PARAMETER DESCRIPTION <code>predictions</code> <p>The predictions dictionary</p> <p> TYPE: <code>dict[str, list]</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: The predictions dataframe</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.postprocess_predictions","title":"<code>postprocess_predictions(pred_df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Postprocess the predictions.</p> <p>Optionally, this can be used to modify the predictions, eg. ensembling. By default, this does nothing.</p> PARAMETER DESCRIPTION <code>pred_df</code> <p>The predictions dataframe</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: The postprocessed predictions dataframe</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.calculate_metrics","title":"<code>calculate_metrics(pred_df: pd.DataFrame) -&gt; dict[str, Any] | None</code>","text":"<p>Calculate the metrics.</p> PARAMETER DESCRIPTION <code>pred_df</code> <p>The predictions dataframe</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>dict[str, Any] | None: The results dictionary containing the metrics</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.save_predictions","title":"<code>save_predictions(pred_df: pd.DataFrame, results_dict: dict[str, list] | None = None) -&gt; None</code>","text":"<p>Save the predictions to a file.</p> PARAMETER DESCRIPTION <code>pred_df</code> <p>The predictions dataframe</p> <p> TYPE: <code>DataFrame</code> </p> <code>results_dict</code> <p>The results dictionary containing the metrics</p> <p> TYPE: <code>dict[str, list] | None</code> DEFAULT: <code>None</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoPredictor.save_encoder_outputs_to_parquet","title":"<code>save_encoder_outputs_to_parquet(spectrum_ids: list[str], encoder_outputs: list[np.ndarray]) -&gt; None</code>","text":"<p>Save the encoder outputs to a file.</p> PARAMETER DESCRIPTION <code>encoder_outputs</code> <p>The encoder outputs</p> <p> TYPE: <code>list[ndarray]</code> </p> <code>spectrum_ids</code> <p>The spectrum ids</p> <p> TYPE: <code>list[str]</code> </p>"},{"location":"API/common/#instanovo.common.CosineWarmupScheduler","title":"<code>CosineWarmupScheduler(optimizer: torch.optim.Optimizer, warmup: int, max_iters: int)</code>","text":"<p>               Bases: <code>_LRScheduler</code></p> <p>Learning rate scheduler with linear warm up followed by cosine shaped decay.</p>"},{"location":"API/common/#instanovo.common.CosineWarmupScheduler--parameters","title":"Parameters","text":"<p>optimizer : torch.optim.Optimizer     Optimizer object. warmup : int     The number of warm up iterations. max_iters : int     The total number of iterations.</p>"},{"location":"API/common/#instanovo.common.CosineWarmupScheduler.get_lr","title":"<code>get_lr() -&gt; list[float]</code>","text":"<p>Get the learning rate at the current step.</p>"},{"location":"API/common/#instanovo.common.CosineWarmupScheduler.get_lr_factor","title":"<code>get_lr_factor(epoch: int) -&gt; float</code>","text":"<p>Get the LR factor at the current step.</p>"},{"location":"API/common/#instanovo.common.FinetuneScheduler","title":"<code>FinetuneScheduler(model_state_dict: dict, config: DictConfig, steps_per_epoch: int | None = None)</code>","text":"<p>Scheduler for unfreezing parameters of a model.</p> PARAMETER DESCRIPTION <code>model_state_dict</code> <p>The state dictionary of the model.</p> <p> TYPE: <code>dict</code> </p> <code>config</code> <p>The configuration for the scheduler.</p> <p> TYPE: <code>DictConfig</code> </p> <code>steps_per_epoch</code> <p>The number of steps per epoch.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p>"},{"location":"API/common/#instanovo.common.FinetuneScheduler.model_state_dict","title":"<code>model_state_dict = model_state_dict</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.FinetuneScheduler.config","title":"<code>config = config</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.FinetuneScheduler.steps_per_epoch","title":"<code>steps_per_epoch = steps_per_epoch</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.FinetuneScheduler.is_verbose","title":"<code>is_verbose = self.config.get('verbose', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.FinetuneScheduler.schedule","title":"<code>schedule = self._get_schedule()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.FinetuneScheduler.next_phase","title":"<code>next_phase: dict[str, Any] | None = self.schedule.pop(0)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.FinetuneScheduler.step","title":"<code>step(global_step: int) -&gt; None</code>","text":"<p>Step the unfreezing scheduler.</p> PARAMETER DESCRIPTION <code>global_step</code> <p>The global step of the model.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/#instanovo.common.WarmupScheduler","title":"<code>WarmupScheduler(optimizer: torch.optim.Optimizer, warmup: int)</code>","text":"<p>               Bases: <code>_LRScheduler</code></p> <p>Linear warmup scheduler.</p>"},{"location":"API/common/#instanovo.common.WarmupScheduler.warmup","title":"<code>warmup = warmup</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.WarmupScheduler.get_lr","title":"<code>get_lr() -&gt; list[float]</code>","text":"<p>Get the learning rate at the current step.</p>"},{"location":"API/common/#instanovo.common.WarmupScheduler.get_lr_factor","title":"<code>get_lr_factor(epoch: int) -&gt; float</code>","text":"<p>Get the LR factor at the current step.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer","title":"<code>AccelerateDeNovoTrainer(config: DictConfig)</code>","text":"<p>Trainer class that uses the Accelerate library.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.run_id","title":"<code>run_id: str</code>  <code>property</code>","text":"<p>Get the run ID.</p> RETURNS DESCRIPTION <code>str</code> <p>The run ID</p> <p> TYPE: <code>str</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.s3","title":"<code>s3: S3FileHandler</code>  <code>property</code>","text":"<p>Get the S3 file handler.</p> RETURNS DESCRIPTION <code>S3FileHandler</code> <p>The S3 file handler</p> <p> TYPE: <code>S3FileHandler</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.global_step","title":"<code>global_step: int</code>  <code>property</code>","text":"<p>Get the current global training step.</p> <p>This represents the total number of training steps across all epochs.</p> RETURNS DESCRIPTION <code>int</code> <p>The current global step number</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.epoch","title":"<code>epoch: int</code>  <code>property</code>","text":"<p>Get the current training epoch.</p> <p>This represents the current epoch number in the training process.</p> RETURNS DESCRIPTION <code>int</code> <p>The current epoch number</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.training_state","title":"<code>training_state: TrainingState</code>  <code>property</code>","text":"<p>Get the training state.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.config","title":"<code>config = config</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.enable_verbose_logging","title":"<code>enable_verbose_logging = self.config.get('enable_verbose_logging', True)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.accelerator","title":"<code>accelerator = self.setup_accelerator()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.residue_set","title":"<code>residue_set = ResidueSet(residue_masses=(self.config.residues.get('residues')), residue_remapping=(self.config.dataset.get('residue_remapping', None)))</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.model","title":"<code>model = self.setup_model()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.optimizer","title":"<code>optimizer = self.setup_optimizer()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.lr_scheduler","title":"<code>lr_scheduler = self.setup_scheduler()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.decoder","title":"<code>decoder = self.setup_decoder()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.metrics","title":"<code>metrics = self.setup_metrics()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.running_loss","title":"<code>running_loss = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.total_steps","title":"<code>total_steps = self.config.get('training_steps', 2500000)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.finetune_scheduler","title":"<code>finetune_scheduler: FinetuneScheduler | None = FinetuneScheduler(self.model.state_dict(), self.config.get('finetune'))</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.steps_per_validation","title":"<code>steps_per_validation = self.config.get('validation_interval', 100000)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.steps_per_checkpoint","title":"<code>steps_per_checkpoint = self.config.get('checkpoint_interval', 100000)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.last_validation_metric","title":"<code>last_validation_metric = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.best_checkpoint_metric","title":"<code>best_checkpoint_metric = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_model","title":"<code>setup_model() -&gt; nn.Module</code>  <code>abstractmethod</code>","text":"<p>Setup the model.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_optimizer","title":"<code>setup_optimizer() -&gt; torch.optim.Optimizer</code>  <code>abstractmethod</code>","text":"<p>Setup the optimizer.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>  <code>abstractmethod</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_data_processors","title":"<code>setup_data_processors() -&gt; tuple[DataProcessor, DataProcessor]</code>  <code>abstractmethod</code>","text":"<p>Setup the data processor.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.save_model","title":"<code>save_model(is_best_checkpoint: bool = False) -&gt; None</code>  <code>abstractmethod</code>","text":"<p>Save the model.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.forward","title":"<code>forward(batch: Any) -&gt; tuple[torch.Tensor, dict[str, torch.Tensor]]</code>  <code>abstractmethod</code>","text":"<p>Forward pass for the model to calculate loss.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; tuple[list[str] | list[list[str]], list[str] | list[list[str]]]</code>  <code>abstractmethod</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.convert_interval_to_steps","title":"<code>convert_interval_to_steps(interval: float | int, steps_per_epoch: int) -&gt; int</code>  <code>staticmethod</code>","text":"<p>Convert an interval to steps.</p> PARAMETER DESCRIPTION <code>interval</code> <p>The interval to convert.</p> <p> TYPE: <code>float | int</code> </p> <code>steps_per_epoch</code> <p>The number of steps per epoch.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The number of steps.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.log_if_verbose","title":"<code>log_if_verbose(message: str, level: str = 'info') -&gt; None</code>","text":"<p>Log a message if verbose logging is enabled.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_metrics","title":"<code>setup_metrics() -&gt; Metrics</code>","text":"<p>Setup the metrics.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_accelerator","title":"<code>setup_accelerator() -&gt; Accelerator</code>","text":"<p>Setup the accelerator.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.build_dataloaders","title":"<code>build_dataloaders(train_dataset: Dataset, valid_dataset: Dataset) -&gt; tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]</code>","text":"<p>Setup the dataloaders.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_scheduler","title":"<code>setup_scheduler() -&gt; torch.optim.lr_scheduler.LRScheduler</code>","text":"<p>Setup the learning rate scheduler.</p> RETURNS DESCRIPTION <code>LRScheduler</code> <p>torch.optim.lr_scheduler.LRScheduler: The learning rate scheduler</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_neptune","title":"<code>setup_neptune() -&gt; None</code>","text":"<p>Setup the neptune.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.setup_tensorboard","title":"<code>setup_tensorboard() -&gt; None</code>","text":"<p>Setup the tensorboard.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.load_datasets","title":"<code>load_datasets() -&gt; tuple[Dataset, Dataset, int, int]</code>","text":"<p>Load the training and validation datasets.</p> RETURNS DESCRIPTION <code>tuple[Dataset, Dataset, int, int]</code> <p>tuple[SpectrumDataFrame, SpectrumDataFrame]: The training and validation datasets</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.print_sample_batch","title":"<code>print_sample_batch() -&gt; None</code>","text":"<p>Print a sample batch of the training data.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.save_accelerator_state","title":"<code>save_accelerator_state(is_best_checkpoint: bool = False) -&gt; None</code>","text":"<p>Save the accelerator state.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.check_if_best_checkpoint","title":"<code>check_if_best_checkpoint() -&gt; bool</code>","text":"<p>Check if the last validation metric is the best metric.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.load_accelerator_state","title":"<code>load_accelerator_state() -&gt; None</code>","text":"<p>Load the accelerator state.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.load_model_state","title":"<code>load_model_state() -&gt; None</code>","text":"<p>Load the model state.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.update_model_state","title":"<code>update_model_state(model_state: dict[str, torch.Tensor], model_config: DictConfig) -&gt; dict[str, torch.Tensor]</code>","text":"<p>Update the model state.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.update_vocab","title":"<code>update_vocab(model_state: dict[str, torch.Tensor]) -&gt; dict[str, torch.Tensor]</code>","text":"<p>Update the vocabulary of the model.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.train","title":"<code>train() -&gt; None</code>","text":"<p>Train the model.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.prepare_batch","title":"<code>prepare_batch(batch: Iterable[Any]) -&gt; Any</code>","text":"<p>Prepare a batch for training.</p> <p>Manually move tensors to accelerator.device since we do not prepare our dataloaders with the accelerator.</p> PARAMETER DESCRIPTION <code>batch</code> <p>The batch to prepare.</p> <p> TYPE: <code>Iterable[Any]</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The prepared batch</p> <p> TYPE: <code>Any</code> </p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.train_epoch","title":"<code>train_epoch() -&gt; None</code>","text":"<p>Train the model for one epoch.</p>"},{"location":"API/common/#instanovo.common.AccelerateDeNovoTrainer.validate_epoch","title":"<code>validate_epoch(num_sanity_steps: int | None = None, calculate_metrics: bool = True) -&gt; None</code>","text":"<p>Validate for one epoch.</p>"},{"location":"API/common/#instanovo.common.NeptuneSummaryWriter","title":"<code>NeptuneSummaryWriter(log_dir: str, run: neptune.Run)</code>","text":"<p>               Bases: <code>SummaryWriter</code></p> <p>Combine SummaryWriter with NeptuneWriter.</p>"},{"location":"API/common/#instanovo.common.NeptuneSummaryWriter.run","title":"<code>run = run</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.NeptuneSummaryWriter.add_scalar","title":"<code>add_scalar(tag: str, scalar_value: float, global_step: int | float | None = None) -&gt; None</code>","text":"<p>Record scalar to tensorboard and Neptune.</p>"},{"location":"API/common/#instanovo.common.NeptuneSummaryWriter.add_text","title":"<code>add_text(tag: str, text_string: str, global_step: Optional[int] = None, walltime: Optional[float] = None) -&gt; None</code>","text":"<p>Record text to tensorboard and Neptune.</p>"},{"location":"API/common/#instanovo.common.NeptuneSummaryWriter.add_hparams","title":"<code>add_hparams(hparam_dict: dict, metric_dict: dict, hparam_domain_discrete: Optional[Dict[str, List[Any]]] = None, run_name: Optional[str] = None, global_step: Optional[int] = None) -&gt; None</code>","text":"<p>Add a set of hyperparameters to be compared in Neptune as for Tensorboard.</p>"},{"location":"API/common/#instanovo.common.Timer","title":"<code>Timer(total_steps: int | None = None)</code>","text":"<p>Timer for training and validation.</p>"},{"location":"API/common/#instanovo.common.Timer.start_time","title":"<code>start_time = time.time()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.Timer.total_steps","title":"<code>total_steps = total_steps</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.Timer.current_step","title":"<code>current_step = 0</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/#instanovo.common.Timer.start","title":"<code>start() -&gt; None</code>","text":"<p>Restart the timer.</p>"},{"location":"API/common/#instanovo.common.Timer.step","title":"<code>step() -&gt; None</code>","text":"<p>Step the timer.</p>"},{"location":"API/common/#instanovo.common.Timer.get_delta","title":"<code>get_delta() -&gt; float</code>","text":"<p>Get the time delta since the timer was started.</p>"},{"location":"API/common/#instanovo.common.Timer.get_eta","title":"<code>get_eta(current_step: int | None = None) -&gt; float</code>","text":"<p>Get the estimated time to completion.</p>"},{"location":"API/common/#instanovo.common.Timer.get_total_time","title":"<code>get_total_time() -&gt; float</code>","text":"<p>Get the total time expected to complete all steps.</p>"},{"location":"API/common/#instanovo.common.Timer.get_rate","title":"<code>get_rate(current_step: int | None = None) -&gt; float</code>","text":"<p>Get the rate of steps per second.</p>"},{"location":"API/common/#instanovo.common.Timer.get_step_time","title":"<code>get_step_time(current_step: int | None = None) -&gt; float</code>","text":"<p>Get the time per step.</p>"},{"location":"API/common/#instanovo.common.Timer.get_time_str","title":"<code>get_time_str() -&gt; str</code>","text":"<p>Get the time delta since the timer was started.</p>"},{"location":"API/common/#instanovo.common.Timer.get_eta_str","title":"<code>get_eta_str(current_step: int | None = None) -&gt; str</code>","text":"<p>Get the estimated time to completion.</p>"},{"location":"API/common/#instanovo.common.Timer.get_total_time_str","title":"<code>get_total_time_str() -&gt; str</code>","text":"<p>Get the total time expected to complete all steps.</p>"},{"location":"API/common/#instanovo.common.Timer.get_rate_str","title":"<code>get_rate_str(current_step: int | None = None) -&gt; str</code>","text":"<p>Get the rate of steps per second.</p>"},{"location":"API/common/#instanovo.common.Timer.get_step_time_rate_str","title":"<code>get_step_time_rate_str(current_step: int | None = None) -&gt; str</code>","text":"<p>Get the time per step.</p>"},{"location":"API/common/#instanovo.common.Timer.get_step_time_str","title":"<code>get_step_time_str(current_step: int | None = None) -&gt; str</code>","text":"<p>Get the time per step.</p>"},{"location":"API/common/#instanovo.common.TrainingState","title":"<code>TrainingState()</code>","text":"<p>Training state for tracking training progress.</p> <p>This class is used by Accelerate to save and load training state during checkpointing and resuming training runs. It tracks the current epoch and global step of training.</p> <p>Initialize training state with zeroed counters.</p>"},{"location":"API/common/#instanovo.common.TrainingState.global_step","title":"<code>global_step: int</code>  <code>property</code>","text":"<p>Get the current global step.</p>"},{"location":"API/common/#instanovo.common.TrainingState.epoch","title":"<code>epoch: int</code>  <code>property</code>","text":"<p>Get the current epoch.</p>"},{"location":"API/common/#instanovo.common.TrainingState.state_dict","title":"<code>state_dict() -&gt; dict[str, Any]</code>","text":"<p>Get the state dictionary for saving.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing the current training state.</p>"},{"location":"API/common/#instanovo.common.TrainingState.load_state_dict","title":"<code>load_state_dict(state_dict: dict[str, Any]) -&gt; None</code>","text":"<p>Load state from a dictionary.</p> PARAMETER DESCRIPTION <code>state_dict</code> <p>Dictionary containing the training state to load.</p> <p> TYPE: <code>dict[str, Any]</code> </p>"},{"location":"API/common/#instanovo.common.TrainingState.step","title":"<code>step() -&gt; None</code>","text":"<p>Step the global step.</p>"},{"location":"API/common/#instanovo.common.TrainingState.step_epoch","title":"<code>step_epoch() -&gt; None</code>","text":"<p>Step the epoch.</p>"},{"location":"API/common/#instanovo.common.TrainingState.unstep_epoch","title":"<code>unstep_epoch() -&gt; None</code>","text":"<p>Unstep the epoch.</p>"},{"location":"API/common/dataset/","title":"Dataset","text":""},{"location":"API/common/dataset/#instanovo.common.dataset","title":"<code>dataset</code>","text":""},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor","title":"<code>DataProcessor(metadata_columns: list[str] | set[str] | None = None)</code>","text":"<p>Data processor abstract class.</p> <p>This class is used to process the data before it is used in the model. It is designed to be used with the <code>Dataset</code> class from the HuggingFace <code>datasets</code> library.</p> <p>It includes two main methods: - <code>process_row</code>: Processes a row of data. - <code>collate_fn</code>: Collates a batch of data. To be passed to the <code>DataLoader</code> class.</p> <p>Additionally, it includes a way to pass metadata columns that will be kept after processing a dataset. These metadata columns will also bypass the <code>collate_fn</code>.</p> <p>Initialize the data processor.</p> PARAMETER DESCRIPTION <code>metadata_columns</code> <p>The metadata columns to add to the expected columns.</p> <p> TYPE: <code>list[str] | set[str] | None</code> DEFAULT: <code>None</code> </p>"},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor.metadata_columns","title":"<code>metadata_columns: set[str]</code>  <code>property</code>","text":"<p>Get the metadata columns.</p> <p>These columns are kept after processing a dataset.</p> RETURNS DESCRIPTION <code>set[str]</code> <p>list[str]: The metadata columns.</p>"},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor.process_row","title":"<code>process_row(row: dict[str, Any]) -&gt; dict[str, Any]</code>  <code>abstractmethod</code>","text":"<p>Process a single row of data.</p> PARAMETER DESCRIPTION <code>row</code> <p>The row of data to process in dict format.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: The processed row with resulting columns.</p>"},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor.process_dataset","title":"<code>process_dataset(dataset: Dataset, return_format: str | None = 'torch') -&gt; Dataset</code>","text":"<p>Process a dataset by mapping the <code>process_row</code> method.</p> <p>The resulting dataset has the columns expected by the <code>collate_fn</code> method.</p> PARAMETER DESCRIPTION <code>dataset</code> <p>The dataset to process.</p> <p> TYPE: <code>Dataset</code> </p> <code>return_format</code> <p>The format to return the dataset in. Default is \"torch\".</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>'torch'</code> </p> RETURNS DESCRIPTION <code>Dataset</code> <p>The processed dataset.</p> <p> TYPE: <code>Dataset</code> </p>"},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor.collate_fn","title":"<code>collate_fn(batch: list[dict[str, Any]]) -&gt; dict[str, Any]</code>","text":"<p>Collate a batch.</p> <p>Metadata columns are added after collation.</p> PARAMETER DESCRIPTION <code>batch</code> <p>The batch to collate.</p> <p> TYPE: <code>list[dict[str, Any]]</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: The collated batch with metadata.</p>"},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor.get_expected_columns","title":"<code>get_expected_columns() -&gt; list[str]</code>","text":"<p>Get the expected columns to be kept in the dataset after processing.</p> <p>These columns are expected by the <code>collate_fn</code> method and include both data and metadata columns.</p> RETURNS DESCRIPTION <code>list[str]</code> <p>list[str]: The expected columns.</p>"},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor.add_metadata_columns","title":"<code>add_metadata_columns(columns: list[str] | set[str]) -&gt; None</code>","text":"<p>Add expected metadata columns.</p> PARAMETER DESCRIPTION <code>columns</code> <p>The columns to add.</p> <p> TYPE: <code>list[str] | set[str]</code> </p>"},{"location":"API/common/dataset/#instanovo.common.dataset.DataProcessor.remove_modifications","title":"<code>remove_modifications(peptide: str, replace_isoleucine_with_leucine: bool = True) -&gt; str</code>  <code>staticmethod</code>","text":"<p>Remove modifications and optionally replace Isoleucine with Leucine.</p> PARAMETER DESCRIPTION <code>peptide</code> <p>The peptide to remove modifications from.</p> <p> TYPE: <code>str</code> </p> <code>replace_isoleucine_with_leucine</code> <p>Whether to replace Isoleucine with Leucine.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The peptide with modifications removed.</p> <p> TYPE: <code>str</code> </p>"},{"location":"API/common/predictor/","title":"Predictor","text":""},{"location":"API/common/predictor/#instanovo.common.predictor","title":"<code>predictor</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor","title":"<code>AccelerateDeNovoPredictor(config: DictConfig)</code>","text":"<p>Predictor class that uses the Accelerate library.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.s3","title":"<code>s3: S3FileHandler</code>  <code>property</code>","text":"<p>Get the S3 file handler.</p> RETURNS DESCRIPTION <code>S3FileHandler</code> <p>The S3 file handler</p> <p> TYPE: <code>S3FileHandler</code> </p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.config","title":"<code>config = config</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.targets","title":"<code>targets: list | None = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.output_path","title":"<code>output_path = self.config.get('output_path', None)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.pred_df","title":"<code>pred_df: pd.DataFrame | None = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.results_dict","title":"<code>results_dict: dict | None = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.prediction_tokenised_col","title":"<code>prediction_tokenised_col = self.config.get('prediction_tokenised_col', 'predictions_tokenised')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.prediction_col","title":"<code>prediction_col = self.config.get('prediction_col', 'predictions')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.log_probs_col","title":"<code>log_probs_col = self.config.get('log_probs_col', 'log_probs')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.token_log_probs_col","title":"<code>token_log_probs_col = self.config.get('token_log_probs_col', 'token_log_probs')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.save_encoder_outputs","title":"<code>save_encoder_outputs = config.get('save_encoder_outputs', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.encoder_output_path","title":"<code>encoder_output_path = config.get('encoder_output_path', None)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.encoder_output_reduction","title":"<code>encoder_output_reduction = config.get('encoder_output_reduction', 'mean')</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.accelerator","title":"<code>accelerator = self.setup_accelerator()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.denovo","title":"<code>denovo = self.config.get('denovo', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.model","title":"<code>model = self.model.eval()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.residue_set","title":"<code>residue_set = self.model.residue_set</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.test_dataset","title":"<code>test_dataset = self.load_dataset()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.test_dataloader","title":"<code>test_dataloader = self.build_dataloader(self.test_dataset)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.decoder","title":"<code>decoder = self.setup_decoder()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.metrics","title":"<code>metrics = self.setup_metrics()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.running_loss","title":"<code>running_loss = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.steps_per_inference","title":"<code>steps_per_inference = len(self.test_dataloader)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.load_model","title":"<code>load_model() -&gt; Tuple[nn.Module, DictConfig]</code>  <code>abstractmethod</code>","text":"<p>Load the model.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>  <code>abstractmethod</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.setup_data_processor","title":"<code>setup_data_processor() -&gt; DataProcessor</code>  <code>abstractmethod</code>","text":"<p>Setup the data processor.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; dict[str, Any]</code>  <code>abstractmethod</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.postprocess_dataset","title":"<code>postprocess_dataset(dataset: Dataset) -&gt; Dataset</code>","text":"<p>Postprocess the dataset.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.load_dataset","title":"<code>load_dataset() -&gt; Dataset</code>","text":"<p>Load the test dataset.</p> RETURNS DESCRIPTION <code>Dataset</code> <p>The test dataset</p> <p> TYPE: <code>Dataset</code> </p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.print_sample_batch","title":"<code>print_sample_batch() -&gt; None</code>","text":"<p>Print a sample batch of the training data.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.setup_metrics","title":"<code>setup_metrics() -&gt; Metrics</code>","text":"<p>Setup the metrics.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.setup_accelerator","title":"<code>setup_accelerator() -&gt; Accelerator</code>","text":"<p>Setup the accelerator.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.build_dataloader","title":"<code>build_dataloader(test_dataset: Dataset) -&gt; torch.utils.data.DataLoader</code>","text":"<p>Setup the dataloaders.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.predict","title":"<code>predict() -&gt; pd.DataFrame</code>","text":"<p>Predict the test dataset.</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.predictions_to_df","title":"<code>predictions_to_df(predictions: dict[str, list]) -&gt; pd.DataFrame</code>","text":"<p>Convert the predictions to a pandas DataFrame.</p> PARAMETER DESCRIPTION <code>predictions</code> <p>The predictions dictionary</p> <p> TYPE: <code>dict[str, list]</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: The predictions dataframe</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.postprocess_predictions","title":"<code>postprocess_predictions(pred_df: pd.DataFrame) -&gt; pd.DataFrame</code>","text":"<p>Postprocess the predictions.</p> <p>Optionally, this can be used to modify the predictions, eg. ensembling. By default, this does nothing.</p> PARAMETER DESCRIPTION <code>pred_df</code> <p>The predictions dataframe</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>DataFrame</code> <p>pd.DataFrame: The postprocessed predictions dataframe</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.calculate_metrics","title":"<code>calculate_metrics(pred_df: pd.DataFrame) -&gt; dict[str, Any] | None</code>","text":"<p>Calculate the metrics.</p> PARAMETER DESCRIPTION <code>pred_df</code> <p>The predictions dataframe</p> <p> TYPE: <code>DataFrame</code> </p> RETURNS DESCRIPTION <code>dict[str, Any] | None</code> <p>dict[str, Any] | None: The results dictionary containing the metrics</p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.save_predictions","title":"<code>save_predictions(pred_df: pd.DataFrame, results_dict: dict[str, list] | None = None) -&gt; None</code>","text":"<p>Save the predictions to a file.</p> PARAMETER DESCRIPTION <code>pred_df</code> <p>The predictions dataframe</p> <p> TYPE: <code>DataFrame</code> </p> <code>results_dict</code> <p>The results dictionary containing the metrics</p> <p> TYPE: <code>dict[str, list] | None</code> DEFAULT: <code>None</code> </p>"},{"location":"API/common/predictor/#instanovo.common.predictor.AccelerateDeNovoPredictor.save_encoder_outputs_to_parquet","title":"<code>save_encoder_outputs_to_parquet(spectrum_ids: list[str], encoder_outputs: list[np.ndarray]) -&gt; None</code>","text":"<p>Save the encoder outputs to a file.</p> PARAMETER DESCRIPTION <code>encoder_outputs</code> <p>The encoder outputs</p> <p> TYPE: <code>list[ndarray]</code> </p> <code>spectrum_ids</code> <p>The spectrum ids</p> <p> TYPE: <code>list[str]</code> </p>"},{"location":"API/common/scheduler/","title":"Scheduler","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler","title":"<code>scheduler</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler","title":"<code>FinetuneScheduler(model_state_dict: dict, config: DictConfig, steps_per_epoch: int | None = None)</code>","text":"<p>Scheduler for unfreezing parameters of a model.</p> PARAMETER DESCRIPTION <code>model_state_dict</code> <p>The state dictionary of the model.</p> <p> TYPE: <code>dict</code> </p> <code>config</code> <p>The configuration for the scheduler.</p> <p> TYPE: <code>DictConfig</code> </p> <code>steps_per_epoch</code> <p>The number of steps per epoch.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler.model_state_dict","title":"<code>model_state_dict = model_state_dict</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler.config","title":"<code>config = config</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler.steps_per_epoch","title":"<code>steps_per_epoch = steps_per_epoch</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler.is_verbose","title":"<code>is_verbose = self.config.get('verbose', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler.schedule","title":"<code>schedule = self._get_schedule()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler.next_phase","title":"<code>next_phase: dict[str, Any] | None = self.schedule.pop(0)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.FinetuneScheduler.step","title":"<code>step(global_step: int) -&gt; None</code>","text":"<p>Step the unfreezing scheduler.</p> PARAMETER DESCRIPTION <code>global_step</code> <p>The global step of the model.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.WarmupScheduler","title":"<code>WarmupScheduler(optimizer: torch.optim.Optimizer, warmup: int)</code>","text":"<p>               Bases: <code>_LRScheduler</code></p> <p>Linear warmup scheduler.</p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.WarmupScheduler.warmup","title":"<code>warmup = warmup</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/scheduler/#instanovo.common.scheduler.WarmupScheduler.get_lr","title":"<code>get_lr() -&gt; list[float]</code>","text":"<p>Get the learning rate at the current step.</p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.WarmupScheduler.get_lr_factor","title":"<code>get_lr_factor(epoch: int) -&gt; float</code>","text":"<p>Get the LR factor at the current step.</p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.CosineWarmupScheduler","title":"<code>CosineWarmupScheduler(optimizer: torch.optim.Optimizer, warmup: int, max_iters: int)</code>","text":"<p>               Bases: <code>_LRScheduler</code></p> <p>Learning rate scheduler with linear warm up followed by cosine shaped decay.</p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.CosineWarmupScheduler--parameters","title":"Parameters","text":"<p>optimizer : torch.optim.Optimizer     Optimizer object. warmup : int     The number of warm up iterations. max_iters : int     The total number of iterations.</p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.CosineWarmupScheduler.get_lr","title":"<code>get_lr() -&gt; list[float]</code>","text":"<p>Get the learning rate at the current step.</p>"},{"location":"API/common/scheduler/#instanovo.common.scheduler.CosineWarmupScheduler.get_lr_factor","title":"<code>get_lr_factor(epoch: int) -&gt; float</code>","text":"<p>Get the LR factor at the current step.</p>"},{"location":"API/common/trainer/","title":"Trainer","text":""},{"location":"API/common/trainer/#instanovo.common.trainer","title":"<code>trainer</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer","title":"<code>AccelerateDeNovoTrainer(config: DictConfig)</code>","text":"<p>Trainer class that uses the Accelerate library.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.run_id","title":"<code>run_id: str</code>  <code>property</code>","text":"<p>Get the run ID.</p> RETURNS DESCRIPTION <code>str</code> <p>The run ID</p> <p> TYPE: <code>str</code> </p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.s3","title":"<code>s3: S3FileHandler</code>  <code>property</code>","text":"<p>Get the S3 file handler.</p> RETURNS DESCRIPTION <code>S3FileHandler</code> <p>The S3 file handler</p> <p> TYPE: <code>S3FileHandler</code> </p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.global_step","title":"<code>global_step: int</code>  <code>property</code>","text":"<p>Get the current global training step.</p> <p>This represents the total number of training steps across all epochs.</p> RETURNS DESCRIPTION <code>int</code> <p>The current global step number</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.epoch","title":"<code>epoch: int</code>  <code>property</code>","text":"<p>Get the current training epoch.</p> <p>This represents the current epoch number in the training process.</p> RETURNS DESCRIPTION <code>int</code> <p>The current epoch number</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.training_state","title":"<code>training_state: TrainingState</code>  <code>property</code>","text":"<p>Get the training state.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.config","title":"<code>config = config</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.enable_verbose_logging","title":"<code>enable_verbose_logging = self.config.get('enable_verbose_logging', True)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.accelerator","title":"<code>accelerator = self.setup_accelerator()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.residue_set","title":"<code>residue_set = ResidueSet(residue_masses=(self.config.residues.get('residues')), residue_remapping=(self.config.dataset.get('residue_remapping', None)))</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.model","title":"<code>model = self.setup_model()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.optimizer","title":"<code>optimizer = self.setup_optimizer()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.lr_scheduler","title":"<code>lr_scheduler = self.setup_scheduler()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.decoder","title":"<code>decoder = self.setup_decoder()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.metrics","title":"<code>metrics = self.setup_metrics()</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.running_loss","title":"<code>running_loss = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.total_steps","title":"<code>total_steps = self.config.get('training_steps', 2500000)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.finetune_scheduler","title":"<code>finetune_scheduler: FinetuneScheduler | None = FinetuneScheduler(self.model.state_dict(), self.config.get('finetune'))</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.steps_per_validation","title":"<code>steps_per_validation = self.config.get('validation_interval', 100000)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.steps_per_checkpoint","title":"<code>steps_per_checkpoint = self.config.get('checkpoint_interval', 100000)</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.last_validation_metric","title":"<code>last_validation_metric = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.best_checkpoint_metric","title":"<code>best_checkpoint_metric = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_model","title":"<code>setup_model() -&gt; nn.Module</code>  <code>abstractmethod</code>","text":"<p>Setup the model.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_optimizer","title":"<code>setup_optimizer() -&gt; torch.optim.Optimizer</code>  <code>abstractmethod</code>","text":"<p>Setup the optimizer.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>  <code>abstractmethod</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_data_processors","title":"<code>setup_data_processors() -&gt; tuple[DataProcessor, DataProcessor]</code>  <code>abstractmethod</code>","text":"<p>Setup the data processor.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.save_model","title":"<code>save_model(is_best_checkpoint: bool = False) -&gt; None</code>  <code>abstractmethod</code>","text":"<p>Save the model.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.forward","title":"<code>forward(batch: Any) -&gt; tuple[torch.Tensor, dict[str, torch.Tensor]]</code>  <code>abstractmethod</code>","text":"<p>Forward pass for the model to calculate loss.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; tuple[list[str] | list[list[str]], list[str] | list[list[str]]]</code>  <code>abstractmethod</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.convert_interval_to_steps","title":"<code>convert_interval_to_steps(interval: float | int, steps_per_epoch: int) -&gt; int</code>  <code>staticmethod</code>","text":"<p>Convert an interval to steps.</p> PARAMETER DESCRIPTION <code>interval</code> <p>The interval to convert.</p> <p> TYPE: <code>float | int</code> </p> <code>steps_per_epoch</code> <p>The number of steps per epoch.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>int</code> <p>The number of steps.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.log_if_verbose","title":"<code>log_if_verbose(message: str, level: str = 'info') -&gt; None</code>","text":"<p>Log a message if verbose logging is enabled.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_metrics","title":"<code>setup_metrics() -&gt; Metrics</code>","text":"<p>Setup the metrics.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_accelerator","title":"<code>setup_accelerator() -&gt; Accelerator</code>","text":"<p>Setup the accelerator.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.build_dataloaders","title":"<code>build_dataloaders(train_dataset: Dataset, valid_dataset: Dataset) -&gt; tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]</code>","text":"<p>Setup the dataloaders.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_scheduler","title":"<code>setup_scheduler() -&gt; torch.optim.lr_scheduler.LRScheduler</code>","text":"<p>Setup the learning rate scheduler.</p> RETURNS DESCRIPTION <code>LRScheduler</code> <p>torch.optim.lr_scheduler.LRScheduler: The learning rate scheduler</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_neptune","title":"<code>setup_neptune() -&gt; None</code>","text":"<p>Setup the neptune.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.setup_tensorboard","title":"<code>setup_tensorboard() -&gt; None</code>","text":"<p>Setup the tensorboard.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.load_datasets","title":"<code>load_datasets() -&gt; tuple[Dataset, Dataset, int, int]</code>","text":"<p>Load the training and validation datasets.</p> RETURNS DESCRIPTION <code>tuple[Dataset, Dataset, int, int]</code> <p>tuple[SpectrumDataFrame, SpectrumDataFrame]: The training and validation datasets</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.print_sample_batch","title":"<code>print_sample_batch() -&gt; None</code>","text":"<p>Print a sample batch of the training data.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.save_accelerator_state","title":"<code>save_accelerator_state(is_best_checkpoint: bool = False) -&gt; None</code>","text":"<p>Save the accelerator state.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.check_if_best_checkpoint","title":"<code>check_if_best_checkpoint() -&gt; bool</code>","text":"<p>Check if the last validation metric is the best metric.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.load_accelerator_state","title":"<code>load_accelerator_state() -&gt; None</code>","text":"<p>Load the accelerator state.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.load_model_state","title":"<code>load_model_state() -&gt; None</code>","text":"<p>Load the model state.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.update_model_state","title":"<code>update_model_state(model_state: dict[str, torch.Tensor], model_config: DictConfig) -&gt; dict[str, torch.Tensor]</code>","text":"<p>Update the model state.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.update_vocab","title":"<code>update_vocab(model_state: dict[str, torch.Tensor]) -&gt; dict[str, torch.Tensor]</code>","text":"<p>Update the vocabulary of the model.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.train","title":"<code>train() -&gt; None</code>","text":"<p>Train the model.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.prepare_batch","title":"<code>prepare_batch(batch: Iterable[Any]) -&gt; Any</code>","text":"<p>Prepare a batch for training.</p> <p>Manually move tensors to accelerator.device since we do not prepare our dataloaders with the accelerator.</p> PARAMETER DESCRIPTION <code>batch</code> <p>The batch to prepare.</p> <p> TYPE: <code>Iterable[Any]</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The prepared batch</p> <p> TYPE: <code>Any</code> </p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.train_epoch","title":"<code>train_epoch() -&gt; None</code>","text":"<p>Train the model for one epoch.</p>"},{"location":"API/common/trainer/#instanovo.common.trainer.AccelerateDeNovoTrainer.validate_epoch","title":"<code>validate_epoch(num_sanity_steps: int | None = None, calculate_metrics: bool = True) -&gt; None</code>","text":"<p>Validate for one epoch.</p>"},{"location":"API/diffusion/","title":"Index","text":""},{"location":"API/diffusion/#instanovo.diffusion","title":"<code>diffusion</code>","text":""},{"location":"API/diffusion/layers/","title":"Layers","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers","title":"<code>layers</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder","title":"<code>TransformerEncoder(dim_model: int = 128, n_head: int = 8, dim_feedforward: int = 1024, n_layers: int = 1, dropout: float = 0.0, use_flash_attention: bool = False, conv_peak_encoder: bool = False, peak_embedding_dtype: torch.dtype | str = torch.float64)</code>","text":"<p>               Bases: <code>Module</code></p> <p>A Transformer encoder for input mass spectra.</p>"},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder--parameters","title":"Parameters","text":"<p>dim_model : int, optional     The latent dimensionality to represent peaks in the mass spectrum. n_head : int, optional     The number of attention heads in each layer. <code>dim_model</code> must be     divisible by <code>n_head</code>. dim_feedforward : int, optional     The dimensionality of the fully connected layers in the Transformer     layers of the model. n_layers : int, optional     The number of Transformer layers. dropout : float, optional     The dropout probability for all layers.</p> <p>Initialise a TransformerEncoder.</p>"},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.use_flash_attention","title":"<code>use_flash_attention = use_flash_attention</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.conv_peak_encoder","title":"<code>conv_peak_encoder = conv_peak_encoder</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.latent_spectrum","title":"<code>latent_spectrum = nn.Parameter(torch.randn(1, 1, dim_model))</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.pad_spectrum","title":"<code>pad_spectrum = nn.Parameter(torch.randn(1, 1, dim_model))</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.peak_encoder","title":"<code>peak_encoder = MultiScalePeakEmbedding(dim_model, dropout=dropout, float_dtype=peak_embedding_dtype)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.conv_encoder","title":"<code>conv_encoder = ConvPeakEmbedding(dim_model, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.encoder","title":"<code>encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.forward","title":"<code>forward(x: Float[Spectrum, ' batch'], x_mask: Optional[Bool[SpectrumMask, ' batch']] = None) -&gt; Tuple[Float[SpectrumEmbedding, ' batch'], Bool[SpectrumMask, ' batch']]</code>","text":"<p>The forward pass.</p>"},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.forward--parameters","title":"Parameters","text":"<p>x : torch.Tensor of shape (n_spectra, n_peaks, 2)     The spectra to embed. Axis 0 represents a mass spectrum, axis 1     contains the peaks in the mass spectrum, and axis 2 is essentially     a 2-tuple specifying the m/z-intensity pair for each peak. These     should be zero-padded, such that all of the spectra in the batch     are the same length. x_mask: torch.Tensor     Spectra padding mask, True for padded indices, bool Tensor (batch, n_peaks)</p>"},{"location":"API/diffusion/layers/#instanovo.diffusion.layers.TransformerEncoder.forward--returns","title":"Returns:","text":"<p>latent : torch.Tensor of shape (n_spectra, n_peaks + 1, dim_model)     The latent representations for the spectrum and each of its     peaks. mem_mask : torch.Tensor     The memory mask specifying which elements were padding in X.</p>"},{"location":"API/diffusion/model/","title":"Model","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model","title":"<code>model</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransformer","title":"<code>MassSpectrumTransformer</code>","text":"<p>               Bases: <code>Pogfuse</code></p> <p>A transformer model specialised for encoding mass spectra.</p>"},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransformer.forward","title":"<code>forward(x: Float[PeptideEmbedding, ' batch'], t_emb: Float[TimeEmbedding, ' batch'], precursor_emb: Float[Tensor, '...'], cond_emb: Optional[Float[SpectrumEmbedding, ' batch']] = None, x_padding_mask: Optional[Bool[PeptideMask, ' batch']] = None, cond_padding_mask: Optional[Bool[SpectrumMask, ' batch']] = None, pos_bias: Optional[Float[Tensor, '...']] = None) -&gt; Float[Tensor, 'batch token embedding']</code>","text":"<p>Compute encodings with the model.</p> <p>Forward with <code>x</code> (bs, seq_len, dim), summing <code>t_emb</code> (bs, dim) before the transformer layer, and appending <code>conditioning_emb</code> (bs, seq_len2, dim) to the key/value pairs of the attention. Also <code>pooled_conv_emb</code> (bs, 1, dim) is summed with the timestep embeddings</p> <p>Optionally specify key/value padding for input <code>x</code> with <code>x_padding_mask</code> (bs, seq_len), and optionally specify key/value padding mask for conditional embedding with <code>cond_padding_mask</code> (bs, seq_len2). By default no padding is used. Good idea to use cond padding but not x padding.</p> <p><code>pos_bias</code> is positional bias for wavlm-style attention gated relative position bias.</p> <p>Returns <code>x</code> of same shape (bs, seq_len, dim)</p>"},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion","title":"<code>MassSpectrumTransFusion(cfg: DictConfig, max_transcript_len: int = 200)</code>","text":"<p>               Bases: <code>TransFusion</code></p> <p>Diffusion reconstruction model conditioned on mass spectra.</p>"},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.layers","title":"<code>layers = nn.ModuleList(layers)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.conditioning_pos_emb","title":"<code>conditioning_pos_emb = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.encoder","title":"<code>encoder = TransformerEncoder(dim_model=(cfg.dim), n_head=(cfg.nheads), dim_feedforward=(cfg.dim_feedforward), n_layers=(cfg.get('encoder_layers', cfg.get('layers', None))), dropout=(cfg.dropout), use_flash_attention=(cfg.get('use_flash_attention', False)), conv_peak_encoder=(cfg.get('conv_peak_encoder', False)), peak_embedding_dtype=(cfg.get('peak_embedding_dtype', torch.float64)))</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.charge_encoder","title":"<code>charge_encoder = torch.nn.Embedding(cfg.max_charge, cfg.dim)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.peak_encoder","title":"<code>peak_encoder = self.encoder.peak_encoder</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.cache_spectra","title":"<code>cache_spectra = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.cache_cond_emb","title":"<code>cache_cond_emb = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.cache_cond_padding_mask","title":"<code>cache_cond_padding_mask = None</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/model/#instanovo.diffusion.model.MassSpectrumTransFusion.forward","title":"<code>forward(x: Integer[Peptide, ' batch'], t: Integer[TimeStep, ' batch'], spectra: Float[Spectrum, ' batch'], spectra_padding_mask: Bool[SpectrumMask, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], x_padding_mask: Optional[Bool[PeptideMask, ' batch']] = None) -&gt; Float[ResidueLogits, 'batch token']</code>","text":"<p>Transformer with conditioning cross attention.</p> <ul> <li><code>x</code>: (bs, seq_len) long tensor of character indices     or (bs, seq_len, vocab_size) if cfg.diffusion_type == 'continuous'</li> <li><code>t</code>: (bs, ) long tensor of timestep indices</li> <li><code>cond_emb</code>: (bs, seq_len2, cond_emb_dim) if using wavlm encoder, else (bs, T)</li> <li><code>x_padding_mask</code>: (bs, seq_len) if using wavlm encoder, else (bs, T)</li> <li><code>cond_padding_mask</code>: (bs, seq_len2)</li> </ul> <p>Returns logits (bs, seq_len, vocab_size)</p>"},{"location":"API/diffusion/multinomial_diffusion/","title":"Multinomial diffusion","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion","title":"<code>multinomial_diffusion</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.MODEL_TYPE","title":"<code>MODEL_TYPE = 'diffusion'</code>  <code>module-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus","title":"<code>InstaNovoPlus(config: DictConfig, transition_model: nn.Module, diffusion_schedule: Float[torch.Tensor, ' time'], residue_set: ResidueSet)</code>","text":"<p>               Bases: <code>Module</code></p> <p>This class implements Multinomial Diffusion as described in Hoogeboom et al. 2021.</p> PARAMETER DESCRIPTION <code>config</code> <p>The model configuration. This should have keys:     - 'name': the model name identifier.     - 'time_steps': the number of time steps in the diffusion process     - 'max_length': the maximum sequence for the model     - 'device': the device where the <code>Pytorch</code> model should be                 loaded e.g. <code>cpu</code>, <code>cuda:0</code> etc.     - 'vocab_size': the number of residues in the vocabulary     - 'transition_model': the <code>DictConfig</code> for the transition model</p> <p>This information is necessary for saving and loading the model.</p> <p> TYPE: <code>DictConfig</code> </p> <code>transition_model</code> <p>The model that predictions the initial sequence given the sequence sampled the current time step and the sequence sampled the previous time step. This is just a sequence tagging model.</p> <p> TYPE: <code>Module</code> </p> <code>diffusion_schedule</code> <p>The sequence of diffusion probabilities. Note that <code>diffusion_schedule[t]</code> is \\alpha_t in the paper's terminology, not \\beta_t.</p> <p> TYPE: <code>FloatTensor[time_steps]</code> </p> <code>residue_set</code> <p>The residue vocabulary. This holds a mapping between residues and indices and residue masses.</p> <p> TYPE: <code>ResidueSet</code> </p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.config_path","title":"<code>config_path: str</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.schedule_path","title":"<code>schedule_path: str</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.checkpoint_path","title":"<code>checkpoint_path: str</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.config","title":"<code>config = config</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.time_steps","title":"<code>time_steps = config.time_steps</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.residue_set","title":"<code>residue_set = residue_set</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.transition_model","title":"<code>transition_model = transition_model</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.save","title":"<code>save(path: str, ckpt_details: str, overwrite: bool = False, temp_dir: str | None = None, use_legacy_format: bool = False) -&gt; None</code>","text":"<p>Save the model to a directory.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to the base directory where the model is saved. The model is saved in a subdirectory with the model's name identifier.</p> <p> TYPE: <code>str</code> </p> <code>ckpt_details</code> <p>Additional checkpoint details to include in model save directory.</p> <p> TYPE: <code>str</code> </p> <code>overwrite</code> <p>Whether to overwrite the directory if one already exists for the model. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>temp_dir</code> <p>Temporary directory to save intermediate files to. Defaults to None.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>use_legacy_format</code> <p>Whether to save the model in the legacy folder format. If False, saves as a single file. Defaults to False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RAISES DESCRIPTION <code>FileExistsError</code> <p>If <code>overwrite</code> is <code>False</code> and a directory already exists for the model identifier.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.load","title":"<code>load(path: str, override_config: DictConfig | dict | None = None) -&gt; Tuple[InstaNovoPlus, DictConfig]</code>  <code>classmethod</code>","text":"<p>Load a saved model.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to model checkpoint file or directory where model is saved.</p> <p> TYPE: <code>str</code> </p> <code>override_config</code> <p>Optional override config values with a DictConfig or dict, defaults to None.</p> <p> TYPE: <code>DictConfig | dict | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>(InstaNovoPlus, DictConfig)</code> <p>The loaded model and config.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.get_pretrained","title":"<code>get_pretrained() -&gt; list[str]</code>  <code>staticmethod</code>","text":"<p>Get a list of pretrained model ids.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.from_pretrained","title":"<code>from_pretrained(model_id: str, override_config: DictConfig | dict | None = None) -&gt; Tuple['InstaNovoPlus', 'DictConfig']</code>  <code>classmethod</code>","text":"<p>Download and load by model id or model path.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.prepare_fine_tuning","title":"<code>prepare_fine_tuning(residue_set: ResidueSet) -&gt; None</code>","text":"<p>Prepare a model for fine-tuning on a dataset with a new residue vocabulary.</p> PARAMETER DESCRIPTION <code>residue_set</code> <p>The residue vocabulary for the new dataset.</p> <p> TYPE: <code>ResidueSet</code> </p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.mixture_categorical","title":"<code>mixture_categorical(log_x: Float[ResidueLogProbabilities, 'batch token'], log_alpha: float, log_alpha_complement: float) -&gt; Float[ResidueLogProbabilities, 'batch token']</code>","text":"<p>A categorical mixture between a base distribution and a uniform distribution.</p> PARAMETER DESCRIPTION <code>log_x</code> <p>The base distribution.</p> <p> TYPE: <code>FloatTensor[..., num_classes]</code> </p> <code>log_alpha</code> <p>The log of the mixture weight.</p> <p> TYPE: <code>float</code> </p> <code>log_alpha_complement</code> <p>The log of 1 minus the mixture weight.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>Float[ResidueLogProbabilities, 'batch token']</code> <p>torch.FloatTensor[..., num_classes]: The log-probabilities of the mixture.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.forward","title":"<code>forward(log_x_t: Float[ResidueLogProbabilities, 'batch token'], log_x_0: Float[ResidueLogProbabilities, 'batch token'], t: Integer[TimeStep, ' batch']) -&gt; Float[ResidueLogProbabilities, 'batch token']</code>","text":"<p>Calculate the log-posterior of <code>t-1</code>-th process values given the 0-th and t-th values.</p> PARAMETER DESCRIPTION <code>log_x_t</code> <p>The log one-hot representation of the process values at the <code>t</code>-th time step.</p> <p> TYPE: <code>FloatTensor[batch_size, sequence_length, num_classes]</code> </p> <code>log_x_0</code> <p>The log one-hot representation of the process values at the <code>t</code>-th time step.</p> <p> TYPE: <code>FloatTensor[batch_size, sequence_length, num_classes]</code> </p> <code>t</code> <p>The time step.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Float[ResidueLogProbabilities, 'batch token']</code> <p>torch.FloatTensor[batch_size, sequence_length, num_classes]: The log-posterior probabilities of the process values at the <code>t-1</code>-th time step given the values at the 0-th and <code>t</code>-th time step i.e. q( x_{t-1} | x_{t}, x_0 ).</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.InstaNovoPlus.reverse_distribution","title":"<code>reverse_distribution(x_t: Integer[Peptide, 'batch token'], time: Integer[TimeStep, ' batch'], **kwargs: dict) -&gt; Float[ResidueLogProbabilities, 'batch token']</code>","text":"<p>Calculate the reverse transition distribution of the diffusion process.</p> PARAMETER DESCRIPTION <code>x_t</code> <p>The values at the <code>t</code>-th time step of the reverse process.</p> <p> TYPE: <code>LongTensor[batch_size, sequence_length]</code> </p> <code>time</code> <p>The time step.</p> <p> TYPE: <code>int</code> </p> RETURNS DESCRIPTION <code>Float[ResidueLogProbabilities, 'batch token']</code> <p>torch.FloatTensor[batch_size, sequence_length, num_classes]: The log-probabilities of values for the <code>t-1</code>-th time step given values at the <code>t</code>-th time step i.e. <code>log p( x_{t-1} | x_{t} )</code>.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.DiffusionLoss","title":"<code>DiffusionLoss(model: InstaNovoPlus)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Holds logic for calculating the diffusion loss.</p> PARAMETER DESCRIPTION <code>model</code> <p>The multinomial diffusion class.</p> <p> TYPE: <code>InstaNovoPlus</code> </p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.DiffusionLoss.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.DiffusionLoss.base_model","title":"<code>base_model = model.module if hasattr(model, 'module') else model</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.DiffusionLoss.time_steps","title":"<code>time_steps = self.base_model.time_steps</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.DiffusionLoss.kl_divergence","title":"<code>kl_divergence(log_probs_first: Float[ResidueLogProbabilities, '...'], log_probs_second: Float[ResidueLogProbabilities, '...']) -&gt; Float[torch.Tensor, '...']</code>  <code>staticmethod</code>","text":"<p>Calculate the Kullback-Liebler divergence between two multinomial distributions.</p> PARAMETER DESCRIPTION <code>log_probs_first</code> <p>The log-probabilities of the base distribution.</p> <p> TYPE: <code>FloatTensor[..., num_classes]</code> </p> <code>log_probs_second</code> <p>The log-probabilities of the comparison distribution.</p> <p> TYPE: <code>FloatTensor[..., num_classes]</code> </p> RETURNS DESCRIPTION <code>Float[Tensor, '...']</code> <p>torch.FloatTensor[1]: The KL-divergence averaged over all but the final dimension.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.DiffusionLoss.forward","title":"<code>forward(x_0: Integer[Peptide, 'batch token'], **kwargs: dict) -&gt; Float[torch.Tensor, '1']</code>","text":"<p>Calculate a single Monte Carlo estimate of the multinomial diffusion loss (-ELBO).</p> PARAMETER DESCRIPTION <code>x_0</code> <p>A batch of padded sequences.</p> <p> TYPE: <code>LongTensor[batch_size, sequence_length]</code> </p> RETURNS DESCRIPTION <code>Float[Tensor, '1']</code> <p>torch.FloatTensor[1]: The loss estimate.</p>"},{"location":"API/diffusion/multinomial_diffusion/#instanovo.diffusion.multinomial_diffusion.cosine_beta_schedule","title":"<code>cosine_beta_schedule(timesteps: int, s: float = 0.008) -&gt; Float[torch.Tensor, ' time']</code>","text":"<p>Cosine schedule as proposed in https://arxiv.org/abs/2102.09672 .</p> <p>Returns alpha parameters, NOT Beta</p>"},{"location":"API/diffusion/predict/","title":"Predict","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict","title":"<code>predict</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CONFIG_PATH","title":"<code>CONFIG_PATH = Path(__file__).parent.parent / 'configs'</code>  <code>module-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor","title":"<code>DiffusionPredictor(config: DictConfig)</code>","text":"<p>               Bases: <code>AccelerateDeNovoPredictor</code></p> <p>Predictor for the InstaNovo+ model.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.refine","title":"<code>refine = config.get('refine', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.refine_all","title":"<code>refine_all = config.get('refine_all', True)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.refine_threshold","title":"<code>refine_threshold = np.log(config.get('refine_threshold', 0.9))</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.precursor_tolerance","title":"<code>precursor_tolerance = config.get('filter_precursor_ppm', 50)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.load_model","title":"<code>load_model() -&gt; Tuple[nn.Module, DictConfig]</code>","text":"<p>Setup the model.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.postprocess_dataset","title":"<code>postprocess_dataset(dataset: Dataset) -&gt; Dataset</code>","text":"<p>Load previous predictions for refinement.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.setup_data_processor","title":"<code>setup_data_processor() -&gt; DataProcessor</code>","text":"<p>Setup the data processor.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.DiffusionPredictor.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; dict[str, Any]</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor","title":"<code>CombinedPredictor(config: DictConfig)</code>","text":"<p>               Bases: <code>TransformerPredictor</code></p> <p>Predictor for the combined InstaNovo+ model.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.diffusion_load_model","title":"<code>diffusion_load_model = DiffusionPredictor.load_model</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.diffusion_get_predictions","title":"<code>diffusion_get_predictions = DiffusionPredictor.get_predictions</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.refine","title":"<code>refine = config.get('refine', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.refine_all","title":"<code>refine_all = config.get('refine_all', True)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.refine_threshold","title":"<code>refine_threshold = np.log(config.get('refine_threshold', 0.9))</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.precursor_tolerance","title":"<code>precursor_tolerance = config.get('filter_precursor_ppm', 50)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.diffusion_model","title":"<code>diffusion_model: nn.Module = self.accelerator.prepare(self.diffusion_model)</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.load_model","title":"<code>load_model() -&gt; Tuple[nn.Module, DictConfig]</code>","text":"<p>Setup the model.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/diffusion/predict/#instanovo.diffusion.predict.CombinedPredictor.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; dict[str, Any]</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/diffusion/train/","title":"Train","text":""},{"location":"API/diffusion/train/#instanovo.diffusion.train","title":"<code>train</code>","text":""},{"location":"API/diffusion/train/#instanovo.diffusion.train.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/diffusion/train/#instanovo.diffusion.train.CONFIG_PATH","title":"<code>CONFIG_PATH = Path(__file__).parent.parent / 'configs'</code>  <code>module-attribute</code>","text":""},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer","title":"<code>DiffusionTrainer(config: DictConfig)</code>","text":"<p>               Bases: <code>AccelerateDeNovoTrainer</code></p> <p>Trainer for the InstaNovo model.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.loss_fn","title":"<code>loss_fn = DiffusionLoss(model=(self.model))</code>  <code>instance-attribute</code>","text":""},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.setup_model","title":"<code>setup_model() -&gt; nn.Module</code>","text":"<p>Setup the model.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.setup_optimizer","title":"<code>setup_optimizer() -&gt; torch.optim.Optimizer</code>","text":"<p>Setup the optimizer.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.setup_data_processors","title":"<code>setup_data_processors() -&gt; tuple[DataProcessor, DataProcessor]</code>","text":"<p>Setup the datasets.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.add_checkpoint_state","title":"<code>add_checkpoint_state() -&gt; dict[str, Any]</code>","text":"<p>Add checkpoint state.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.save_model","title":"<code>save_model(is_best_checkpoint: bool = False) -&gt; None</code>","text":"<p>Save the model.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.update_vocab","title":"<code>update_vocab(model_state: dict[str, torch.Tensor]) -&gt; dict[str, torch.Tensor]</code>","text":"<p>Update the vocabulary of the model.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.update_model_state","title":"<code>update_model_state(model_state: dict[str, torch.Tensor], model_config: DictConfig) -&gt; dict[str, torch.Tensor]</code>","text":"<p>Update the model state.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.forward","title":"<code>forward(batch: Any) -&gt; tuple[torch.Tensor, dict[str, torch.Tensor]]</code>","text":"<p>Forward pass for the model to calculate loss.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.DiffusionTrainer.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; tuple[list[str] | list[list[str]], list[str] | list[list[str]]]</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/diffusion/train/#instanovo.diffusion.train.main","title":"<code>main(config: DictConfig) -&gt; None</code>","text":"<p>Train the model.</p>"},{"location":"API/inference/","title":"Index","text":""},{"location":"API/inference/#instanovo.inference","title":"<code>inference</code>","text":""},{"location":"API/inference/#instanovo.inference.__all__","title":"<code>__all__ = ['ScoredSequence', 'Decodable', 'Decoder', 'BeamSearchDecoder', 'GreedyDecoder', 'KnapsackBeamSearchDecoder', 'Knapsack']</code>  <code>module-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder","title":"<code>BeamSearchDecoder(model: Decodable, suppressed_residues: list[str] | None = None, mass_scale: int = MASS_SCALE, disable_terminal_residues_anywhere: bool = True, keep_invalid_mass_sequences: bool = True, float_dtype: torch.dtype = torch.float64)</code>","text":"<p>               Bases: <code>Decoder</code></p> <p>A class for decoding from de novo sequence models using beam search.</p> <p>This class conforms to the <code>Decoder</code> interface and decodes from models that conform to the <code>Decodable</code> interface.</p>"},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.mass_scale","title":"<code>mass_scale = mass_scale</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.disable_terminal_residues_anywhere","title":"<code>disable_terminal_residues_anywhere = disable_terminal_residues_anywhere</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.keep_invalid_mass_sequences","title":"<code>keep_invalid_mass_sequences = keep_invalid_mass_sequences</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.float_dtype","title":"<code>float_dtype = float_dtype</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.residue_masses","title":"<code>residue_masses = torch.zeros((len(self.model.residue_set),), dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.terminal_residue_indices","title":"<code>terminal_residue_indices = torch.tensor(terminal_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.suppressed_residue_indices","title":"<code>suppressed_residue_indices = torch.tensor(suppressed_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.residue_target_offsets","title":"<code>residue_target_offsets = torch.tensor(residue_target_offsets, dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.vocab_size","title":"<code>vocab_size = len(self.model.residue_set)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.BeamSearchDecoder.decode","title":"<code>decode(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], beam_size: int, max_length: int, mass_tolerance: float = 5e-05, max_isotope: int = 1, min_log_prob: float = -float('inf'), return_encoder_output: bool = False, encoder_output_reduction: Literal['mean', 'max', 'sum', 'full'] = 'mean', return_beam: bool = False, **kwargs) -&gt; dict[str, Any]</code>","text":"<p>Decode predicted residue sequence for a batch of spectra using beam search.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p> <code>beam_size</code> <p>The maximum size of the beam. Ignored in beam search.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>The maximum length of a residue sequence.</p> <p> TYPE: <code>int</code> </p> <code>mass_tolerance</code> <p>The maximum relative error for which a predicted sequence is still considered to have matched the precursor mass.</p> <p> TYPE: <code>float</code> DEFAULT: <code>5e-05</code> </p> <code>max_isotope</code> <p>The maximum number of additional neutrons for isotopes whose mass a predicted sequence's mass is considered when comparing to the precursor mass.</p> <p>All additional nucleon numbers from 1 to <code>max_isotope</code> inclusive are considered.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>min_log_prob</code> <p>Minimum log probability to stop decoding early. If a sequence probability is less than this value it is marked as complete. Defaults to -inf.</p> <p> TYPE: <code>float</code> DEFAULT: <code>-float('inf')</code> </p> <code>return_beam</code> <p>Optionally return beam-search results. Ignored in greedy search.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>list[list[str]]: The predicted sequence as a list of residue tokens. This method will return an empty list for each spectrum in the batch where decoding fails i.e. no sequence that fits the precursor mass to within a tolerance is found.</p>"},{"location":"API/inference/#instanovo.inference.GreedyDecoder","title":"<code>GreedyDecoder(model: Decodable, suppressed_residues: list[str] | None = None, mass_scale: int = MASS_SCALE, disable_terminal_residues_anywhere: bool = True, float_dtype: torch.dtype = torch.float64)</code>","text":"<p>               Bases: <code>Decoder</code></p> <p>A class for decoding from de novo sequence models using greedy search.</p> <p>This class conforms to the <code>Decoder</code> interface and decodes from models that conform to the <code>Decodable</code> interface.</p>"},{"location":"API/inference/#instanovo.inference.GreedyDecoder.mass_scale","title":"<code>mass_scale = mass_scale</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.disable_terminal_residues_anywhere","title":"<code>disable_terminal_residues_anywhere = disable_terminal_residues_anywhere</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.float_dtype","title":"<code>float_dtype = float_dtype</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.residue_masses","title":"<code>residue_masses = torch.zeros((len(self.model.residue_set),), dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.terminal_residue_indices","title":"<code>terminal_residue_indices = torch.tensor(terminal_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.suppressed_residue_indices","title":"<code>suppressed_residue_indices = torch.tensor(suppressed_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.residue_target_offsets","title":"<code>residue_target_offsets = torch.tensor(residue_target_offsets, dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.vocab_size","title":"<code>vocab_size = len(self.model.residue_set)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.GreedyDecoder.decode","title":"<code>decode(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], max_length: int, mass_tolerance: float = 5e-05, max_isotope: int = 1, min_log_prob: float = -float('inf'), return_encoder_output: bool = False, encoder_output_reduction: Literal['mean', 'max', 'sum', 'full'] = 'mean', **kwargs) -&gt; dict[str, Any]</code>","text":"<p>Decode predicted residue sequence for a batch of spectra using greedy search.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p> <code>max_length</code> <p>The maximum length of a residue sequence.</p> <p> TYPE: <code>int</code> </p> <code>mass_tolerance</code> <p>The maximum relative error for which a predicted sequence is still considered to have matched the precursor mass.</p> <p> TYPE: <code>float</code> DEFAULT: <code>5e-05</code> </p> <code>max_isotope</code> <p>The maximum number of additional neutrons for isotopes whose mass a predicted sequence's mass is considered when comparing to the precursor mass.</p> <p>All additional nucleon numbers from 1 to <code>max_isotope</code> inclusive are considered.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>min_log_prob</code> <p>Minimum log probability to stop decoding early. If a sequence probability is less than this value it is marked as complete. Defaults to -inf.</p> <p> TYPE: <code>float</code> DEFAULT: <code>-float('inf')</code> </p> <code>return_encoder_output</code> <p>Whether to return the encoder output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>encoder_output_reduction</code> <p>The reduction to apply to the encoder output. Valid values are \"mean\", \"max\", \"sum\", \"full\". Defaults to \"mean\".</p> <p> TYPE: <code>Literal['mean', 'max', 'sum', 'full']</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: Required keys:     - \"predictions\": list[list[str]]     - \"mass_error\": list[float]     - \"prediction_log_probability\": list[float]     - \"prediction_token_log_probabilities\": list[list[float]]     - \"encoder_output\": list[float] (optional) Example additional keys:     - \"prediction_beam_0\": list[str]</p>"},{"location":"API/inference/#instanovo.inference.Decodable","title":"<code>Decodable</code>","text":"<p>An interface for models that can be decoded.</p> <p>Algorithms should conform to the search interface.</p>"},{"location":"API/inference/#instanovo.inference.Decodable.residue_set","title":"<code>residue_set: ResidueSet</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Every model must have a <code>residue_set</code> attribute.</p>"},{"location":"API/inference/#instanovo.inference.Decodable.init","title":"<code>init(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], *args, **kwargs) -&gt; Any</code>  <code>abstractmethod</code>","text":"<p>Initialize the search state.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p>"},{"location":"API/inference/#instanovo.inference.Decodable.score_candidates","title":"<code>score_candidates(sequences: Integer[Peptide, '...'], precursor_mass_charge: Float[PrecursorFeatures, '...'], *args, **kwargs) -&gt; torch.FloatTensor</code>  <code>abstractmethod</code>","text":"<p>Generate and score the next set of candidates.</p> PARAMETER DESCRIPTION <code>sequences</code> <p>Partial residue sequences in generated the course of decoding.</p> <p> TYPE: <code>LongTensor</code> </p> <code>precursor_mass_charge</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p>"},{"location":"API/inference/#instanovo.inference.Decodable.get_residue_masses","title":"<code>get_residue_masses(mass_scale: int) -&gt; torch.LongTensor</code>  <code>abstractmethod</code>","text":"<p>Get residue masses for the model's residue vocabulary.</p> PARAMETER DESCRIPTION <code>mass_scale</code> <p>The scale in Daltons at which masses are calculated and rounded off. For example, a scale of 10000 would represent masses at a scale of 1e4 Da.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/inference/#instanovo.inference.Decodable.decode","title":"<code>decode(sequence: Integer[Peptide, '...']) -&gt; list[str]</code>  <code>abstractmethod</code>","text":"<p>Map sequences of indices to residues using the model's residue vocabulary.</p> PARAMETER DESCRIPTION <code>sequence</code> <p>The sequence of residue indices to be mapped to the corresponding residue strings.</p> <p> TYPE: <code>LongTensor</code> </p>"},{"location":"API/inference/#instanovo.inference.Decodable.get_eos_index","title":"<code>get_eos_index() -&gt; int</code>  <code>abstractmethod</code>","text":"<p>Get the end of sequence token's index in the model's residue vocabulary.</p>"},{"location":"API/inference/#instanovo.inference.Decodable.get_empty_index","title":"<code>get_empty_index() -&gt; int</code>  <code>abstractmethod</code>","text":"<p>Get the empty token's index in the model's residue vocabulary.</p>"},{"location":"API/inference/#instanovo.inference.Decoder","title":"<code>Decoder(model: Decodable)</code>","text":"<p>A class that implements some search algorithm for decoding.</p> <p>Model should conform to the <code>Decodable</code> interface.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to predict residue sequences from using the implemented search algorithm.</p> <p> TYPE: <code>Decodable</code> </p>"},{"location":"API/inference/#instanovo.inference.Decoder.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Decoder.decode","title":"<code>decode(spectra: Float[Spectrum, '...'], precursors: Float[PrecursorFeatures, '...'], *args, **kwargs) -&gt; dict[str, Any]</code>  <code>abstractmethod</code>","text":"<p>Generate the predicted residue sequence using the decoder's search algorithm.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>FloatTensor</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: Required keys:     - \"sequence\": list[str]     - \"mass_error\": float     - \"sequence_log_probability\": float     - \"token_log_probabilities\": list[float]     - \"encoder_output\": list[float] (optional) Example additional keys:     - \"sequence_beam_0\": list[str]</p>"},{"location":"API/inference/#instanovo.inference.ScoredSequence","title":"<code>ScoredSequence(sequence: list[str], mass_error: float, sequence_log_probability: float, token_log_probabilities: list[float])</code>  <code>dataclass</code>","text":"<p>This class holds a residue sequence and its log probability.</p>"},{"location":"API/inference/#instanovo.inference.ScoredSequence.sequence","title":"<code>sequence: list[str]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.ScoredSequence.mass_error","title":"<code>mass_error: float</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.ScoredSequence.sequence_log_probability","title":"<code>sequence_log_probability: float</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.ScoredSequence.token_log_probabilities","title":"<code>token_log_probabilities: list[float]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack","title":"<code>Knapsack(max_mass: float, mass_scale: int, max_isotope: int, residues: list[str], residue_indices: dict[str, int], masses: MassArray, chart: KnapsackChart)</code>  <code>dataclass</code>","text":"<p>A class that precomputes and stores a knapsack chart.</p> PARAMETER DESCRIPTION <code>max_mass</code> <p>The maximum mass up to which the chart is calculated.</p> <p> TYPE: <code>float</code> </p> <code>mass_scale</code> <p>The scale in Daltons at which masses are calculated and rounded off. For example, a scale of 10000 would represent masses at a scale of 1e4 Da.</p> <p> TYPE: <code>int</code> </p> <code>residues</code> <p>The list of residues that are considered in knapsack decoding. The order of this list is the inverse of <code>residue_indices</code>.</p> <p> TYPE: <code>list[str]</code> </p> <code>residue_indices</code> <p>A mapping from residues as strings to indices in the knapsack chart. This is the inverse of <code>residues</code>.</p> <p> TYPE: <code>dict[str, int]</code> </p> <code>masses</code> <p>The set of realisable masses in ascending order.</p> <p> TYPE: <code>numpy.ndarray[number of masses]</code> </p> <code>chart</code> <p>The chart of realisable masses and residues that can lead to these masses. <code>chart[mass, residue]</code> is <code>True</code> if and only if a sequence of <code>mass</code> can be generated starting with the residue with index <code>residue</code>.</p> <p> TYPE: <code>numpy.ndarray[number of masses, number of residues]</code> </p>"},{"location":"API/inference/#instanovo.inference.Knapsack.max_mass","title":"<code>max_mass: float</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack.mass_scale","title":"<code>mass_scale: int</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack.max_isotope","title":"<code>max_isotope: int</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack.residues","title":"<code>residues: list[str]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack.residue_indices","title":"<code>residue_indices: dict[str, int]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack.masses","title":"<code>masses: MassArray</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack.chart","title":"<code>chart: KnapsackChart</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.Knapsack.save","title":"<code>save(path: str) -&gt; None</code>","text":"<p>Save the knapsack file to a directory.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the directory.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>FileExistsError</code> <p>If the directory <code>path</code> already exists, this message raise an exception.</p>"},{"location":"API/inference/#instanovo.inference.Knapsack.construct_knapsack","title":"<code>construct_knapsack(residue_masses: dict[str, float], residue_indices: dict[str, int], max_mass: float, mass_scale: int, max_isotope: int = 2) -&gt; 'Knapsack'</code>  <code>classmethod</code>","text":"<p>Construct a knapsack chart using depth-first search.</p> <p>Previous construction algorithms have used dynamic programming, but its space and time complexity scale linearly with mass resolution since every <code>possible</code> mass is iterated over rather than only the <code>feasible</code> masses.</p> <p>Graph search algorithms only iterate over <code>feasible</code> masses which become a smaller and smaller share of possible masses as the mass resolution increases. This leads to dramatic performance improvements.</p> <p>This implementation uses depth-first search since its agenda is a stack which can be implemented using python lists whose operations have amortized constant time complexity.</p> PARAMETER DESCRIPTION <code>residue_masses</code> <p>A mapping from considered residues to their masses.</p> <p> TYPE: <code>dict[str, float]</code> </p> <code>max_mass</code> <p>The maximum mass up to which the chart is calculated.</p> <p> TYPE: <code>float</code> </p> <code>mass_scale</code> <p>The scale in Daltons at which masses are calculated and rounded off. For example, a scale of 10000 would represent masses at a scale of 1e4 Da.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/inference/#instanovo.inference.Knapsack.from_file","title":"<code>from_file(path: str) -&gt; 'Knapsack'</code>  <code>classmethod</code>","text":"<p>Load a knapsack saved to a directory.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the directory.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>_type_</code> <p>description</p> <p> TYPE: <code>'Knapsack'</code> </p>"},{"location":"API/inference/#instanovo.inference.Knapsack.get_feasible_masses","title":"<code>get_feasible_masses(target_mass: float, tolerance: float) -&gt; list[int]</code>","text":"<p>Find a set of feasible masses for a given target mass and tolerance using binary search.</p> PARAMETER DESCRIPTION <code>target_mass</code> <p>The masses to be decoded in Daltons.</p> <p> TYPE: <code>float</code> </p> <code>tolerance</code> <p>The mass tolerance in Daltons.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>list[int]</code> <p>list[int]: A list of feasible masses.</p>"},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder","title":"<code>KnapsackBeamSearchDecoder(model: Decodable, knapsack: Knapsack, suppressed_residues: list[str] | None = None, disable_terminal_residues_anywhere: bool = True, keep_invalid_mass_sequences: bool = True, float_dtype: torch.dtype = torch.float64)</code>","text":"<p>               Bases: <code>Decoder</code></p> <p>A class for decoding from de novo sequence models using beam search.</p> <p>This class conforms to the <code>Decoder</code> interface and decodes from models that conform to the <code>Decodable</code> interface.</p>"},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.knapsack","title":"<code>knapsack = knapsack</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.chart","title":"<code>chart = torch.tensor(self.knapsack.chart)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.mass_scale","title":"<code>mass_scale = knapsack.mass_scale</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.disable_terminal_residues_anywhere","title":"<code>disable_terminal_residues_anywhere = disable_terminal_residues_anywhere</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.keep_invalid_mass_sequences","title":"<code>keep_invalid_mass_sequences = keep_invalid_mass_sequences</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.float_dtype","title":"<code>float_dtype = float_dtype</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.residue_masses","title":"<code>residue_masses = torch.zeros((len(self.model.residue_set),), dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.terminal_residue_indices","title":"<code>terminal_residue_indices = torch.tensor(terminal_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.suppressed_residue_indices","title":"<code>suppressed_residue_indices = torch.tensor(suppressed_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.residue_target_offsets","title":"<code>residue_target_offsets = torch.tensor(residue_target_offsets, dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.vocab_size","title":"<code>vocab_size = len(self.model.residue_set)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.from_file","title":"<code>from_file(model: Decodable, path: str, float_dtype: torch.dtype = torch.float64) -&gt; KnapsackBeamSearchDecoder</code>  <code>classmethod</code>","text":"<p>Initialize a decoder by loading a saved knapsack.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to be decoded from.</p> <p> TYPE: <code>Decodable</code> </p> <code>path</code> <p>The path to the directory where the knapsack         was saved to.</p> <p> TYPE: <code>str</code> </p> <code>float_dtype</code> <p>The floating point dtype to use.</p> <p> TYPE: <code>dtype</code> DEFAULT: <code>float64</code> </p> RETURNS DESCRIPTION <code>KnapsackBeamSearchDecoder</code> <p>The decoder.</p> <p> TYPE: <code>KnapsackBeamSearchDecoder</code> </p>"},{"location":"API/inference/#instanovo.inference.KnapsackBeamSearchDecoder.decode","title":"<code>decode(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], beam_size: int, max_length: int, mass_tolerance: float = 5e-05, max_isotope: int = 1, min_log_prob: float = -float('inf'), return_encoder_output: bool = False, encoder_output_reduction: Literal['mean', 'max', 'sum', 'full'] = 'mean', return_beam: bool = False, **kwargs) -&gt; dict[str, Any]</code>","text":"<p>Decode predicted residue sequence for a batch of spectra using beam search.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p> <code>beam_size</code> <p>The maximum size of the beam. Ignored in beam search.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>The maximum length of a residue sequence.</p> <p> TYPE: <code>int</code> </p> <code>mass_tolerance</code> <p>The maximum relative error for which a predicted sequence is still considered to have matched the precursor mass.</p> <p> TYPE: <code>float</code> DEFAULT: <code>5e-05</code> </p> <code>max_isotope</code> <p>The maximum number of additional neutrons for isotopes whose mass a predicted sequence's mass is considered when comparing to the precursor mass.</p> <p>All additional nucleon numbers from 1 to <code>max_isotope</code> inclusive are considered.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>min_log_prob</code> <p>Minimum log probability to stop decoding early. If a sequence probability is less than this value it is marked as complete. Defaults to -inf.</p> <p> TYPE: <code>float</code> DEFAULT: <code>-float('inf')</code> </p> <code>return_beam</code> <p>Optionally return beam-search results. Ignored in greedy search.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>list[list[str]]: The predicted sequence as a list of residue tokens. This method will return an empty list for each spectrum in the batch where decoding fails i.e. no sequence that fits the precursor mass to within a tolerance is found.</p>"},{"location":"API/inference/beam_search/","title":"Beam search","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search","title":"<code>beam_search</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder","title":"<code>BeamSearchDecoder(model: Decodable, suppressed_residues: list[str] | None = None, mass_scale: int = MASS_SCALE, disable_terminal_residues_anywhere: bool = True, keep_invalid_mass_sequences: bool = True, float_dtype: torch.dtype = torch.float64)</code>","text":"<p>               Bases: <code>Decoder</code></p> <p>A class for decoding from de novo sequence models using beam search.</p> <p>This class conforms to the <code>Decoder</code> interface and decodes from models that conform to the <code>Decodable</code> interface.</p>"},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.mass_scale","title":"<code>mass_scale = mass_scale</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.disable_terminal_residues_anywhere","title":"<code>disable_terminal_residues_anywhere = disable_terminal_residues_anywhere</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.keep_invalid_mass_sequences","title":"<code>keep_invalid_mass_sequences = keep_invalid_mass_sequences</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.float_dtype","title":"<code>float_dtype = float_dtype</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.residue_masses","title":"<code>residue_masses = torch.zeros((len(self.model.residue_set),), dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.terminal_residue_indices","title":"<code>terminal_residue_indices = torch.tensor(terminal_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.suppressed_residue_indices","title":"<code>suppressed_residue_indices = torch.tensor(suppressed_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.residue_target_offsets","title":"<code>residue_target_offsets = torch.tensor(residue_target_offsets, dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.vocab_size","title":"<code>vocab_size = len(self.model.residue_set)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/beam_search/#instanovo.inference.beam_search.BeamSearchDecoder.decode","title":"<code>decode(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], beam_size: int, max_length: int, mass_tolerance: float = 5e-05, max_isotope: int = 1, min_log_prob: float = -float('inf'), return_encoder_output: bool = False, encoder_output_reduction: Literal['mean', 'max', 'sum', 'full'] = 'mean', return_beam: bool = False, **kwargs) -&gt; dict[str, Any]</code>","text":"<p>Decode predicted residue sequence for a batch of spectra using beam search.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p> <code>beam_size</code> <p>The maximum size of the beam. Ignored in beam search.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>The maximum length of a residue sequence.</p> <p> TYPE: <code>int</code> </p> <code>mass_tolerance</code> <p>The maximum relative error for which a predicted sequence is still considered to have matched the precursor mass.</p> <p> TYPE: <code>float</code> DEFAULT: <code>5e-05</code> </p> <code>max_isotope</code> <p>The maximum number of additional neutrons for isotopes whose mass a predicted sequence's mass is considered when comparing to the precursor mass.</p> <p>All additional nucleon numbers from 1 to <code>max_isotope</code> inclusive are considered.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>min_log_prob</code> <p>Minimum log probability to stop decoding early. If a sequence probability is less than this value it is marked as complete. Defaults to -inf.</p> <p> TYPE: <code>float</code> DEFAULT: <code>-float('inf')</code> </p> <code>return_beam</code> <p>Optionally return beam-search results. Ignored in greedy search.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>list[list[str]]: The predicted sequence as a list of residue tokens. This method will return an empty list for each spectrum in the batch where decoding fails i.e. no sequence that fits the precursor mass to within a tolerance is found.</p>"},{"location":"API/inference/diffusion/","title":"Diffusion","text":""},{"location":"API/inference/diffusion/#instanovo.inference.diffusion","title":"<code>diffusion</code>","text":""},{"location":"API/inference/diffusion/#instanovo.inference.diffusion.DiffusionDecoder","title":"<code>DiffusionDecoder(model: InstaNovoPlus)</code>","text":"<p>               Bases: <code>Decoder</code></p> <p>Class for decoding from a diffusion model by forward sampling.</p>"},{"location":"API/inference/diffusion/#instanovo.inference.diffusion.DiffusionDecoder.model","title":"<code>model: InstaNovoPlus = model</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/diffusion/#instanovo.inference.diffusion.DiffusionDecoder.time_steps","title":"<code>time_steps = self.model.time_steps</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/diffusion/#instanovo.inference.diffusion.DiffusionDecoder.residue_set","title":"<code>residue_set = self.model.residue_set</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/diffusion/#instanovo.inference.diffusion.DiffusionDecoder.loss_function","title":"<code>loss_function = DiffusionLoss(model=(self.model))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/diffusion/#instanovo.inference.diffusion.DiffusionDecoder.decode","title":"<code>decode(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], spectra_padding_mask: Bool[SpectrumMask, ' batch'], initial_sequence: Optional[Integer[Peptide, ' batch']] = None, start_step: int = DIFFUSION_START_STEP, eval_steps: tuple[int, ...] = DIFFUSION_EVAL_STEPS, beam_size: int = 1, mass_tolerance: float = 5e-05, max_isotope: int = 1, return_encoder_output: bool = False, encoder_output_reduction: Literal['mean', 'max', 'sum', 'full'] = 'mean', return_beam: bool = False, **kwargs: Any) -&gt; dict[str, Any]</code>","text":"<p>Decoding predictions from a diffusion model by forward sampling.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>A batch of spectra to be decoded.</p> <p> TYPE: <code>Float[Spectrum, ' batch']</code> </p> <code>spectra_padding_mask</code> <p>Padding mask for a batch of variable length spectra.</p> <p> TYPE: <code>Bool[SpectrumMask, ' batch']</code> </p> <code>precursors</code> <p>Precursor mass, charge and m/z for a batch of spectra.</p> <p> TYPE: <code>Float[PrecursorFeatures, ' batch']</code> </p> <code>initial_sequence</code> <p>An initial sequence for the model to refine. If no initial sequence is provided (the value is None), will sample a random sequence from a uniform unigram model. Defaults to None.</p> <p> TYPE: <code>Optional[Integer[Peptide, ' batch']]</code> DEFAULT: <code>None</code> </p> <code>start_step</code> <p>The step at which to insert the initial sequence and start refinement. If <code>initial_sequence</code> is not provided, this will be set to <code>time_steps - 1</code>.</p> <p> TYPE: <code>int</code> DEFAULT: <code>DIFFUSION_START_STEP</code> </p> <code>eval_steps</code> <p>The steps at which to evaluate the loss and compute the log-probabilities.</p> <p> TYPE: <code>tuple[int, ...]</code> DEFAULT: <code>DIFFUSION_EVAL_STEPS</code> </p> <code>return_encoder_output</code> <p>Whether to return the encoder output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>encoder_output_reduction</code> <p>The reduction to apply to the encoder output. Valid values are \"mean\", \"max\", \"sum\", \"full\". Defaults to \"mean\".</p> <p> TYPE: <code>Literal['mean', 'max', 'sum', 'full']</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: The decoded peptides and their log-probabilities for a batch of spectra. Required keys:     - \"predictions\": list[list[str]]     - \"prediction_log_probability\": list[float]     - \"prediction_token_log_probabilities\": list[list[float]]     - \"encoder_output\": list[float] (optional) Example additional keys:     - \"prediction_beam_0\": list[str]</p>"},{"location":"API/inference/greedy_search/","title":"Greedy search","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search","title":"<code>greedy_search</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder","title":"<code>GreedyDecoder(model: Decodable, suppressed_residues: list[str] | None = None, mass_scale: int = MASS_SCALE, disable_terminal_residues_anywhere: bool = True, float_dtype: torch.dtype = torch.float64)</code>","text":"<p>               Bases: <code>Decoder</code></p> <p>A class for decoding from de novo sequence models using greedy search.</p> <p>This class conforms to the <code>Decoder</code> interface and decodes from models that conform to the <code>Decodable</code> interface.</p>"},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.mass_scale","title":"<code>mass_scale = mass_scale</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.disable_terminal_residues_anywhere","title":"<code>disable_terminal_residues_anywhere = disable_terminal_residues_anywhere</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.float_dtype","title":"<code>float_dtype = float_dtype</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.residue_masses","title":"<code>residue_masses = torch.zeros((len(self.model.residue_set),), dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.terminal_residue_indices","title":"<code>terminal_residue_indices = torch.tensor(terminal_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.suppressed_residue_indices","title":"<code>suppressed_residue_indices = torch.tensor(suppressed_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.residue_target_offsets","title":"<code>residue_target_offsets = torch.tensor(residue_target_offsets, dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.vocab_size","title":"<code>vocab_size = len(self.model.residue_set)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/greedy_search/#instanovo.inference.greedy_search.GreedyDecoder.decode","title":"<code>decode(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], max_length: int, mass_tolerance: float = 5e-05, max_isotope: int = 1, min_log_prob: float = -float('inf'), return_encoder_output: bool = False, encoder_output_reduction: Literal['mean', 'max', 'sum', 'full'] = 'mean', **kwargs) -&gt; dict[str, Any]</code>","text":"<p>Decode predicted residue sequence for a batch of spectra using greedy search.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p> <code>max_length</code> <p>The maximum length of a residue sequence.</p> <p> TYPE: <code>int</code> </p> <code>mass_tolerance</code> <p>The maximum relative error for which a predicted sequence is still considered to have matched the precursor mass.</p> <p> TYPE: <code>float</code> DEFAULT: <code>5e-05</code> </p> <code>max_isotope</code> <p>The maximum number of additional neutrons for isotopes whose mass a predicted sequence's mass is considered when comparing to the precursor mass.</p> <p>All additional nucleon numbers from 1 to <code>max_isotope</code> inclusive are considered.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>min_log_prob</code> <p>Minimum log probability to stop decoding early. If a sequence probability is less than this value it is marked as complete. Defaults to -inf.</p> <p> TYPE: <code>float</code> DEFAULT: <code>-float('inf')</code> </p> <code>return_encoder_output</code> <p>Whether to return the encoder output.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>encoder_output_reduction</code> <p>The reduction to apply to the encoder output. Valid values are \"mean\", \"max\", \"sum\", \"full\". Defaults to \"mean\".</p> <p> TYPE: <code>Literal['mean', 'max', 'sum', 'full']</code> DEFAULT: <code>'mean'</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: Required keys:     - \"predictions\": list[list[str]]     - \"mass_error\": list[float]     - \"prediction_log_probability\": list[float]     - \"prediction_token_log_probabilities\": list[list[float]]     - \"encoder_output\": list[float] (optional) Example additional keys:     - \"prediction_beam_0\": list[str]</p>"},{"location":"API/inference/interfaces/","title":"Interfaces","text":""},{"location":"API/inference/interfaces/#instanovo.inference.interfaces","title":"<code>interfaces</code>","text":""},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.ScoredSequence","title":"<code>ScoredSequence(sequence: list[str], mass_error: float, sequence_log_probability: float, token_log_probabilities: list[float])</code>  <code>dataclass</code>","text":"<p>This class holds a residue sequence and its log probability.</p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.ScoredSequence.sequence","title":"<code>sequence: list[str]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.ScoredSequence.mass_error","title":"<code>mass_error: float</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.ScoredSequence.sequence_log_probability","title":"<code>sequence_log_probability: float</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.ScoredSequence.token_log_probabilities","title":"<code>token_log_probabilities: list[float]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable","title":"<code>Decodable</code>","text":"<p>An interface for models that can be decoded.</p> <p>Algorithms should conform to the search interface.</p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable.residue_set","title":"<code>residue_set: ResidueSet</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Every model must have a <code>residue_set</code> attribute.</p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable.init","title":"<code>init(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], *args, **kwargs) -&gt; Any</code>  <code>abstractmethod</code>","text":"<p>Initialize the search state.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable.score_candidates","title":"<code>score_candidates(sequences: Integer[Peptide, '...'], precursor_mass_charge: Float[PrecursorFeatures, '...'], *args, **kwargs) -&gt; torch.FloatTensor</code>  <code>abstractmethod</code>","text":"<p>Generate and score the next set of candidates.</p> PARAMETER DESCRIPTION <code>sequences</code> <p>Partial residue sequences in generated the course of decoding.</p> <p> TYPE: <code>LongTensor</code> </p> <code>precursor_mass_charge</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable.get_residue_masses","title":"<code>get_residue_masses(mass_scale: int) -&gt; torch.LongTensor</code>  <code>abstractmethod</code>","text":"<p>Get residue masses for the model's residue vocabulary.</p> PARAMETER DESCRIPTION <code>mass_scale</code> <p>The scale in Daltons at which masses are calculated and rounded off. For example, a scale of 10000 would represent masses at a scale of 1e4 Da.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable.decode","title":"<code>decode(sequence: Integer[Peptide, '...']) -&gt; list[str]</code>  <code>abstractmethod</code>","text":"<p>Map sequences of indices to residues using the model's residue vocabulary.</p> PARAMETER DESCRIPTION <code>sequence</code> <p>The sequence of residue indices to be mapped to the corresponding residue strings.</p> <p> TYPE: <code>LongTensor</code> </p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable.get_eos_index","title":"<code>get_eos_index() -&gt; int</code>  <code>abstractmethod</code>","text":"<p>Get the end of sequence token's index in the model's residue vocabulary.</p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decodable.get_empty_index","title":"<code>get_empty_index() -&gt; int</code>  <code>abstractmethod</code>","text":"<p>Get the empty token's index in the model's residue vocabulary.</p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decoder","title":"<code>Decoder(model: Decodable)</code>","text":"<p>A class that implements some search algorithm for decoding.</p> <p>Model should conform to the <code>Decodable</code> interface.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to predict residue sequences from using the implemented search algorithm.</p> <p> TYPE: <code>Decodable</code> </p>"},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decoder.model","title":"<code>model = model</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/interfaces/#instanovo.inference.interfaces.Decoder.decode","title":"<code>decode(spectra: Float[Spectrum, '...'], precursors: Float[PrecursorFeatures, '...'], *args, **kwargs) -&gt; dict[str, Any]</code>  <code>abstractmethod</code>","text":"<p>Generate the predicted residue sequence using the decoder's search algorithm.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>FloatTensor</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>dict[str, Any]: Required keys:     - \"sequence\": list[str]     - \"mass_error\": float     - \"sequence_log_probability\": float     - \"token_log_probabilities\": list[float]     - \"encoder_output\": list[float] (optional) Example additional keys:     - \"sequence_beam_0\": list[str]</p>"},{"location":"API/inference/knapsack/","title":"Knapsack","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack","title":"<code>knapsack</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack","title":"<code>Knapsack(max_mass: float, mass_scale: int, max_isotope: int, residues: list[str], residue_indices: dict[str, int], masses: MassArray, chart: KnapsackChart)</code>  <code>dataclass</code>","text":"<p>A class that precomputes and stores a knapsack chart.</p> PARAMETER DESCRIPTION <code>max_mass</code> <p>The maximum mass up to which the chart is calculated.</p> <p> TYPE: <code>float</code> </p> <code>mass_scale</code> <p>The scale in Daltons at which masses are calculated and rounded off. For example, a scale of 10000 would represent masses at a scale of 1e4 Da.</p> <p> TYPE: <code>int</code> </p> <code>residues</code> <p>The list of residues that are considered in knapsack decoding. The order of this list is the inverse of <code>residue_indices</code>.</p> <p> TYPE: <code>list[str]</code> </p> <code>residue_indices</code> <p>A mapping from residues as strings to indices in the knapsack chart. This is the inverse of <code>residues</code>.</p> <p> TYPE: <code>dict[str, int]</code> </p> <code>masses</code> <p>The set of realisable masses in ascending order.</p> <p> TYPE: <code>numpy.ndarray[number of masses]</code> </p> <code>chart</code> <p>The chart of realisable masses and residues that can lead to these masses. <code>chart[mass, residue]</code> is <code>True</code> if and only if a sequence of <code>mass</code> can be generated starting with the residue with index <code>residue</code>.</p> <p> TYPE: <code>numpy.ndarray[number of masses, number of residues]</code> </p>"},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.max_mass","title":"<code>max_mass: float</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.mass_scale","title":"<code>mass_scale: int</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.max_isotope","title":"<code>max_isotope: int</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.residues","title":"<code>residues: list[str]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.residue_indices","title":"<code>residue_indices: dict[str, int]</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.masses","title":"<code>masses: MassArray</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.chart","title":"<code>chart: KnapsackChart</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.save","title":"<code>save(path: str) -&gt; None</code>","text":"<p>Save the knapsack file to a directory.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the directory.</p> <p> TYPE: <code>str</code> </p> RAISES DESCRIPTION <code>FileExistsError</code> <p>If the directory <code>path</code> already exists, this message raise an exception.</p>"},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.construct_knapsack","title":"<code>construct_knapsack(residue_masses: dict[str, float], residue_indices: dict[str, int], max_mass: float, mass_scale: int, max_isotope: int = 2) -&gt; 'Knapsack'</code>  <code>classmethod</code>","text":"<p>Construct a knapsack chart using depth-first search.</p> <p>Previous construction algorithms have used dynamic programming, but its space and time complexity scale linearly with mass resolution since every <code>possible</code> mass is iterated over rather than only the <code>feasible</code> masses.</p> <p>Graph search algorithms only iterate over <code>feasible</code> masses which become a smaller and smaller share of possible masses as the mass resolution increases. This leads to dramatic performance improvements.</p> <p>This implementation uses depth-first search since its agenda is a stack which can be implemented using python lists whose operations have amortized constant time complexity.</p> PARAMETER DESCRIPTION <code>residue_masses</code> <p>A mapping from considered residues to their masses.</p> <p> TYPE: <code>dict[str, float]</code> </p> <code>max_mass</code> <p>The maximum mass up to which the chart is calculated.</p> <p> TYPE: <code>float</code> </p> <code>mass_scale</code> <p>The scale in Daltons at which masses are calculated and rounded off. For example, a scale of 10000 would represent masses at a scale of 1e4 Da.</p> <p> TYPE: <code>int</code> </p>"},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.from_file","title":"<code>from_file(path: str) -&gt; 'Knapsack'</code>  <code>classmethod</code>","text":"<p>Load a knapsack saved to a directory.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the directory.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>_type_</code> <p>description</p> <p> TYPE: <code>'Knapsack'</code> </p>"},{"location":"API/inference/knapsack/#instanovo.inference.knapsack.Knapsack.get_feasible_masses","title":"<code>get_feasible_masses(target_mass: float, tolerance: float) -&gt; list[int]</code>","text":"<p>Find a set of feasible masses for a given target mass and tolerance using binary search.</p> PARAMETER DESCRIPTION <code>target_mass</code> <p>The masses to be decoded in Daltons.</p> <p> TYPE: <code>float</code> </p> <code>tolerance</code> <p>The mass tolerance in Daltons.</p> <p> TYPE: <code>float</code> </p> RETURNS DESCRIPTION <code>list[int]</code> <p>list[int]: A list of feasible masses.</p>"},{"location":"API/inference/knapsack_beam_search/","title":"Knapsack beam search","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search","title":"<code>knapsack_beam_search</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder","title":"<code>KnapsackBeamSearchDecoder(model: Decodable, knapsack: Knapsack, suppressed_residues: list[str] | None = None, disable_terminal_residues_anywhere: bool = True, keep_invalid_mass_sequences: bool = True, float_dtype: torch.dtype = torch.float64)</code>","text":"<p>               Bases: <code>Decoder</code></p> <p>A class for decoding from de novo sequence models using beam search.</p> <p>This class conforms to the <code>Decoder</code> interface and decodes from models that conform to the <code>Decodable</code> interface.</p>"},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.knapsack","title":"<code>knapsack = knapsack</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.chart","title":"<code>chart = torch.tensor(self.knapsack.chart)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.mass_scale","title":"<code>mass_scale = knapsack.mass_scale</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.disable_terminal_residues_anywhere","title":"<code>disable_terminal_residues_anywhere = disable_terminal_residues_anywhere</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.keep_invalid_mass_sequences","title":"<code>keep_invalid_mass_sequences = keep_invalid_mass_sequences</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.float_dtype","title":"<code>float_dtype = float_dtype</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.residue_masses","title":"<code>residue_masses = torch.zeros((len(self.model.residue_set),), dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.terminal_residue_indices","title":"<code>terminal_residue_indices = torch.tensor(terminal_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.suppressed_residue_indices","title":"<code>suppressed_residue_indices = torch.tensor(suppressed_residues_idx, dtype=(torch.long))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.residue_target_offsets","title":"<code>residue_target_offsets = torch.tensor(residue_target_offsets, dtype=(self.float_dtype))</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.vocab_size","title":"<code>vocab_size = len(self.model.residue_set)</code>  <code>instance-attribute</code>","text":""},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.from_file","title":"<code>from_file(model: Decodable, path: str, float_dtype: torch.dtype = torch.float64) -&gt; KnapsackBeamSearchDecoder</code>  <code>classmethod</code>","text":"<p>Initialize a decoder by loading a saved knapsack.</p> PARAMETER DESCRIPTION <code>model</code> <p>The model to be decoded from.</p> <p> TYPE: <code>Decodable</code> </p> <code>path</code> <p>The path to the directory where the knapsack         was saved to.</p> <p> TYPE: <code>str</code> </p> <code>float_dtype</code> <p>The floating point dtype to use.</p> <p> TYPE: <code>dtype</code> DEFAULT: <code>float64</code> </p> RETURNS DESCRIPTION <code>KnapsackBeamSearchDecoder</code> <p>The decoder.</p> <p> TYPE: <code>KnapsackBeamSearchDecoder</code> </p>"},{"location":"API/inference/knapsack_beam_search/#instanovo.inference.knapsack_beam_search.KnapsackBeamSearchDecoder.decode","title":"<code>decode(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], beam_size: int, max_length: int, mass_tolerance: float = 5e-05, max_isotope: int = 1, min_log_prob: float = -float('inf'), return_encoder_output: bool = False, encoder_output_reduction: Literal['mean', 'max', 'sum', 'full'] = 'mean', return_beam: bool = False, **kwargs) -&gt; dict[str, Any]</code>","text":"<p>Decode predicted residue sequence for a batch of spectra using beam search.</p> PARAMETER DESCRIPTION <code>spectra</code> <p>The spectra to be sequenced.</p> <p> TYPE: <code>FloatTensor</code> </p> <code>precursors</code> <p>The precursor mass, charge and mass-to-charge ratio.</p> <p> TYPE: <code>torch.FloatTensor[batch size, 3]</code> </p> <code>beam_size</code> <p>The maximum size of the beam. Ignored in beam search.</p> <p> TYPE: <code>int</code> </p> <code>max_length</code> <p>The maximum length of a residue sequence.</p> <p> TYPE: <code>int</code> </p> <code>mass_tolerance</code> <p>The maximum relative error for which a predicted sequence is still considered to have matched the precursor mass.</p> <p> TYPE: <code>float</code> DEFAULT: <code>5e-05</code> </p> <code>max_isotope</code> <p>The maximum number of additional neutrons for isotopes whose mass a predicted sequence's mass is considered when comparing to the precursor mass.</p> <p>All additional nucleon numbers from 1 to <code>max_isotope</code> inclusive are considered.</p> <p> TYPE: <code>int</code> DEFAULT: <code>1</code> </p> <code>min_log_prob</code> <p>Minimum log probability to stop decoding early. If a sequence probability is less than this value it is marked as complete. Defaults to -inf.</p> <p> TYPE: <code>float</code> DEFAULT: <code>-float('inf')</code> </p> <code>return_beam</code> <p>Optionally return beam-search results. Ignored in greedy search.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>list[list[str]]: The predicted sequence as a list of residue tokens. This method will return an empty list for each spectrum in the batch where decoding fails i.e. no sequence that fits the precursor mass to within a tolerance is found.</p>"},{"location":"API/transformer/","title":"Index","text":""},{"location":"API/transformer/#instanovo.transformer","title":"<code>transformer</code>","text":""},{"location":"API/transformer/layers/","title":"Layers","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers","title":"<code>layers</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.PositionalEncoding","title":"<code>PositionalEncoding(d_model: int, dropout: float = 0.1, max_len: int = 5000)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Standard sinusoidal positional encoding.</p>"},{"location":"API/transformer/layers/#instanovo.transformer.layers.PositionalEncoding.dropout","title":"<code>dropout = nn.Dropout(p=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.PositionalEncoding.forward","title":"<code>forward(x: Float[Tensor, 'token batch embedding']) -&gt; Float[Tensor, 'token batch embedding']</code>","text":"<p>Positional encoding forward pass.</p> PARAMETER DESCRIPTION <code>x</code> <p>Tensor, shape <code>[seq_len, batch_size, embedding_dim]</code></p> <p> TYPE: <code>Float[Tensor, 'token batch embedding']</code> </p>"},{"location":"API/transformer/layers/#instanovo.transformer.layers.MultiScalePeakEmbedding","title":"<code>MultiScalePeakEmbedding(h_size: int, dropout: float = 0, float_dtype: torch.dtype | str = torch.float64)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Multi-scale sinusoidal embedding based on Voronov et. al.</p>"},{"location":"API/transformer/layers/#instanovo.transformer.layers.MultiScalePeakEmbedding.h_size","title":"<code>h_size = h_size</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.MultiScalePeakEmbedding.float_dtype","title":"<code>float_dtype = getattr(torch, float_dtype, None) if isinstance(float_dtype, str) else float_dtype</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.MultiScalePeakEmbedding.mlp","title":"<code>mlp = nn.Sequential(nn.Linear(h_size, h_size), nn.ReLU(), nn.Dropout(dropout), nn.Linear(h_size, h_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.MultiScalePeakEmbedding.head","title":"<code>head = nn.Sequential(nn.Linear(h_size + 1, h_size), nn.ReLU(), nn.Dropout(dropout), nn.Linear(h_size, h_size), nn.Dropout(dropout))</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.MultiScalePeakEmbedding.forward","title":"<code>forward(spectra: Float[Spectrum, ' batch']) -&gt; Float[SpectrumEmbedding, ' batch']</code>","text":"<p>Encode peaks.</p>"},{"location":"API/transformer/layers/#instanovo.transformer.layers.MultiScalePeakEmbedding.encode_mass","title":"<code>encode_mass(x: Float[Tensor, ' batch']) -&gt; Float[Tensor, 'batch embedding']</code>","text":"<p>Encode mz.</p>"},{"location":"API/transformer/layers/#instanovo.transformer.layers.ConvPeakEmbedding","title":"<code>ConvPeakEmbedding(h_size: int, dropout: float = 0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Convolutional peak embedding.</p>"},{"location":"API/transformer/layers/#instanovo.transformer.layers.ConvPeakEmbedding.h_size","title":"<code>h_size = h_size</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.ConvPeakEmbedding.conv","title":"<code>conv = nn.Sequential(nn.Conv1d(1, h_size // 4, kernel_size=40000, stride=100, padding=(40000 // 2 - 1)), nn.ReLU(), nn.Dropout(), nn.Conv1d(h_size // 4, h_size, kernel_size=5, stride=1, padding=1), nn.ReLU(), nn.Dropout())</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/layers/#instanovo.transformer.layers.ConvPeakEmbedding.forward","title":"<code>forward(x: Tensor) -&gt; Tensor</code>","text":"<p>Conv peak embedding.</p>"},{"location":"API/transformer/model/","title":"Model","text":""},{"location":"API/transformer/model/#instanovo.transformer.model","title":"<code>model</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.MODEL_TYPE","title":"<code>MODEL_TYPE = 'transformer'</code>  <code>module-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo","title":"<code>InstaNovo(residue_set: ResidueSet, dim_model: int = 768, n_head: int = 16, dim_feedforward: int = 2048, encoder_layers: int = 9, decoder_layers: int = 9, dropout: float = 0.1, max_charge: int = 5, use_flash_attention: bool = False, conv_peak_encoder: bool = False, peak_embedding_dtype: torch.dtype | str = torch.float64)</code>","text":"<p>               Bases: <code>Module</code>, <code>Decodable</code></p> <p>The Instanovo model.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.vocab_size","title":"<code>vocab_size = len(residue_set)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.use_flash_attention","title":"<code>use_flash_attention = use_flash_attention</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.conv_peak_encoder","title":"<code>conv_peak_encoder = conv_peak_encoder</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.latent_spectrum","title":"<code>latent_spectrum = nn.Parameter(torch.randn(1, 1, dim_model))</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.pad_spectrum","title":"<code>pad_spectrum = nn.Parameter(torch.randn(1, 1, dim_model))</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.peak_encoder","title":"<code>peak_encoder = MultiScalePeakEmbedding(dim_model, dropout=dropout, float_dtype=peak_embedding_dtype)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.conv_encoder","title":"<code>conv_encoder = ConvPeakEmbedding(dim_model, dropout=dropout)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.encoder","title":"<code>encoder = nn.TransformerEncoder(encoder_layer, num_layers=encoder_layers)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.aa_embed","title":"<code>aa_embed = nn.Embedding(self.vocab_size, dim_model, padding_idx=0)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.aa_pos_embed","title":"<code>aa_pos_embed = PositionalEncoding(dim_model, dropout, max_len=MAX_SEQUENCE_LENGTH)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.decoder","title":"<code>decoder = nn.TransformerDecoder(decoder_layer, num_layers=decoder_layers)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.head","title":"<code>head = nn.Linear(dim_model, self.vocab_size)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.charge_encoder","title":"<code>charge_encoder = nn.Embedding(max_charge, dim_model)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.residue_set","title":"<code>residue_set: ResidueSet</code>  <code>property</code>","text":"<p>Every model must have a <code>residue_set</code> attribute.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.get_pretrained","title":"<code>get_pretrained() -&gt; list[str]</code>  <code>staticmethod</code>","text":"<p>Get a list of pretrained model ids.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.load","title":"<code>load(path: str, update_residues_to_unimod: bool = True, override_config: DictConfig | dict | None = None) -&gt; tuple['InstaNovo', 'DictConfig']</code>  <code>classmethod</code>","text":"<p>Load model from checkpoint path.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to checkpoint file.</p> <p> TYPE: <code>str</code> </p> <code>update_residues_to_unimod</code> <p>Update residues to unimod, defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>override_config</code> <p>Optional override config values with a DictConfig or dict, defaults to None.</p> <p> TYPE: <code>DictConfig | dict | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple['InstaNovo', 'DictConfig']</code> <p>tuple[InstaNovo, DictConfig]: Tuple of model and config.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.from_pretrained","title":"<code>from_pretrained(model_id: str, update_residues_to_unimod: bool = True, override_config: DictConfig | dict | None = None) -&gt; tuple['InstaNovo', 'DictConfig']</code>  <code>classmethod</code>","text":"<p>Download and load by model id or model path.</p> PARAMETER DESCRIPTION <code>model_id</code> <p>Model id or model path.</p> <p> TYPE: <code>str</code> </p> <code>update_residues_to_unimod</code> <p>Update residues to unimod, defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>override_config</code> <p>Optional override config values with a DictConfig or dict, defaults to None.</p> <p> TYPE: <code>DictConfig | dict | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>tuple['InstaNovo', 'DictConfig']</code> <p>tuple[InstaNovo, DictConfig]: Tuple of model and config.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.forward","title":"<code>forward(x: Float[Spectrum, ' batch'], p: Float[PrecursorFeatures, ' batch'], y: Integer[Peptide, ' batch'], x_mask: Optional[Bool[SpectrumMask, ' batch']] = None, y_mask: Optional[Bool[PeptideMask, ' batch']] = None, add_bos: bool = True, return_encoder_output: bool = False) -&gt; Float[ResidueLogits, 'batch token+1']</code>","text":"<p>Model forward pass.</p> PARAMETER DESCRIPTION <code>x</code> <p>Spectra, float Tensor (batch, n_peaks, 2)</p> <p> TYPE: <code>Float[Spectrum, ' batch']</code> </p> <code>p</code> <p>Precursors, float Tensor (batch, 3)</p> <p> TYPE: <code>Float[PrecursorFeatures, ' batch']</code> </p> <code>y</code> <p>Peptide, long Tensor (batch, seq_len, vocab)</p> <p> TYPE: <code>Integer[Peptide, ' batch']</code> </p> <code>x_mask</code> <p>Spectra padding mask, True for padded indices, bool Tensor (batch, n_peaks)</p> <p> TYPE: <code>Optional[Bool[SpectrumMask, ' batch']]</code> DEFAULT: <code>None</code> </p> <code>y_mask</code> <p>Peptide padding mask, bool Tensor (batch, seq_len)</p> <p> TYPE: <code>Optional[Bool[PeptideMask, ' batch']]</code> DEFAULT: <code>None</code> </p> <code>add_bos</code> <p>Force add a  prefix to y, bool <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>logits</code> <p>float Tensor (batch, n, vocab_size),</p> <p> TYPE: <code>Float[ResidueLogits, 'batch token+1']</code> </p> <code>Float[ResidueLogits, 'batch token+1']</code> <p>(batch, n+1, vocab_size) if add_bos==True.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.init","title":"<code>init(spectra: Float[Spectrum, ' batch'], precursors: Float[PrecursorFeatures, ' batch'], spectra_mask: Optional[Bool[SpectrumMask, ' batch']] = None) -&gt; Tuple[Tuple[Float[Spectrum, ' batch'], Bool[SpectrumMask, ' batch']], Float[ResidueLogProbabilities, 'batch token']]</code>","text":"<p>Initialise model encoder.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.score_candidates","title":"<code>score_candidates(sequences: Integer[Peptide, ' batch'], precursor_mass_charge: Float[PrecursorFeatures, ' batch'], spectra: Float[Spectrum, ' batch'], spectra_mask: Bool[SpectrumMask, ' batch']) -&gt; Float[ResidueLogProbabilities, 'batch token']</code>","text":"<p>Score a set of candidate sequences.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.get_residue_masses","title":"<code>get_residue_masses(mass_scale: int) -&gt; Integer[DiscretizedMass, ' residue']</code>","text":"<p>Get the scaled masses of all residues.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.get_eos_index","title":"<code>get_eos_index() -&gt; int</code>","text":"<p>Get the EOS token ID.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.get_empty_index","title":"<code>get_empty_index() -&gt; int</code>","text":"<p>Get the PAD token ID.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.decode","title":"<code>decode(sequence: Peptide) -&gt; list[str]</code>","text":"<p>Decode a single sequence of AA IDs.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.idx_to_aa","title":"<code>idx_to_aa(idx: Peptide) -&gt; list[str]</code>","text":"<p>Decode a single sample of indices to aa list.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.batch_idx_to_aa","title":"<code>batch_idx_to_aa(idx: Integer[Peptide, ' batch'], reverse: bool) -&gt; list[list[str]]</code>","text":"<p>Decode a batch of indices to aa lists.</p>"},{"location":"API/transformer/model/#instanovo.transformer.model.InstaNovo.score_sequences","title":"<code>score_sequences(peptides: Integer[Peptide, ' batch'] | list[str] | list[list[str]], peptides_mask: Bool[PeptideMask, ' batch'] | None = None, spectra: Float[Spectrum, ' batch'] | None = None, precursors: Float[PrecursorFeatures, ' batch'] | None = None, spectra_mask: Bool[SpectrumMask, ' batch'] | None = None, spectra_embedding: Float[SpectrumEmbedding, ' batch'] | None = None, max_batch_size: int = 256) -&gt; Float[ResidueLogProbabilities, 'batch token']</code>","text":"<p>Score a set of peptides.</p>"},{"location":"API/transformer/predict/","title":"Predict","text":""},{"location":"API/transformer/predict/#instanovo.transformer.predict","title":"<code>predict</code>","text":""},{"location":"API/transformer/predict/#instanovo.transformer.predict.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/transformer/predict/#instanovo.transformer.predict.CONFIG_PATH","title":"<code>CONFIG_PATH = Path(__file__).parent.parent / 'configs'</code>  <code>module-attribute</code>","text":""},{"location":"API/transformer/predict/#instanovo.transformer.predict.TransformerPredictor","title":"<code>TransformerPredictor(config: DictConfig)</code>","text":"<p>               Bases: <code>AccelerateDeNovoPredictor</code></p> <p>Predictor for the InstaNovo model.</p>"},{"location":"API/transformer/predict/#instanovo.transformer.predict.TransformerPredictor.num_beams","title":"<code>num_beams = config.get('num_beams', 1)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/predict/#instanovo.transformer.predict.TransformerPredictor.save_beams","title":"<code>save_beams = config.get('save_beams', False)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/predict/#instanovo.transformer.predict.TransformerPredictor.load_model","title":"<code>load_model() -&gt; Tuple[nn.Module, DictConfig]</code>","text":"<p>Setup the model.</p>"},{"location":"API/transformer/predict/#instanovo.transformer.predict.TransformerPredictor.setup_data_processor","title":"<code>setup_data_processor() -&gt; DataProcessor</code>","text":"<p>Setup the data processor.</p>"},{"location":"API/transformer/predict/#instanovo.transformer.predict.TransformerPredictor.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/transformer/predict/#instanovo.transformer.predict.TransformerPredictor.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; dict[str, Any]</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/transformer/train/","title":"Train","text":""},{"location":"API/transformer/train/#instanovo.transformer.train","title":"<code>train</code>","text":""},{"location":"API/transformer/train/#instanovo.transformer.train.logger","title":"<code>logger = ColorLog(console, __name__).logger</code>  <code>module-attribute</code>","text":""},{"location":"API/transformer/train/#instanovo.transformer.train.CONFIG_PATH","title":"<code>CONFIG_PATH = Path(__file__).parent.parent / 'configs'</code>  <code>module-attribute</code>","text":""},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer","title":"<code>TransformerTrainer(config: DictConfig)</code>","text":"<p>               Bases: <code>AccelerateDeNovoTrainer</code></p> <p>Trainer for the InstaNovo model.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.loss_fn","title":"<code>loss_fn = nn.CrossEntropyLoss(ignore_index=0)</code>  <code>instance-attribute</code>","text":""},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.setup_model","title":"<code>setup_model() -&gt; nn.Module</code>","text":"<p>Setup the model.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.update_vocab","title":"<code>update_vocab(model_state: dict[str, torch.Tensor]) -&gt; dict[str, torch.Tensor]</code>","text":"<p>Update the vocabulary of the model.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.setup_optimizer","title":"<code>setup_optimizer() -&gt; torch.optim.Optimizer</code>","text":"<p>Setup the optimizer.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.setup_decoder","title":"<code>setup_decoder() -&gt; Decoder</code>","text":"<p>Setup the decoder.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.setup_data_processors","title":"<code>setup_data_processors() -&gt; tuple[DataProcessor, DataProcessor]</code>","text":"<p>Setup the datasets.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.add_checkpoint_state","title":"<code>add_checkpoint_state() -&gt; dict[str, Any]</code>","text":"<p>Add checkpoint state.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.save_model","title":"<code>save_model(is_best_checkpoint: bool = False) -&gt; None</code>","text":"<p>Save the model.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.forward","title":"<code>forward(batch: Any) -&gt; tuple[torch.Tensor, dict[str, torch.Tensor]]</code>","text":"<p>Forward pass for the model to calculate loss.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.TransformerTrainer.get_predictions","title":"<code>get_predictions(batch: Any) -&gt; tuple[list[str] | list[list[str]], list[str] | list[list[str]]]</code>","text":"<p>Get the predictions for a batch.</p>"},{"location":"API/transformer/train/#instanovo.transformer.train.main","title":"<code>main(config: DictConfig) -&gt; None</code>","text":"<p>Train the model.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/","title":"Winnow: calibrated confidence and FDR control for de novo sequencing","text":"<p>Originally published at instanovo.ai on November 4 2025.</p> <p>De novo peptide sequencing (DNS) models have advanced rapidly in recent years, enabling the translation of mass spectra into peptide sequences without relying on prior databases. This capability enabled by deep learning has opened the door to discovering novel peptides, exploring uncharacterised proteomes, and expanding applications across metaproteomics and immunopeptidomics.</p> <p>Ensuring the reliability of these discoveries depends on accurate false discovery rate (FDR) estimation, a measure of how many reported peptide identifications are likely incorrect. In traditional proteomics, FDR control is central to trust in the biological interpretation of results and reproducibility. FDR estimation is typically achieved using target\u2013decoy methods, such approaches however are not directly compatible with DNS, where the sequence space is effectively unlimited.</p> <p>Existing attempts to estimate FDR in DNS often rely on fitting assumed score distributions to separate correct from incorrect peptide\u2013spectrum matches (PSMs), an approach that can bias results and limit generalisability. Others extrapolate confidence thresholds from database-labelled subsets to unlabelled spectra, a brittle solution when score distributions differ.Our new framework Winnow brings principled, model-agnostic FDR estimation and calibration to DNS. By grounding error control in statistical theory while avoiding strong distributional assumptions, Winnow offers a more general and robust approach to confidence calibration in de novo peptide predictions.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#what-is-winnow-and-how-does-it-work","title":"What is Winnow and how does it work?","text":"<p>Winnow is a model-agnostic framework for computing posterior error probabilities (PEPs), q-values, and experiment-wide FDR without relying on parametric assumptions or database search labels.</p> <p></p> <p></p> <p> </p> <p>Figure 1: Overview of the Winnow framework for FDR estimation in DNS. A) At the core of the Winnow algorithm is a calibrator model that predicts the likelihood of a PSM being correct, based on features derived from both model outputs and experimental spectra. The model used database search labels for training. Score calibration allows us to estimate FDR and other metrics more accurately, retrieve more correct predictions at lower FDR, and generalise the scoring strategy across models and datasets. B) Schematic showing standard usage of Winnow. The tool takes MS/MS scan information (precursor mass, precursor charge, mass-to-charge and intensity values), DNS predictions, and optionally a database search result for the same MS files for calibration. The Winnow framework includes feature calculation, database label matching and calibration. Winnow then applies a neural network to assign probabilities of each PSM being correct. This calibrated confidence is then used to non-parametrically estimate FDR. C) The experiment-wide error metrics, FDR and PEP, and D) spectrum-specific metrics are calculated and reported by Winnow, allowing filtering at both levels. Figure made with Biorender.com.</p> <p>Designed as a lightweight calibration and rescoring layer, Winnow can be applied to any DNS model to improve the reliability of its predictions. The framework follows four main stages:</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#input-and-inference","title":"Input and inference","text":"<p>A DNS tool such as InstaNovo generates PSMs and assigns an initial confidence score to each prediction. These raw scores indicate model confidence but are not always well-calibrated probabilities of correctness.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#feature-computation","title":"Feature computation","text":"<p>Winnow complements each candidate PSM with additional information derived from both the mass spectrometry data and the model output (Figure 2). These supplementary features capture experimental evidence and prediction dynamics that improve calibration accuracy.</p> <p>Examples include:</p> <ul> <li>Precursor mass error, the deviation between observed and theoretical precursor masses</li> <li>Fragment-ion match counts and intensities for the top and runner-up predictions</li> <li>Retention-time error, comparing the iRT value predicted from the peptide sequence using the Prosit model with the iRT value predicted by a neural network trained to map observed retention times to iRT</li> <li>Beam-search statistics such as margin, median margin, entropy and z-score, which quantify uncertainty within the model's candidate predictions</li> </ul> <p>Together, these features provide a broader representation of each PSM than the DNS score alone.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#score-calibration","title":"Score calibration","text":"<p>Next, Winnow applies a feed-forward neural network that learns to map each PSM's raw confidence and features to a calibrated probability that the sequence is correct. By combining evidence from both the DNS model and experimental metadata, this step converts raw, model-specific scores into probabilities that are interpretable and consistent across datasets. The calibrator is trained using reference identifications from database searches but generalises beyond them, enabling accurate calibration even for unlabelled spectra.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#fdr-estimation","title":"FDR estimation","text":"<p>Finally, Winnow estimates error rates using a non-parametric FDR estimator that avoids fitting score distributions or assuming prior class ratios. Instead, it integrates directly over calibrated probabilities to calculate PSM-specific and experiment-wide FDR, providing trustworthy, statistically principled control of false discoveries. Winnow also includes a database-grounded estimator, which uses database search matches as reference labels but relies on extrapolation to unlabelled data, making it less stable in certain settings.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#built-for-flexibility-and-trust","title":"Built for flexibility and trust","text":"<p>Beyond the core workflow, Winnow was designed around several key principles that make it adaptable across models, datasets, and experimental conditions.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#flexible-calibration-modes","title":"Flexible calibration modes","text":"<p>Winnow can be applied zero-shot using a pretrained calibrator, fine-tuned on a specific dataset, or retrained from scratch. This flexibility allows adaptation to diverse experimental conditions and instruments. Users can also customise its feature set, disabling less informative inputs or adding new, experiment-specific ones.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#model-agnostic-architecture","title":"Model-agnostic architecture","text":"<p>Winnow treats the DNS model as a black box. It makes no assumptions about the model's internals or scoring function, meaning it can be seamlessly layered onto any existing DNS tool to improve reliability and confidence calibration.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#non-parametric-label-free-fdr-control","title":"Non-parametric, label-free FDR control","text":"<p>Traditional FDR estimation often relies on decoy databases or fitted score distributions. Winnow's estimator takes a different route: it uses calibrated probabilities directly, sidestepping distributional assumptions and removing the need for reference labels. A new formulation of FDR</p> <p>At its core, Winnow introduces a discriminative decomposition of FDR, a conceptual advance in proteomics. By directly modelling the probability that a candidate PSM is incorrect, Winnow reframes FDR estimation in a purely discriminative setting, grounding its error control in statistical first principles rather than approximations.</p> <p> </p> <p>Figure 2: Feature contributions during calibration. SHAP feature importance scores for the general model, grouped by feature clusters created with an XGBoost model, with a cutoff for distances less than 0.5. Distance in the clustering is assumed to be scaled roughly between 0 and 1, where a 0 distance means the features are perfectly redundant and 1 means they are completely independent. The most important features are margin between top and runner-up beam predictions, fragment ion match rate and precursor mass error.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#winnow-instanovo","title":"Winnow + InstaNovo","text":"<p>InstaDeep's InstaNovo already delivers high-performing de novo peptide sequencing and provides an ideal testbed for evaluating Winnow's impact.</p> <p>Applying the Winnow calibrator to InstaNovo's raw confidence scores leads to a clear performance gain: recall increases at fixed FDR thresholds, meaning more correct PSMs are recovered while maintaining strict error control.</p> <p>Winnow's decoy-free FDR estimator also tracks true false discovery rates when benchmarked against reference proteomes and traditional database search pipelines (Figure 3). This demonstrates that accurate FDR control can be achieved without relying on target\u2013decoy methods or parametric score models.Across diverse datasets, the pairing of Winnow and InstaNovo consistently improves confidence calibration, yielding trustworthy error control. Together, they form a powerful combination: InstaNovo pushes the boundaries of peptide discovery, and Winnow ensures those discoveries can be trusted.</p> <p> </p> <p> </p> <p> </p> <p>Figure 3: Performance of Winnow's calibrator and FDR estimation methods on an unseen dataset: C. elegans. A) Precision-recall curves for the subset of C. elegans that received database search labels, comparing raw DNS model confidence and calibrated confidence. B) Precision-recall curves for the full C. elegans dataset using correct proteome mapping as a proxy for correct PSM identification. C) PSM-specific FDR run plots for Winnow's non-parametric and database-grounded FDR estimation methods on the labelled subset of C. elegans. D) PSM-specific FDR run plots on the full, unlabelled subset of C. elegans. E) Calibration curves for the labelled subset of the C. elegans dataset, comparing calibrated and raw DNS model confidence. F) Calibration curves for the full C. elegans dataset.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#what-this-means","title":"What this means","text":"<p>Winnow introduces a practical and statistically grounded framework for trustworthy, comparable peptide discovery in DNS. By enabling calibrated confidence scores and non-parametric FDR estimation, it bridges a long-standing gap between database-driven validation and open-space DNS.</p> <p>Beyond improving individual model performance, Winnow lays the foundation for a shared calibration layer across DNS tools, standardising confidence scales, simplifying model comparison, and enhancing interoperability throughout proteomics workflows.</p> <p>Looking ahead, we aim to broaden Winnow's generalisability across instruments, fragmentation methods, and sample types, exploring richer feature sets and alternative calibrator architectures. We also envision multi-model calibration, where Winnow has the potential to jointly align outputs from several DNS or search engines into unified, statistically consistent confidence estimates.</p>"},{"location":"blog/calibrated-confidence-and-fdr-control-for-de-novo-sequencing/#how-to-try-winnow","title":"How to try Winnow","text":"<p>Winnow is available now as the open-source Python package winnow-fdr complete with a command-line interface and detailed documentation. To use it:</p> <ol> <li>Run InstaNovol to generate peptide predictions and confidence scores.</li> <li>Compute PSM-level features with Winnow (mass error, fragment-ion match statistics, etc.).</li> <li>Apply the Winnow calibrator (or train your own) to transform raw scores into calibrated probabilities.</li> <li>Use Winnow's decoy- and label-free estimator to compute PEP, q-values, and experiment-wide FDR.</li> <li>Filter or rank results using these calibrated metrics.</li> </ol> <p>For full details, read our paper and explore the Winnow codebase.</p> <p>Disclaimer: All claims made are supported by our research paper: De novo peptide sequencing rescoring and FDR estimation with Winnow unless explicitly cited otherwise.</p>"},{"location":"blog/introducing-instanovo-p-a-de-novo-sequencing-model-for-phosphoproteomics/","title":"Introducing InstaNovo-P, a de novo sequencing model for phosphoproteomics","text":"<p>Originally published at instanovo.ai on May 22 2025.</p>"},{"location":"blog/introducing-instanovo-p-a-de-novo-sequencing-model-for-phosphoproteomics/#announcing-instanovo-p","title":"Announcing InstaNovo-P","text":"<p>We are happy to share our newest model in the InstaNovo family, InstaNovo-P in our latest bioRxiv preprint.</p> <p>InstaNovo-P is a fine-tuned version of our base model, InstaNovo v1.0.0, specifically tailored towards application in phosphoproteomics mass spectrometry experiments. InstaNovo-P was further trained on approx. 2.8 million PSMs from 75 thousand phosphorylated peptides. InstaNovo-P was extended to recognize the residues phospho-tyrosine, -serine and -threonine, achieving high accuracy in detecting phosphorylated peptides while retaining its performance in unmodified peptides.</p>"},{"location":"blog/introducing-instanovo-p-a-de-novo-sequencing-model-for-phosphoproteomics/#benchmarking-instanovo-p","title":"Benchmarking InstaNovo-P","text":"<p>InstaNovo-P performs better than the current state of the art de novo sequencing model that supports phosphorylation, PrimeNovo. It also performs better than the base InstaNovo v1.0.0 model in the test dataset of the ProteomeTools dataset used for training the base model, indicating that our gradual unfreezing strategy while fine tuning prevented loss of performance in unmodified peptides (Figure 1A). InstaNovo-P exhibits state-of-the-art performance on detection of phosphorylated peptides (Figure 1B).</p> <p></p>"},{"location":"blog/introducing-instanovo-p-a-de-novo-sequencing-model-for-phosphoproteomics/#instanovo-p-performance-varies-with-phosphorylation-types","title":"InstaNovo-P performance varies with phosphorylation types","text":"<p>We investigated performance of the model across peptides with different properties. InstaNovo-P performed better in detection of peptides with phosphorylated serines, which reflected the composition of our training dataset (Figure 2A). We also observed performance dependence on peptide length, as well as number of phosphorylation sites present on phosphorylated peptides (Figure 2B). These results indicate that InstaNovo-P presents similar behaviour to our base model, and that additional training data would increase performance on other phosphorylated threonine and tyrosine.</p> <p></p>"},{"location":"blog/introducing-instanovo-p-a-de-novo-sequencing-model-for-phosphoproteomics/#instanovo-p-enhances-localization-confidence-and-captures-biological-pathways","title":"InstaNovo-P enhances localization confidence and captures biological pathways","text":"<p>We found that InstaNovo-P captures a substantial amount of phosphorylated peptides with low false discovery thresholds (&lt; 5% FDR as assessed by database search result grounding). When validating our model with an external dataset of FGFR2 signaling in breast cancer cells, we find that InstaNovo-P exhibits 66.5% recall overall, with 41.2% recall at 5% FDR (Figure 3A). Notably, we show that we can detect phosphorylation events in crucial proteins that participate in FGFR2 signaling, and our detected events recapitulate the pathways involved. Additionally, we observed high correlation of phosphorylation localization when compared to database search (Figure 3B). This indicates that InstaNovo-P is adept at localizing phosphorylation in peptides that contain more than one possible site, and provides another axis of information that can enhance localization certainly.</p> <p></p>"},{"location":"blog/introducing-instanovo-p-a-de-novo-sequencing-model-for-phosphoproteomics/#instanovo-p-provides-value-to-phosphoproteomics-experiments","title":"InstaNovo-P provides value to phosphoproteomics experiments","text":"<p>Importantly, InstaNovo detects a considerable number of peptides that go undetected with database approaches (Figure 4A). We could verify the presence of these peptides by targeted proteomics in independent samples, corroborating our predictions (Figure 4B).</p> <p></p> <p>Together, our results suggest that InstaNovo-P can provide complementary information to phosphoproteomics database searches, by detecting novel peptides and enhancing localization certainty. The new release of our base model, InstaNovo v1.1 has already been trained with the phosphorylation dataset used to fine tune this model, and now supports phosphorylation, with comparable performance to InstaNovo-P across datasets. We will continue to develop models for important applications of de novo peptide sequencing in proteomics, and expand the supported post translational modifications further. We look forward to researchers using our models for deeper and more robust biological insights in proteomics!</p> <p>Source of all images: internal</p>"},{"location":"blog/introducing-the-next-generation-of-instanovo-models/","title":"Introducing the next generation of InstaNovo models","text":"<p>Originally published at instanovo.ai on April 9 2025.</p>"},{"location":"blog/introducing-the-next-generation-of-instanovo-models/#announcing-instanovo-v11","title":"Announcing InstaNovo v1.1","text":"<p>Since our InstaNovo paper is now published, we'd like to share an update on what we've been working on while our manuscript was under review. With the release of our preprint over a year ago, we were overwhelmed by the response from the community and the applications of our models. We are actively collaborating with experts and continue to explore the potential of solutions for de novo peptide sequencing. Our ongoing efforts focus on developing more accurate models, expanding the de novo sequencing ecosystem for analysis and data reporting, fine-tuning our models, and designing tailored, application-specific workflows.</p> <p>While much of this work is still in progress, we have just released an improved version of our base model, InstaNovo v1.1. This model boasts higher recall, greater identification certainty, expanded support for modifications, and enhanced data processing and reporting features. We believe these advancements are worth communicating with this post instead of an article, and we are excited to show you how this model compares to the earlier model in our paper.</p>"},{"location":"blog/introducing-the-next-generation-of-instanovo-models/#getting-started","title":"Getting started","text":"<p>Our new model is available in the main InstaNovo branch with detailed documentation on installation, local execution, and running it in training or testing mode with your data. If you prefer a hosted solution, you can access the model via our HuggingFace space, where you can upload your files and analyse them on free GPU compute. To reproduce the analysis in this blog post or to run this analysis on your own dataset, refer to this Jupyter notebook.</p>"},{"location":"blog/introducing-the-next-generation-of-instanovo-models/#training-data","title":"Training data","text":"<p>InstaNovo v1.1 (IN v1.1) has been trained on the ProteomeTools, MassiveKB, and kind dataset contributions from several other projects processed by the CompOmics group at Ghent University. We are grateful for the huge community effort to generate, process, and curate the datasets that have enabled the development of our models. We are excited to contribute with the release of this combined dataset in the near future.</p>"},{"location":"blog/introducing-the-next-generation-of-instanovo-models/#benchmarking-in-v11","title":"Benchmarking IN v1.1","text":"<p>IN v1.1 is a substantial improvement over IN v0.1, the original model from our paper. To benchmark these models, we used a standard HeLa proteome run, a widely used reference sample in proteomics facilities for quality control and one of the validation datasets in our study.</p> <p>Compared to the gold standard database search, IN v0.1 achieved a recall of 49.5%. IN v1.1, using greedy precursor mass fit search (i.e. selecting the sequence that best fits the observed precursor mass), improves recall to 56.7%, while knapsack beam search further boosts recall to 63%. This compounds to a 13.5% improvement over the previous model, with more than six out of ten peptides being detected without precursor mass filtering on predictions (Figure 1a). Additionally, IN v1.1 predicts 42.6% more Peptide Spectrum Matches (PSMs) that map to the proteome with exact sequence matching (Figure 1b).</p> <p></p> <p>We use peptide-level metrics and especially recall to assess our models, the most direct evaluation of prediction performance. This is because bottom up proteomics is a peptide centric methodology, where the percent accuracy within the peptide chain is not particularly informative. Crucially, we evaluate whether the complete sequence prediction is correct.</p> <p>The distribution of model confidence, defined as the product of our residue log probabilities raised in its natural exponent, indicates that the new model is sharper in its prediction certainty. We observe more high confidence predictions being correct, while lower confidence predictions are more densely clustered in the lower confidence range (Figure 2a). Accordingly, we observe better precision values in parallel with increased coverage (Figure 2b).</p> <p></p> <p>While it is still unclear whether this trend will persist with larger training datasets and increasing model sizes, this pattern suggests that confidence-based thresholding can help reduce false positive rates.</p> <p>We use this precision to estimate the false discovery rate (FDR) and derive confidence cutoffs for low false identifications, which yield identification results aligned with conventional proteomics search outputs. In agreement with our confidence analysis, we observe that lower confidence thresholds are required to maintain a 5% FDR (Figure 3a). At the same threshold, IN v1.1 identifies more novel PSMs compared to its predecessor (Figure 3b).</p> <p></p> <p>To assess FDR more directly, we mapped predicted PSMs to the human proteome. As expected, we observed an increased proportion of PSMs mapping to the proteome, with the greatest improvements in the high confidence range (Figure 4a). Additionally, when comparing the ratio of mapped to unmapped predictions, IN v1.1 demonstrates a considerable reduction in false positive rates (Figure 4b, dashed line indicates 5% FDR when directly mapping to proteome without database grounding).</p> <p></p> <p>Due to this higher discrimination of false positives and PSMs in the model confidence scale, IN v1.1 identifies 145.1% more peptides mapping to the proteome at 5% FDR compared to its precursor (Figure 5a), leading to a 35.3% increase in protein identifications with the same threshold (Figure 5b).</p> <p></p>"},{"location":"blog/introducing-the-next-generation-of-instanovo-models/#expanded-modification-support-features-and-runtime","title":"Expanded modification support, features and runtime","text":"<p>The IN v1.1 release introduces compatibility with four additional modifications: phosphorylation, deamidation, carbamylation, and ammonia loss. Carbamidomethylation is now a variable modification, with variable acetylation and oxidation also supported. This results in an increase in overall peptide sequence predictions (Figure 6a), with a substantial number of high confidence predictions at 5% FDR, even in samples without enrichment (Figure 6b). For large datasets, especially when prioritising high-confidence results, there is a tradeoff between performance and inference time (Figure 6c). Despite linear scaling, knapsack precursor fit takes 36 times longer than greedy precursor fit per spectrum. While knapsack beam search provides the best performance, it comes at a steep computational cost. In many cases, running the model with greedy precursor mass search may be more efficient while still delivering robust results.</p> <p></p> <p>In the updated version, a spectrum dataframe class has been introduced to further improve data import robustness and interoperability. Residue log probabilities are now included in the results alongside the token list, and scan number and precursor mass error (in ppm) are now also included in the output table. The model also supports evaluation mode with a database search reference, where FDR confidence thresholds are automatically reported during inference. In the new model, leucine and isoleucine are predicted as separate residue tokens, albeit with relatively low recall at peptide level (17.7% for leucine and 19.6% for isoleucine).</p>"},{"location":"blog/introducing-the-next-generation-of-instanovo-models/#performance-on-other-datasets-and-outlook","title":"Performance on other datasets and outlook","text":"<p>Although here we focus on a single dataset, we have observed similar performance gains across biological samples and applications (Figure 7), indicating generalized gains. Importantly, we observe a 81.3% peptide recall in our GluC dataset, which is a GluC pretreated HeLa proteome with more data than the HeLa QC above.</p> <p></p> <p>We believe our models continue to improve in performance, and we have yet to determine the upper limit for database search recall and novel identification rates. Our goal is to achieve robust accuracy near the 90% recall mark across experimental datasets, edging closer to solving de novo peptide sequencing. We will continue to scale and refine our models, as well as explore biological applications and features further. Additionally, the next generation of IN+, our diffusion model, is being trained and will be released soon.</p> <p>So stay tuned for more updates, several preprints coming out soon!</p> <p>Source of all images: internal</p> <p>Original research paper available at: InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale proteomics experiments</p>"},{"location":"development/allure/","title":"Test Report","text":""},{"location":"development/setup/","title":"For Developers","text":"<p>This guide is for developers who want to contribute to InstaNovo or set up a development environment.</p> <p>InstaNovo is built for Python &gt;=3.10, &lt;3.14 and tested on Linux, Windows and macOS.</p>"},{"location":"development/setup/#setting-up-with-uv","title":"Setting up with <code>uv</code>","text":"<p>This project uses uv to manage Python dependencies.</p> <ol> <li> <p>Install <code>uv</code>: If you don't have <code>uv</code> installed, follow the official installation instructions.</p> </li> <li> <p>Fork and clone the repository:</p> <pre><code>git clone https://github.com/YOUR-USERNAME/InstaNovo.git\ncd InstaNovo\n</code></pre> </li> <li> <p>Install dependencies:</p> <p>If you have an NVIDIA GPU:</p> <pre><code>uv sync --extra cu126\nuv run pre-commit install\n</code></pre> <p>If you are on a CPU-only, or macOS machine:</p> <pre><code>uv sync --extra cpu\nuv run pre-commit install\n</code></pre> <p>To also install the documentation dependencies:</p> <pre><code>uv sync --extra cu126 --group docs\n</code></pre> </li> <li> <p>Activate the virtual environment:</p> <pre><code>source .venv/bin/activate\n</code></pre> </li> </ol>"},{"location":"development/setup/#metal-performance-shaders","title":"Metal Performance Shaders","text":"<p>InstaNovo now has support for Metal Performance Shaders (MPS) for Apple silicon devices. If you would like to use InstaNovo with MPS, please set <code>mps</code> to True in the configuration files (<code>instanovo/configs/</code>) and set the environment variable:</p> <pre><code>PYTORCH_ENABLE_MPS_FALLBACK=1\n</code></pre> <p>This allows the CPU to be used for functionality not yet supported on MPS.</p>"},{"location":"development/setup/#development-workflows","title":"Development workflows","text":""},{"location":"development/setup/#testing","title":"Testing","text":"<p>InstaNovo uses <code>pytest</code> for testing.</p> <ol> <li> <p>Download test data:</p> <pre><code>uv run instanovo/scripts/get_zenodo_record.py\n</code></pre> </li> <li> <p>Run tests:</p> <pre><code>python -m pytest --cov-report=html --cov --random-order --verbose .\n</code></pre> </li> <li> <p>View coverage report:</p> <pre><code>python -m coverage report -m\n</code></pre> </li> </ol>"},{"location":"development/setup/#linting","title":"Linting","text":"<p>We use <code>pre-commit</code> hooks to maintain code quality. To run the linters on all files:</p> <pre><code>pre-commit run --all-files\n</code></pre>"},{"location":"development/setup/#building-the-documentation","title":"Building the documentation","text":"<p>To build and serve the documentation locally:</p> <pre><code>uv sync --extra cu126 --group docs\ngit config --global --add safe.directory \"$(dirname \"$(pwd)\")\"\nrm -rf docs/API\npython ./docs/gen_ref_nav.py\nmkdocs build --verbose --site-dir docs_public\nmkdocs serve\n</code></pre>"},{"location":"explanation/performance/","title":"Explanation: InstaNovo Performance","text":"<p>This document provides an overview of InstaNovo's performance on various benchmark datasets.</p>"},{"location":"explanation/performance/#performance-metrics","title":"Performance Metrics","text":"<p>We evaluate the performance of InstaNovo using peptide accuracy. This metric measures the percentage of correctly predicted peptide sequences at full coverage (i.e., without any confidence filtering).</p>"},{"location":"explanation/performance/#benchmarks","title":"Benchmarks","text":"<p>We have benchmarked InstaNovo v1.1 and InstaNovo+ v1.1 against our previous models. For all results, InstaNovo decoding was performed with knapsack beam search decoding, and InstaNovo+ was used for refinement.</p>"},{"location":"explanation/performance/#nine-species-dataset","title":"Nine-species dataset","text":"<p>This dataset contains spectra from nine different species. The models were evaluated in a zero-shot setting (i.e., without any fine-tuning on the test species).</p> Dataset InstaNovo v0.1 InstaNovo+ v0.1 InstaNovo v1.1 InstaNovo+ v1.1 Bacillus 0.624 0.674 0.652 0.684 Mouse 0.466 0.490 0.524 0.542 Yeast 0.559 0.624 0.618 0.645"},{"location":"explanation/performance/#biological-validation-datasets","title":"Biological validation datasets","text":"<p>We also evaluated the models on a variety of challenging biological datasets.</p> Dataset InstaNovo v0.1 InstaNovo+ v0.1 InstaNovo v1.1 InstaNovo+ v1.1 HeLa degradome 0.695 0.719 0.813 0.821 HeLa single-shot 0.503 0.517 0.642 0.647 Herceptin 0.494 0.562 0.710 0.720 Immunopeptidomics 0.581 0.697 0.707 0.748 Candidatus \"Scalindua brodae\" 0.724 0.736 0.748 0.762 Snake venoms 0.196 0.198 0.221 0.238 Nanobodies 0.447 0.464 0.492 0.508 Wound fluids 0.225 0.229 0.354 0.364 <p>As the results show, InstaNovo+ v1.1 consistently outperforms the previous models across all datasets.</p>"},{"location":"explanation/spectrum_data_frame/","title":"Explanation: The SpectrumDataFrame","text":"<p>At the core of InstaNovo's data handling is the <code>SpectrumDataFrame</code>. This document provides a more detailed explanation of this class and its features.</p>"},{"location":"explanation/spectrum_data_frame/#what-is-it","title":"What is it?","text":"<p>The <code>SpectrumDataFrame</code> is a specialized data structure designed to provide a unified and efficient interface for working with mass spectrometry data. It acts as a wrapper around various data sources, including:</p> <ul> <li>Standard mass spectrometry files (<code>.mgf</code>, <code>.mzml</code>, <code>.mzxml</code>)</li> <li>Tabular data files (<code>.csv</code>, <code>.parquet</code>)</li> <li>In-memory Pandas and Polars DataFrames</li> </ul> <p>By providing a single API, the <code>SpectrumDataFrame</code> simplifies the process of loading, processing, and iterating over spectral data, regardless of its original format.</p>"},{"location":"explanation/spectrum_data_frame/#key-features","title":"Key Features","text":""},{"location":"explanation/spectrum_data_frame/#glob-notation-support","title":"Glob Notation Support","text":"<p>The <code>SpectrumDataFrame</code> natively supports glob notation when specifying data paths. This allows you to easily reference multiple files at once using wildcard patterns. All supported file formats are automatically detected and converted to the internal SpectrumDataFrame format for training and inference.</p> <p>For example, you can use glob notation to process all MGF files in a directory:</p> <pre><code>instanovo predict --data_path=./experiment/*.mgf\n</code></pre> <p>You can also specify glob patterns in your configuration files to process multiple files across different directories or with different extensions:</p> <pre><code># In your config file\ndata_path: \"./experiment/**/*.mzml\"\n</code></pre> <p>This flexibility makes it easy to work with large datasets organized across multiple files and directories without having to manually list each file.</p>"},{"location":"explanation/spectrum_data_frame/#lazy-loading-and-asynchronous-prefetching","title":"Lazy Loading and Asynchronous Prefetching","text":"<p>When working with large datasets, it's often not feasible to load all the data into memory at once. The <code>SpectrumDataFrame</code> addresses this with lazy loading. When lazy loading is enabled, the <code>SpectrumDataFrame</code> only loads the data for the files that are currently being accessed. This allows you to work with datasets that are much larger than your available RAM.</p> <p>To further improve performance, the <code>SpectrumDataFrame</code> uses asynchronous prefetching. This means that while you are processing the data from one file, the <code>SpectrumDataFrame</code> is already loading the next file in the background. This helps to minimize I/O wait times and keep your GPU busy during training.</p>"},{"location":"explanation/spectrum_data_frame/#efficient-shuffling","title":"Efficient Shuffling","text":"<p>Effective shuffling of training data is crucial for training robust models. The <code>SpectrumDataFrame</code> implements a two-fold shuffling strategy:</p> <ol> <li>File-level shuffling: The order of the files to be loaded is shuffled.</li> <li>Within-file shuffling: The spectra within each file are also shuffled.</li> </ol> <p>This ensures that the model sees a diverse range of data in each training epoch.</p>"},{"location":"explanation/spectrum_data_frame/#on-the-fly-filtering-and-sampling","title":"On-the-fly Filtering and Sampling","text":"<p>The <code>SpectrumDataFrame</code> allows you to perform filtering and sampling operations without modifying the underlying data on disk. You can apply filters to select specific spectra based on their properties (e.g., precursor charge) or sample a subset of your data for quick experiments.</p> <pre><code>from instanovo.utils import SpectrumDataFrame\n\n# Load a dataset with lazy loading\nsdf = SpectrumDataFrame.load(\"/path/to/experiment/*.mzml\", lazy=True)\n\n# Keep only spectra with a precursor charge of 2 or less\nsdf.filter_rows(lambda row: row[\"precursor_charge\"] &lt;= 2)\n\n# Sample 50% of the data\nsdf.sample_subset(fraction=0.5, seed=42)\n</code></pre>"},{"location":"explanation/spectrum_data_frame/#interoperability","title":"Interoperability","text":"<p>The <code>SpectrumDataFrame</code> is designed to be interoperable with other popular data science libraries. You can easily convert a <code>SpectrumDataFrame</code> to a Pandas DataFrame or a Polars LazyFrame:</p> <pre><code># Convert to a Pandas DataFrame\npandas_df = sdf.to_pandas()\n\n# Convert to a Polars LazyFrame\npolars_lazy_df = sdf.to_polars(return_lazy=True)\n</code></pre> <p>You can also write the contents of a <code>SpectrumDataFrame</code> to an <code>.mgf</code> file:</p> <pre><code>sdf.write_mgf(\"path/to/output.mgf\")\n</code></pre>"},{"location":"explanation/spectrum_data_frame/#example-usage","title":"Example usage","text":"<p>Converting mgf files to the native parquet format:</p> <pre><code>from instanovo.utils import SpectrumDataFrame\n\n# Convert mgf files to native parquet:\nsdf = SpectrumDataFrame.load(\"/path/to/data.mgf\", lazy=False, is_annotated=True)\nsdf.save(\"path/to/parquet/folder\", partition=\"train\", chunk_size=1e6)\n</code></pre> <p>Loading the native format in shuffle mode:</p> <pre><code># Load a native parquet dataset:\nsdf = SpectrumDataFrame.load(\"path/to/parquet/folder\", partition=\"train\", shuffle=True, lazy=True, is_annotated=True)\n</code></pre> <p>Using the loaded SpectrumDataFrame in a PyTorch DataLoader:</p> <pre><code>from instanovo.transformer.dataset import SpectrumDataset\nfrom torch.utils.data import DataLoader\n\nds = SpectrumDataset(sdf)\n# Note: Shuffle and workers is handled by the SpectrumDataFrame\ndl = DataLoader(\n    ds,\n    collate_fn=SpectrumDataset.collate_batch,\n    shuffle=False,\n    num_workers=0,\n)\n</code></pre> <p>Some more examples using the SpectrumDataFrame:</p> <pre><code>sdf = SpectrumDataFrame.load(\"/path/to/experiment/*.mzml\", lazy=True)\n\n# Remove rows with a charge value &gt; 3:\nsdf.filter_rows(lambda row: row[\"precursor_charge\"]&lt;=2)\n\n# Sample a subset of the data:\nsdf.sample_subset(fraction=0.5, seed=42)\n\n# Convert to pandas\ndf = sdf.to_pandas() # Returns a pd.DataFrame\n\n# Convert to polars LazyFrame\nlazy_df = sdf.to_polars(return_lazy=True) # Returns a pl.LazyFrame\n\n# Save as an `.mgf` file\nsdf.write_mgf(\"path/to/output.mgf\")\n</code></pre>"},{"location":"how-to/predicting/","title":"How-to: Make Predictions with InstaNovo","text":"<p>This guide covers various ways to make predictions with InstaNovo, including using different models and customizing the prediction process.</p>"},{"location":"how-to/predicting/#basic-prediction","title":"Basic Prediction","text":"<p>The most straightforward way to make predictions is to use the <code>instanovo predict</code> command. This command runs both the InstaNovo transformer model and the InstaNovo+ diffusion model for refinement.</p> <pre><code>instanovo predict --data-path /path/to/your/spectra.mgf --output-path predictions.csv\n</code></pre> <p>Which results in the following output:</p> <pre><code>experiment_name,scan_number,spectrum_id,precursor_mz,precursor_charge,prediction_id,predictions,log_probs,token_log_probs,group,instanovo_predictions,instanovo_log_probabilities,instanovo_token_log_probabilities,instanovo_predictions_beam_0,instanovo_log_probabilities_beam_0,instanovo_token_log_probabilities_beam_0,instanovo_predictions_beam_1,instanovo_log_probabilities_beam_1,instanovo_token_log_probabilities_beam_1,instanovo_predictions_beam_2,instanovo_log_probabilities_beam_2,instanovo_token_log_probabilities_beam_2,instanovo_predictions_beam_3,instanovo_log_probabilities_beam_3,instanovo_token_log_probabilities_beam_3,instanovo_predictions_beam_4,instanovo_log_probabilities_beam_4,instanovo_token_log_probabilities_beam_4,diffusion_predictions,diffusion_log_probabilities,diffusion_token_log_probabilities,diffusion_unrefined_predictions,diffusion_predictions_beam_0,diffusion_log_probabilities_beam_0,diffusion_predictions_beam_1,diffusion_log_probabilities_beam_1,diffusion_predictions_beam_2,diffusion_log_probabilities_beam_2,diffusion_predictions_beam_3,diffusion_log_probabilities_beam_3,diffusion_predictions_beam_4,diffusion_log_probabilities_beam_4,predictions_tokenised,delta_mass_ppm\nspectra,0,spectra:0,451.25348,2,0,IAHYNKR,-0.0038739838637411594,,no_group,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-1.4490094184875488,[0],LAHYNKR,-1.4490094184875488,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],\"['I', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.0038739838637411594,,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.14114204049110413,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.055098626762628555,\"['I', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.0038739838637411594,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.06414960324764252,\"['I', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.10904442518949509,\"I, A, H, Y, N, K, R\",0.6781111138830191\n</code></pre> <p>This output CSV file contains several columns. Here are some of the most important ones:</p> Column Description <code>scan_number</code> The scan number of the spectrum in the input file. <code>precursor_mz</code> The mass-to-charge ratio of the precursor ion. <code>precursor_charge</code> The charge of the precursor ion. <code>diffusion_predictions</code> The peptide sequence predicted by InstaNovo+. <code>transformer_predictions</code> The peptide sequence predicted by the base InstaNovo model. <code>log_probs</code> The log probability of the prediction. Higher (less negative) values indicate greater model confidence in the predicted output. <p>For a full description of the output, see the prediction output reference.</p>"},{"location":"how-to/predicting/#evaluation","title":"Evaluation","text":"<p>To evaluate InstaNovo performance on an annotated dataset (a dataset which has a column with the ground truth sequence):</p> <pre><code>instanovo predict --evaluation --data-path ./sample_data/spectra.mgf --output-path predictions.csv\n</code></pre> <p>Which results in the following output:</p> <pre><code>experiment_name,scan_number,spectrum_id,precursor_mz,precursor_charge,prediction_id,predictions,targets,log_probs,token_log_probs,group,instanovo_predictions,instanovo_log_probabilities,instanovo_token_log_probabilities,instanovo_predictions_beam_0,instanovo_log_probabilities_beam_0,instanovo_token_log_probabilities_beam_0,instanovo_predictions_beam_1,instanovo_log_probabilities_beam_1,instanovo_token_log_probabilities_beam_1,instanovo_predictions_beam_2,instanovo_log_probabilities_beam_2,instanovo_token_log_probabilities_beam_2,instanovo_predictions_beam_3,instanovo_log_probabilities_beam_3,instanovo_token_log_probabilities_beam_3,instanovo_predictions_beam_4,instanovo_log_probabilities_beam_4,instanovo_token_log_probabilities_beam_4,diffusion_predictions,diffusion_log_probabilities,diffusion_token_log_probabilities,diffusion_unrefined_predictions,diffusion_predictions_beam_0,diffusion_log_probabilities_beam_0,diffusion_predictions_beam_1,diffusion_log_probabilities_beam_1,diffusion_predictions_beam_2,diffusion_log_probabilities_beam_2,diffusion_predictions_beam_3,diffusion_log_probabilities_beam_3,diffusion_predictions_beam_4,diffusion_log_probabilities_beam_4,predictions_tokenised,delta_mass_ppm\nspectra,0,spectra:0,451.25348,2,0,LAHYNKR,IAHYNKR,-0.03630233183503151,,no_group,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-1.4490094184875488,[0],LAHYNKR,-1.4490094184875488,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.03630233183503151,,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.3328973650932312,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.09905184805393219,\"['L', 'A', 'H', 'F', 'D', 'K', 'R']\",-1.303741455078125,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.1970413625240326,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.03630233183503151,\"L, A, H, Y, N, K, R\",0.6781111138830191\n</code></pre> <p>Note that the <code>--evaluation</code> flag includes the <code>targets</code> column in the output, which contains the ground truth peptide sequence. Metrics will be calculated and displayed in the console.</p>"},{"location":"how-to/predicting/#command-line-arguments","title":"Command-line arguments","text":"<p>InstaNovo provides several command-line arguments for common prediction parameters:</p> <ul> <li><code>--data-path</code>: Path to your spectral data. It can be a single file (<code>.mgf</code>, <code>.mzml</code>, <code>.mzxml</code>, <code>.ipc</code>) or a directory. You can also use glob patterns (e.g., <code>./experiment/*.mgf</code>).</li> <li><code>--output-path</code>: Path to the output CSV file.</li> <li><code>--instanovo-model</code>: The InstaNovo model to use. You can specify a model ID (e.g., <code>instanovo-v1.1.0</code>) or a path to a checkpoint file (<code>.ckpt</code>).</li> <li><code>--instanovo-plus-model</code>: The InstaNovo+ model to use. You can specify a model ID (e.g., <code>instanovoplus-v1.1.0</code>) or a path to a checkpoint file (<code>.ckpt</code>).</li> <li><code>--denovo</code>: Use this flag for de novo prediction on unannotated data.</li> <li><code>--evaluation</code>: Use this flag to evaluate the model on annotated data.</li> <li><code>--with-refinement</code> / <code>--no-refinement</code>: Whether to use InstaNovo+ for refinement (default is <code>True</code>).</li> </ul>"},{"location":"how-to/predicting/#overriding-configuration-values","title":"Overriding configuration values","text":"<p>InstaNovo uses configuration files for more advanced settings, located in <code>instanovo/configs/inference/</code>. The default configuration is <code>default.yaml</code>.</p> <p>You can override any value in the configuration file from the command line. For example, to change the number of beams used in beam search to 5, you would run:</p> <pre><code>instanovo predict --data-path ./sample_data/spectra.mgf --output-path predictions.csv num_beams=5\n</code></pre> <p>Note that there is no <code>--</code> prefix for configuration overrides.</p>"},{"location":"how-to/predicting/#advanced-prediction-scenarios","title":"Advanced Prediction Scenarios","text":""},{"location":"how-to/predicting/#running-only-instanovo-transformer","title":"Running only InstaNovo (Transformer)","text":"<p>If you want to run predictions using only the InstaNovo transformer model without the diffusion refinement, you can use the <code>instanovo transformer predict</code> command:</p> <pre><code>instanovo transformer predict --data-path /path/to/your/spectra.mgf --output-path instanovo_predictions.csv\n</code></pre> <p>To see all available options for this command, run:</p> <pre><code>instanovo transformer predict --help\n</code></pre>"},{"location":"how-to/predicting/#running-only-instanovo-diffusion","title":"Running only InstaNovo+ (Diffusion)","text":"<p>To run predictions using only the InstaNovo+ diffusion model, you can use the <code>instanovo diffusion predict</code> command. This is useful if you already have predictions from another model and want to refine them.</p> <pre><code>instanovo diffusion predict --data-path /path/to/your/spectra.mgf --output-path instanovoplus_predictions.csv instanovo_predictions_path=instanovo_predictions.csv\n</code></pre> <p>Here, <code>instanovo_predictions.csv</code> is a CSV file containing the initial predictions.</p> <p>To see all available options for this command, run:</p> <pre><code>instanovo diffusion predict --help\n</code></pre>"},{"location":"how-to/predicting/#two-step-prediction","title":"Two-step prediction","text":"<p>You can also run the prediction in two separate steps:</p> <ol> <li> <p>Run InstaNovo:</p> <pre><code>instanovo transformer predict --data-path ./sample_data/spectra.mgf --output-path instanovo_predictions.csv\n</code></pre> </li> <li> <p>Run InstaNovo+ for refinement:</p> <pre><code>instanovo diffusion predict --data-path ./sample_data/spectra.mgf --output-path instanovoplus_predictions.csv instanovo_predictions_path=instanovo_predictions.csv\n</code></pre> </li> </ol> <p>This approach gives you more control over the process and allows you to inspect the intermediate predictions from the transformer model.</p>"},{"location":"how-to/training/","title":"How-to: Train InstaNovo Models","text":"<p>This guide explains how to train your own InstaNovo and InstaNovo+ models.</p>"},{"location":"how-to/training/#preparing-your-data","title":"Preparing your data","text":"<p>Before you can start training, you need to have your data in a format that InstaNovo can understand. The easiest way to do this is to use the <code>SpectrumDataFrame</code>. See the how-to guide on using custom datasets for more details.</p>"},{"location":"how-to/training/#training-instanovo-transformer","title":"Training InstaNovo (Transformer)","text":"<p>The InstaNovo transformer model is the base model that performs the initial de novo sequencing.</p> <p>To train the transformer model, you use the <code>instanovo transformer train</code> command. The training process is configured using a YAML file. The default configuration file is <code>instanovo/configs/instanovo.yaml</code>.</p> <p>To start training with the default configuration, you would run:</p> <pre><code>instanovo transformer train\n</code></pre> <p>You will likely want to customize the training configuration, such as the paths to your training and validation data. You can do this by creating your own YAML file and passing it to the command, or by overriding specific values from the command line.</p> <p>For example, to specify the training and validation data paths, you could run:</p> <pre><code>instanovo transformer train --data.train_data_path /path/to/train/data --data.val_data_path /path/to/val/data\n</code></pre> <p>To see all the available options for the training command, run:</p> <pre><code>instanovo transformer train --help\n</code></pre> <p>To customize the model architecture, you can modify the model configuration file at <code>instanovo/configs/model/instanovo_base.yaml</code>.</p>"},{"location":"how-to/training/#training-instanovo-diffusion","title":"Training InstaNovo+ (Diffusion)","text":"<p>The InstaNovo+ diffusion model is used to refine the predictions made by the transformer model.</p> <p>Training the diffusion model is similar to training the transformer model. You use the <code>instanovo diffusion train</code> command, and the configuration is managed through a YAML file (default: <code>instanovo/configs/instanovoplus.yaml</code>).</p> <p>To start training the diffusion model, you would run:</p> <pre><code>instanovo diffusion train\n</code></pre> <p>Again, you can customize the configuration by providing your own YAML file or by overriding values from the command line.</p> <p>To see all the available options, run:</p> <pre><code>instanovo diffusion train --help\n</code></pre> <p>To customize the model architecture, you can modify the model configuration file at <code>instanovo/configs/model/instanovoplus_base.yaml</code>.</p>"},{"location":"how-to/using_custom_datasets/","title":"How-to: Use Your Own Datasets","text":"<p>InstaNovo is designed to be flexible and work with your own mass spectrometry data. This guide explains how to prepare your data for use with InstaNovo.</p>"},{"location":"how-to/using_custom_datasets/#the-spectrumdataframe","title":"The SpectrumDataFrame","text":"<p>InstaNovo uses a custom data structure called <code>SpectrumDataFrame</code> to handle spectral data. This class provides a unified interface for various common mass spectrometry file formats, including <code>.mgf</code>, <code>.mzml</code>, <code>.mzxml</code>, and <code>.csv</code>. It also supports reading data directly from Pandas or Polars DataFrames.</p> <p>One of the key features of the <code>SpectrumDataFrame</code> is its ability to handle large datasets that don't fit into memory. It does this through lazy loading, where data is loaded from disk only when it's needed.</p>"},{"location":"how-to/using_custom_datasets/#using-standard-file-formats","title":"Using standard file formats","text":"<p>The easiest way to use your own data is to provide it in one of the supported file formats. You can then pass the path to your data directly to the <code>instanovo predict</code> or <code>instanovo train</code> commands.</p> <p>You can specify a single file, a directory, or use glob patterns to specify multiple files:</p> <pre><code># Predict from a single MGF file\ninstanovo predict --data-path /path/to/your/data.mgf\n\n# Predict from all MGF files in a directory\ninstanovo predict --data-path /path/to/your/experiment/*.mgf\n</code></pre>"},{"location":"how-to/using_custom_datasets/#creating-a-custom-dataset-from-a-dataframe","title":"Creating a custom dataset from a DataFrame","text":"<p>If your data is not in a standard file format, you can create a <code>SpectrumDataFrame</code> from a Pandas or Polars DataFrame.</p> <p>Your DataFrame must have the following columns:</p> <ul> <li><code>sequence</code> (string): The target peptide sequence (required for training).</li> <li><code>precursor_mz</code> (float): The precursor m/z.</li> <li><code>precursor_charge</code> (integer): The precursor charge.</li> <li><code>mz_array</code> (list of floats): The m/z values of the MS2 peaks.</li> <li><code>intensity_array</code> (list of floats): The intensity values of the MS2 peaks.</li> </ul> <p>Here is an example of how to create a <code>SpectrumDataFrame</code> from a Pandas DataFrame:</p> <pre><code>import pandas as pd\nfrom instanovo.utils.data_handler import SpectrumDataFrame\n\n# Create a sample DataFrame\ndata = {\n    'sequence': ['PEPTIDE'],\n    'precursor_mz': [600.0],\n    'precursor_charge': [2],\n    'mz_array': [[100.1, 200.2, 300.3]],\n    'intensity_array': [[1000.0, 2000.0, 1500.0]]\n}\ndf = pd.DataFrame(data)\n\n# Create a SpectrumDataFrame\nsdf = SpectrumDataFrame(df)\n\n# You can now use this sdf for training or prediction\n</code></pre>"},{"location":"how-to/using_custom_datasets/#converting-to-native-format","title":"Converting to native format","text":"<p>For very large datasets, it can be more efficient to convert your data to InstaNovo's native format, which is based on Apache Parquet. This allows for faster loading and shuffling during training.</p> <p>You can convert your data using the <code>SpectrumDataFrame.save</code> method:</p> <pre><code>from instanovo.utils import SpectrumDataFrame\n\n# Load your data from MGF files\nsdf = SpectrumDataFrame.load(\"/path/to/data.mgf\", lazy=False, is_annotated=True)\n\n# Save it in the native Parquet format\nsdf.save(\"path/to/parquet/folder\", partition=\"train\", chunk_size=1e6)\n</code></pre> <p>You can then load this native dataset for training:</p> <pre><code># Load the native Parquet dataset\nsdf = SpectrumDataFrame.load(\"path/to/parquet/folder\", partition=\"train\", shuffle=True, lazy=True, is_annotated=True)\n</code></pre> <p>InstaNovo also provides a command-line script for converting data:</p> <pre><code>instanovo convert --help\n</code></pre> <p></p>"},{"location":"notebooks/getting_started_with_instanovo/","title":"Getting started with InstaNovo","text":"<p>Links:</p> <ul> <li>Nature Machine Intelligence Paper: InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale proteomics experiments  Kevin Eloff, Konstantinos Kalogeropoulos, Amandla Mabona, Oliver Morell, Rachel Catzel, Esperanza Rivera-de-Torre, Jakob Berg Jespersen, Wesley Williams, Sam P. B. van Beljouw, Marcin J. Skwark, Andreas Hougaard Laustsen, Stan J. J. Brouns, Anne Ljungars, Erwin M. Schoof, Jeroen Van Goey, Ulrich auf dem Keller, Karim Beguir, Nicolas Lopez Carranza, Timothy P. Jenkins</li> <li>Code: GitHub</li> </ul> <p>Important:</p> <p>It is highly recommended to run this notebook in an environment with access to a GPU. If you are running this notebook in Google Colab:</p> <ul> <li>In the menu, go to <code>Runtime &gt; Change Runtime Type &gt; T4 GPU</code></li> </ul> In\u00a0[\u00a0]: Copied! <pre>import os\nimport sys\n\nif \"google.colab\" in sys.modules or \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n    # Suppress TensorFlow warnings\n    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n    # Install torchvision when running on Google Colab to prevent errors\n    !uv pip install --system \"instanovo[cu126]&gt;=1.2.0\" pyopenms-viz torchvision tf-nightly\nelse:\n    !uv pip install \"instanovo[cu126]&gt;=1.2.0\" pyopenms-viz\n</pre> import os import sys  if \"google.colab\" in sys.modules or \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:     # Suppress TensorFlow warnings     os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"     # Install torchvision when running on Google Colab to prevent errors     !uv pip install --system \"instanovo[cu126]&gt;=1.2.0\" pyopenms-viz torchvision tf-nightly else:     !uv pip install \"instanovo[cu126]&gt;=1.2.0\" pyopenms-viz In\u00a0[\u00a0]: Copied! <pre># Filter warnings and set logging level\nimport warnings\nimport logging\n\nwarnings.filterwarnings(\"ignore\", module=\"matplotlib\")\nwarnings.filterwarnings(\"ignore\", module=\"torch\")\nlogging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\nlogging.getLogger(\"rdkit\").setLevel(logging.WARNING)\n</pre> # Filter warnings and set logging level import warnings import logging  warnings.filterwarnings(\"ignore\", module=\"matplotlib\") warnings.filterwarnings(\"ignore\", module=\"torch\") logging.getLogger(\"matplotlib\").setLevel(logging.WARNING) logging.getLogger(\"rdkit\").setLevel(logging.WARNING) <p>We can use <code>instanovo version</code> to check the version of InstaNovo (the transformer-based model), InstaNovo+ (the diffusion-based model) and some of their dependencies.</p> In\u00a0[\u00a0]: Copied! <pre>!instanovo version\n</pre> !instanovo version <p>Import the transformer-based InstaNovo model.</p> In\u00a0[\u00a0]: Copied! <pre>from instanovo.transformer.model import InstaNovo\n</pre> from instanovo.transformer.model import InstaNovo <p>Set the device to GPU if available (recommended), otherwise use CPU.</p> In\u00a0[\u00a0]: Copied! <pre>import torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n</pre> import torch  device = \"cuda\" if torch.cuda.is_available() else \"cpu\" device <p>InstaNovo supports automatic model downloads. You can see the IDs of the pretrained models that are available.</p> In\u00a0[\u00a0]: Copied! <pre>InstaNovo.get_pretrained()\n</pre> InstaNovo.get_pretrained() <p>And download the model checkpoint given the ID.</p> In\u00a0[\u00a0]: Copied! <pre>model, config = InstaNovo.from_pretrained(\"instanovo-v1.1.0\")\nmodel = model.to(device).eval()\n</pre> model, config = InstaNovo.from_pretrained(\"instanovo-v1.1.0\") model = model.to(device).eval() <p>Alternatively, you can also download the model checkpoint directly from the InstaNovo releases page.</p> In\u00a0[\u00a0]: Copied! <pre>from instanovo.utils.data_handler import SpectrumDataFrame\n\nsdf = SpectrumDataFrame.from_huggingface(\n    \"InstaDeepAI/ms_ninespecies_benchmark\",\n    is_annotated=True,\n    shuffle=False,\n    split=\"test[:10%]\",  # Let's only use a subset of the test data for faster inference in this notebook\n)\n</pre> from instanovo.utils.data_handler import SpectrumDataFrame  sdf = SpectrumDataFrame.from_huggingface(     \"InstaDeepAI/ms_ninespecies_benchmark\",     is_annotated=True,     shuffle=False,     split=\"test[:10%]\",  # Let's only use a subset of the test data for faster inference in this notebook ) In\u00a0[\u00a0]: Copied! <pre>sdf.to_pandas().head(5)\n</pre> sdf.to_pandas().head(5) <p>Let's quickly plot the spectrum in the first row</p> In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\n\npd.options.plotting.backend = \"ms_matplotlib\"\nrow = sdf[0]\nrow_df = pd.DataFrame({\"mz\": row[\"mz_array\"], \"intensity\": row[\"intensity_array\"]})\nrow_df.plot(\n    kind=\"spectrum\",\n    x=\"mz\",\n    y=\"intensity\",\n    annotate_mz=True,\n    bin_method=\"none\",\n    annotate_top_n_peaks=5,\n    aggregate_duplicates=True,\n    title=f\"Mass spectrum of {row['sequence']}\",\n);\n</pre> import pandas as pd  pd.options.plotting.backend = \"ms_matplotlib\" row = sdf[0] row_df = pd.DataFrame({\"mz\": row[\"mz_array\"], \"intensity\": row[\"intensity_array\"]}) row_df.plot(     kind=\"spectrum\",     x=\"mz\",     y=\"intensity\",     annotate_mz=True,     bin_method=\"none\",     annotate_top_n_peaks=5,     aggregate_duplicates=True,     title=f\"Mass spectrum of {row['sequence']}\", ); <p>We include a residue remapping to ensure our input dataset can be mapped to the format the model vocabulary expects.</p> In\u00a0[\u00a0]: Copied! <pre>model.residue_set.update_remapping(\n    {\n        \"M(ox)\": \"M[UNIMOD:35]\",\n        \"M(+15.99)\": \"M[UNIMOD:35]\",\n        \"S(p)\": \"S[UNIMOD:21]\",  # Phosphorylation\n        \"T(p)\": \"T[UNIMOD:21]\",\n        \"Y(p)\": \"Y[UNIMOD:21]\",\n        \"S(+79.97)\": \"S[UNIMOD:21]\",\n        \"T(+79.97)\": \"T[UNIMOD:21]\",\n        \"Y(+79.97)\": \"Y[UNIMOD:21]\",\n        \"Q(+0.98)\": \"Q[UNIMOD:7]\",  # Deamidation\n        \"N(+0.98)\": \"N[UNIMOD:7]\",\n        \"Q(+.98)\": \"Q[UNIMOD:7]\",\n        \"N(+.98)\": \"N[UNIMOD:7]\",\n        \"C(+57.02)\": \"C[UNIMOD:4]\",  # Carboxyamidomethylation\n        \"(+42.01)\": \"[UNIMOD:1]\",  # Acetylation\n        \"(+43.01)\": \"[UNIMOD:5]\",  # Carbamylation\n        \"(-17.03)\": \"[UNIMOD:385]\",\n    }\n)\n</pre> model.residue_set.update_remapping(     {         \"M(ox)\": \"M[UNIMOD:35]\",         \"M(+15.99)\": \"M[UNIMOD:35]\",         \"S(p)\": \"S[UNIMOD:21]\",  # Phosphorylation         \"T(p)\": \"T[UNIMOD:21]\",         \"Y(p)\": \"Y[UNIMOD:21]\",         \"S(+79.97)\": \"S[UNIMOD:21]\",         \"T(+79.97)\": \"T[UNIMOD:21]\",         \"Y(+79.97)\": \"Y[UNIMOD:21]\",         \"Q(+0.98)\": \"Q[UNIMOD:7]\",  # Deamidation         \"N(+0.98)\": \"N[UNIMOD:7]\",         \"Q(+.98)\": \"Q[UNIMOD:7]\",         \"N(+.98)\": \"N[UNIMOD:7]\",         \"C(+57.02)\": \"C[UNIMOD:4]\",  # Carboxyamidomethylation         \"(+42.01)\": \"[UNIMOD:1]\",  # Acetylation         \"(+43.01)\": \"[UNIMOD:5]\",  # Carbamylation         \"(-17.03)\": \"[UNIMOD:385]\",     } ) In\u00a0[\u00a0]: Copied! <pre>from instanovo.transformer.data import TransformerDataProcessor\n\n# HuggingFace dataset\nds = sdf.to_dataset(in_memory=True)\n\nprocessor = TransformerDataProcessor(\n    model.residue_set,\n    reverse_peptide=False,\n    return_str=True,\n)\n\nds = processor.process_dataset(ds)\n</pre> from instanovo.transformer.data import TransformerDataProcessor  # HuggingFace dataset ds = sdf.to_dataset(in_memory=True)  processor = TransformerDataProcessor(     model.residue_set,     reverse_peptide=False,     return_str=True, )  ds = processor.process_dataset(ds) In\u00a0[\u00a0]: Copied! <pre>from torch.utils.data import DataLoader\n\n# When using SpectrumDataFrame, workers and shuffle is handled internally.\ndl = DataLoader(ds, batch_size=64, shuffle=False, collate_fn=processor.collate_fn)\n</pre> from torch.utils.data import DataLoader  # When using SpectrumDataFrame, workers and shuffle is handled internally. dl = DataLoader(ds, batch_size=64, shuffle=False, collate_fn=processor.collate_fn) In\u00a0[\u00a0]: Copied! <pre>batch = next(iter(dl))\n\nbatch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n\npeptides = batch[\"peptides\"]\nbatch.keys()\n</pre> batch = next(iter(dl))  batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}  peptides = batch[\"peptides\"] batch.keys() In\u00a0[\u00a0]: Copied! <pre>from instanovo.inference import BeamSearchDecoder, GreedyDecoder\n\nnum_beams = 1  # Change this, defaults are 1 or 5\n\nif num_beams &gt; 1:\n    decoder = BeamSearchDecoder(model=model)\nelse:\n    decoder = GreedyDecoder(model=model)\n</pre> from instanovo.inference import BeamSearchDecoder, GreedyDecoder  num_beams = 1  # Change this, defaults are 1 or 5  if num_beams &gt; 1:     decoder = BeamSearchDecoder(model=model) else:     decoder = GreedyDecoder(model=model) In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\nfrom instanovo.constants import MASS_SCALE\nfrom instanovo.inference.knapsack import Knapsack\nfrom instanovo.inference.knapsack_beam_search import KnapsackBeamSearchDecoder\n\nnum_beams = 5\n\n\ndef _setup_knapsack(model: InstaNovo) -&gt; Knapsack:\n    # Cannot allow negative masses in knapsack graph\n    if \"(-17.03)\" in model.residue_set.residue_masses:\n        model.residue_set.residue_masses[\"(-17.03)\"] = 1e3\n    if \"[UNIMOD:385]\" in model.residue_set.residue_masses:\n        model.residue_set.residue_masses[\"[UNIMOD:385]\"] = 1e3\n\n    residue_masses = dict(model.residue_set.residue_masses.copy())\n    if any(x &lt; 0 for x in residue_masses.values()):\n        raise NotImplementedError(\n            \"Negative mass found in residues, this will break the knapsack graph. \"\n            \"Either disable knapsack or use strictly positive masses\"\n        )\n    for special_residue in list(model.residue_set.residue_to_index.keys())[:3]:\n        residue_masses[special_residue] = 0\n    residue_indices = model.residue_set.residue_to_index\n    return Knapsack.construct_knapsack(\n        residue_masses=residue_masses,\n        residue_indices=residue_indices,\n        max_mass=4000.00,\n        mass_scale=MASS_SCALE,\n    )\n\n\nknapsack_path = Path(\"./checkpoints/knapsack/\")\n\nif not knapsack_path.exists():\n    print(\"Knapsack path missing or not specified, generating...\")\n    knapsack = _setup_knapsack(model)\n    decoder = KnapsackBeamSearchDecoder(model, knapsack)\n    print(f\"Saving knapsack to {knapsack_path}\")\n    knapsack_path.parent.mkdir(parents=True, exist_ok=True)\n    knapsack.save(knapsack_path)\nelse:\n    print(\"Knapsack path found. Loading...\")\n    decoder = KnapsackBeamSearchDecoder.from_file(model=model, path=knapsack_path)\n</pre> from pathlib import Path from instanovo.constants import MASS_SCALE from instanovo.inference.knapsack import Knapsack from instanovo.inference.knapsack_beam_search import KnapsackBeamSearchDecoder  num_beams = 5   def _setup_knapsack(model: InstaNovo) -&gt; Knapsack:     # Cannot allow negative masses in knapsack graph     if \"(-17.03)\" in model.residue_set.residue_masses:         model.residue_set.residue_masses[\"(-17.03)\"] = 1e3     if \"[UNIMOD:385]\" in model.residue_set.residue_masses:         model.residue_set.residue_masses[\"[UNIMOD:385]\"] = 1e3      residue_masses = dict(model.residue_set.residue_masses.copy())     if any(x &lt; 0 for x in residue_masses.values()):         raise NotImplementedError(             \"Negative mass found in residues, this will break the knapsack graph. \"             \"Either disable knapsack or use strictly positive masses\"         )     for special_residue in list(model.residue_set.residue_to_index.keys())[:3]:         residue_masses[special_residue] = 0     residue_indices = model.residue_set.residue_to_index     return Knapsack.construct_knapsack(         residue_masses=residue_masses,         residue_indices=residue_indices,         max_mass=4000.00,         mass_scale=MASS_SCALE,     )   knapsack_path = Path(\"./checkpoints/knapsack/\")  if not knapsack_path.exists():     print(\"Knapsack path missing or not specified, generating...\")     knapsack = _setup_knapsack(model)     decoder = KnapsackBeamSearchDecoder(model, knapsack)     print(f\"Saving knapsack to {knapsack_path}\")     knapsack_path.parent.mkdir(parents=True, exist_ok=True)     knapsack.save(knapsack_path) else:     print(\"Knapsack path found. Loading...\")     decoder = KnapsackBeamSearchDecoder.from_file(model=model, path=knapsack_path) <p>Evaluating a single batch...</p> In\u00a0[\u00a0]: Copied! <pre>from instanovo.inference import ScoredSequence\n\nwith torch.no_grad():\n    p = decoder.decode(\n        spectra=batch[\"spectra\"],\n        precursors=batch[\"precursors\"],\n        beam_size=num_beams,\n        max_length=config[\"max_length\"],\n    )\n\npreds = [x.sequence if isinstance(x, ScoredSequence) else [] for x in p]\nprobs = [x.sequence_log_probability if isinstance(x, ScoredSequence) else -float(\"inf\") for x in p]\n</pre> from instanovo.inference import ScoredSequence  with torch.no_grad():     p = decoder.decode(         spectra=batch[\"spectra\"],         precursors=batch[\"precursors\"],         beam_size=num_beams,         max_length=config[\"max_length\"],     )  preds = [x.sequence if isinstance(x, ScoredSequence) else [] for x in p] probs = [x.sequence_log_probability if isinstance(x, ScoredSequence) else -float(\"inf\") for x in p] In\u00a0[\u00a0]: Copied! <pre>from typing import Optional\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\nfrom instanovo.inference.beam_search import ScoredSequence\n\n\ndef plot_residue_confidence(prediction: ScoredSequence, peptide: Optional[str] = None) -&gt; None:\n    if not prediction:\n        return\n    ticks = list(range(len(prediction.sequence)))\n    token_probabilities = np.exp(prediction.token_log_probabilities[: len(ticks)])\n    sequence_confidence = np.exp(prediction.sequence_log_probability)\n\n    _, ax = plt.subplots()\n    bars = sns.barplot(x=ticks, y=token_probabilities, errorbar=None, ax=ax)\n\n    # Increase Y-axis limit to create space for text labels\n    ax.set_ylim(0, max(token_probabilities) * 1.2)\n\n    # Add numbers above bars with a slanted angle\n    for bar, prob in zip(bars.patches, token_probabilities):\n        height = bar.get_height()\n        ax.text(\n            bar.get_x() + bar.get_width() / 2,\n            float(height) + 0.02,\n            f\"{float(prob):.4f}\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n            color=\"black\",\n            rotation=45,\n        )\n\n    # Check if any residue contains a PTM (e.g., \"S(+79.97)\")\n    has_ptm = any(\"(\" in res and \")\" in res for res in prediction.sequence)\n\n    # Set labels\n    x_label = f\"    Prediction: {''.join(prediction.sequence)}\"\n    if peptide is not None:\n        x_label += f\"\\nGround truth: {peptide}\"\n    ax.set_xlabel(x_label)\n    ax.set_ylabel(\"Confidence Probability\")\n\n    # Set title with sequence confidence\n    ax.set_title(\n        f\"Residue Confidence per Position\\nSequence Probability: {sequence_confidence:.4f}\"\n    )\n\n    # Set X-ticks\n    ax.set_xticks(ticks)\n    ax.set_xticklabels(\n        prediction.sequence,\n        rotation=45 if has_ptm else 0,\n        ha=\"right\" if has_ptm else \"center\",\n    )\n\n    plt.show()\n</pre> from typing import Optional  import matplotlib.pyplot as plt import seaborn as sns import numpy as np  from instanovo.inference.beam_search import ScoredSequence   def plot_residue_confidence(prediction: ScoredSequence, peptide: Optional[str] = None) -&gt; None:     if not prediction:         return     ticks = list(range(len(prediction.sequence)))     token_probabilities = np.exp(prediction.token_log_probabilities[: len(ticks)])     sequence_confidence = np.exp(prediction.sequence_log_probability)      _, ax = plt.subplots()     bars = sns.barplot(x=ticks, y=token_probabilities, errorbar=None, ax=ax)      # Increase Y-axis limit to create space for text labels     ax.set_ylim(0, max(token_probabilities) * 1.2)      # Add numbers above bars with a slanted angle     for bar, prob in zip(bars.patches, token_probabilities):         height = bar.get_height()         ax.text(             bar.get_x() + bar.get_width() / 2,             float(height) + 0.02,             f\"{float(prob):.4f}\",             ha=\"center\",             va=\"bottom\",             fontsize=9,             color=\"black\",             rotation=45,         )      # Check if any residue contains a PTM (e.g., \"S(+79.97)\")     has_ptm = any(\"(\" in res and \")\" in res for res in prediction.sequence)      # Set labels     x_label = f\"    Prediction: {''.join(prediction.sequence)}\"     if peptide is not None:         x_label += f\"\\nGround truth: {peptide}\"     ax.set_xlabel(x_label)     ax.set_ylabel(\"Confidence Probability\")      # Set title with sequence confidence     ax.set_title(         f\"Residue Confidence per Position\\nSequence Probability: {sequence_confidence:.4f}\"     )      # Set X-ticks     ax.set_xticks(ticks)     ax.set_xticklabels(         prediction.sequence,         rotation=45 if has_ptm else 0,         ha=\"right\" if has_ptm else \"center\",     )      plt.show() <p>For a spectrum that is sequenced correctly, the sequence probability and per-residue probabilities are uniformly high:</p> In\u00a0[\u00a0]: Copied! <pre>plot_residue_confidence(p[-1], peptides[-1])\n</pre> plot_residue_confidence(p[-1], peptides[-1]) <p>For another spectrum which is sequenced incorrectly, the sequence probability is low and the per-residue probabilities of the incorrectly sequenced residues (up to isomerism) are lower than of those correctly sequenced:</p> In\u00a0[\u00a0]: Copied! <pre>plot_residue_confidence(p[0], peptides[0])\n</pre> plot_residue_confidence(p[0], peptides[0]) <p>These examples suggest the model is fairly well calibrated.</p> In\u00a0[\u00a0]: Copied! <pre>from instanovo.utils.metrics import Metrics\n\nmetrics = Metrics(model.residue_set, config[\"isotope_error_range\"])\n</pre> from instanovo.utils.metrics import Metrics  metrics = Metrics(model.residue_set, config[\"isotope_error_range\"]) In\u00a0[\u00a0]: Copied! <pre>aa_precision, aa_recall, peptide_recall, peptide_precision = metrics.compute_precision_recall(\n    peptides, preds\n)\npeptide_recall\n</pre> aa_precision, aa_recall, peptide_recall, peptide_precision = metrics.compute_precision_recall(     peptides, preds ) peptide_recall <p>Evaluating on the yeast test fold of the nine-species dataset:</p> In\u00a0[\u00a0]: Copied! <pre>from tqdm.notebook import tqdm\n\npreds = []\ntargs = []\nprobs = []\n\nfor _, batch in tqdm(enumerate(dl), total=len(dl)):\n    batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n\n    with torch.no_grad():\n        p = decoder.decode(\n            spectra=batch[\"spectra\"],\n            precursors=batch[\"precursors\"],\n            beam_size=config[\"n_beams\"],\n            max_length=config[\"max_length\"],\n        )\n\n    preds += [x.sequence if isinstance(x, ScoredSequence) else [] for x in p]\n    probs += [\n        x.sequence_log_probability if isinstance(x, ScoredSequence) else -float(\"inf\") for x in p\n    ]\n    targs += list(batch[\"peptides\"])\n</pre> from tqdm.notebook import tqdm  preds = [] targs = [] probs = []  for _, batch in tqdm(enumerate(dl), total=len(dl)):     batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}      with torch.no_grad():         p = decoder.decode(             spectra=batch[\"spectra\"],             precursors=batch[\"precursors\"],             beam_size=config[\"n_beams\"],             max_length=config[\"max_length\"],         )      preds += [x.sequence if isinstance(x, ScoredSequence) else [] for x in p]     probs += [         x.sequence_log_probability if isinstance(x, ScoredSequence) else -float(\"inf\") for x in p     ]     targs += list(batch[\"peptides\"]) In\u00a0[\u00a0]: Copied! <pre>aa_precision, aa_recall, peptide_recall, peptide_precision = metrics.compute_precision_recall(\n    targs, preds\n)\naa_error_rate = metrics.compute_aa_er(targs, preds)\nauc = metrics.calc_auc(targs, preds, np.exp(pd.Series(probs)))\n\nprint(f\"amino acid error rate:    {aa_error_rate:.5f}\")\nprint(f\"amino acid precision:     {aa_precision:.5f}\")\nprint(f\"amino acid recall:        {aa_recall:.5f}\")\nprint(f\"peptide precision:        {peptide_precision:.5f}\")\nprint(f\"peptide recall:           {peptide_recall:.5f}\")\nprint(f\"area under the PR curve:  {auc:.5f}\")\n</pre> aa_precision, aa_recall, peptide_recall, peptide_precision = metrics.compute_precision_recall(     targs, preds ) aa_error_rate = metrics.compute_aa_er(targs, preds) auc = metrics.calc_auc(targs, preds, np.exp(pd.Series(probs)))  print(f\"amino acid error rate:    {aa_error_rate:.5f}\") print(f\"amino acid precision:     {aa_precision:.5f}\") print(f\"amino acid recall:        {aa_recall:.5f}\") print(f\"peptide precision:        {peptide_precision:.5f}\") print(f\"peptide recall:           {peptide_recall:.5f}\") print(f\"area under the PR curve:  {auc:.5f}\") In\u00a0[\u00a0]: Copied! <pre>fdr = 5 / 100  # Desired FDR\n\n_, threshold = metrics.find_recall_at_fdr(targs, preds, np.exp(probs), fdr=fdr)\naa_precision_fdr, aa_recall_fdr, peptide_recall_fdr, peptide_precision_fdr = (\n    metrics.compute_precision_recall(targs, preds, np.exp(probs), threshold=threshold)\n)\nprint(f\"Performance at {fdr * 100:.1f}% FDR:\\n\")\nprint(f\"amino acid precision:     {aa_precision_fdr:.5f}\")\nprint(f\"amino acid recall:        {aa_recall_fdr:.5f}\")\nprint(f\"peptide precision:        {peptide_precision_fdr:.5f}\")\nprint(f\"peptide recall:           {peptide_recall_fdr:.5f}\")\nprint(f\"area under the PR curve:  {auc:.5f}\")\nprint(f\"confidence threshold:     {threshold:.5f}  &lt;-- Use this as a confidence cutoff\")\n</pre> fdr = 5 / 100  # Desired FDR  _, threshold = metrics.find_recall_at_fdr(targs, preds, np.exp(probs), fdr=fdr) aa_precision_fdr, aa_recall_fdr, peptide_recall_fdr, peptide_precision_fdr = (     metrics.compute_precision_recall(targs, preds, np.exp(probs), threshold=threshold) ) print(f\"Performance at {fdr * 100:.1f}% FDR:\\n\") print(f\"amino acid precision:     {aa_precision_fdr:.5f}\") print(f\"amino acid recall:        {aa_recall_fdr:.5f}\") print(f\"peptide precision:        {peptide_precision_fdr:.5f}\") print(f\"peptide recall:           {peptide_recall_fdr:.5f}\") print(f\"area under the PR curve:  {auc:.5f}\") print(f\"confidence threshold:     {threshold:.5f}  &lt;-- Use this as a confidence cutoff\") <p>Note: to reproduce the results of the paper, the entire Yeast test set should be evaluated with the 0.1.7 release of InstaNovo.</p> In\u00a0[\u00a0]: Copied! <pre>pred_df = pd.DataFrame(\n    {\n        \"targets\": targs,\n        \"tokenized_predictions\": preds,\n        \"predictions\": [\"\".join(x) for x in preds],\n        \"log_probabilities\": probs,\n    }\n)\npred_df.head()\n</pre> pred_df = pd.DataFrame(     {         \"targets\": targs,         \"tokenized_predictions\": preds,         \"predictions\": [\"\".join(x) for x in preds],         \"log_probabilities\": probs,     } ) pred_df.head() In\u00a0[\u00a0]: Copied! <pre>pred_df.to_csv(\"predictions_knapsack_beam_search.csv\", index=False)\n</pre> pred_df.to_csv(\"predictions_knapsack_beam_search.csv\", index=False) In\u00a0[\u00a0]: Copied! <pre>from instanovo.diffusion.multinomial_diffusion import InstaNovoPlus\n\nInstaNovoPlus.get_pretrained()\n</pre> from instanovo.diffusion.multinomial_diffusion import InstaNovoPlus  InstaNovoPlus.get_pretrained() In\u00a0[\u00a0]: Copied! <pre>diffusion_model, diffusion_config = InstaNovoPlus.from_pretrained(\"instanovoplus-v1.1.0\")\ndiffusion_model = diffusion_model.to(device).eval()\n</pre> diffusion_model, diffusion_config = InstaNovoPlus.from_pretrained(\"instanovoplus-v1.1.0\") diffusion_model = diffusion_model.to(device).eval() <p>Next we create a decoder object.</p> In\u00a0[\u00a0]: Copied! <pre>from instanovo.inference.diffusion import DiffusionDecoder\n\ndiffusion_decoder = DiffusionDecoder(model=diffusion_model)\n</pre> from instanovo.inference.diffusion import DiffusionDecoder  diffusion_decoder = DiffusionDecoder(model=diffusion_model) <p>Then we prepare the inference data loader using predictions from the InstaNovo transformer model.</p> In\u00a0[\u00a0]: Copied! <pre>from instanovo.constants import REFINEMENT_COLUMN\nfrom instanovo.diffusion.data import DiffusionDataProcessor\n\ndiffusion_ds = sdf.to_dataset(in_memory=True)\n\n# Add the \"tokenized_predictions\" column from pred_df to the diffusion_ds HuggingFace dataset\ndiffusion_ds = diffusion_ds.add_column(REFINEMENT_COLUMN, pred_df[\"tokenized_predictions\"])\n\ndiffusion_processor = DiffusionDataProcessor(\n    diffusion_model.residue_set,\n    reverse_peptide=False,\n    return_str=True,\n    metadata_columns=[REFINEMENT_COLUMN],\n)\n\ndiffusion_ds = diffusion_processor.process_dataset(diffusion_ds)\n\ndiffusion_dl = DataLoader(\n    diffusion_ds,\n    batch_size=64,\n    shuffle=False,\n    collate_fn=diffusion_processor.collate_fn,\n)\n</pre> from instanovo.constants import REFINEMENT_COLUMN from instanovo.diffusion.data import DiffusionDataProcessor  diffusion_ds = sdf.to_dataset(in_memory=True)  # Add the \"tokenized_predictions\" column from pred_df to the diffusion_ds HuggingFace dataset diffusion_ds = diffusion_ds.add_column(REFINEMENT_COLUMN, pred_df[\"tokenized_predictions\"])  diffusion_processor = DiffusionDataProcessor(     diffusion_model.residue_set,     reverse_peptide=False,     return_str=True,     metadata_columns=[REFINEMENT_COLUMN], )  diffusion_ds = diffusion_processor.process_dataset(diffusion_ds)  diffusion_dl = DataLoader(     diffusion_ds,     batch_size=64,     shuffle=False,     collate_fn=diffusion_processor.collate_fn, ) <p>Finally, we predict sequences by iterating over the spectra and refining the InstaNovo predictions.</p> In\u00a0[\u00a0]: Copied! <pre>predictions = []\nlog_probs = []\n\nfor batch in tqdm(diffusion_dl, total=len(diffusion_dl)):\n    batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n\n    with torch.no_grad():\n        batch_predictions, batch_log_probs = diffusion_decoder.decode(\n            spectra=batch[\"spectra\"],\n            spectra_padding_mask=batch[\"spectra_mask\"],\n            precursors=batch[\"precursors\"],\n            initial_sequence=batch[REFINEMENT_COLUMN],\n        )\n    predictions.extend(batch_predictions)\n    log_probs.extend(batch_log_probs)\n</pre> predictions = [] log_probs = []  for batch in tqdm(diffusion_dl, total=len(diffusion_dl)):     batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}      with torch.no_grad():         batch_predictions, batch_log_probs = diffusion_decoder.decode(             spectra=batch[\"spectra\"],             spectra_padding_mask=batch[\"spectra_mask\"],             precursors=batch[\"precursors\"],             initial_sequence=batch[REFINEMENT_COLUMN],         )     predictions.extend(batch_predictions)     log_probs.extend(batch_log_probs) <p>Iterative refinement improves performance on this sample of the Nine Species dataset. (To replicate the performance reported in the paper, you would need to evaluate on the entire dataset.)</p> In\u00a0[\u00a0]: Copied! <pre>(\n    aa_precision_refined,\n    aa_recall_refined,\n    peptide_recall_refined,\n    peptide_precision_refined,\n) = metrics.compute_precision_recall(targs, predictions=predictions)\naa_error_rate_refined = metrics.compute_aa_er(targs, predictions)\nauc_refined = metrics.calc_auc(targs, predictions, np.exp(pd.Series(log_probs)))\n\nprint(f\"amino acid error rate:     {aa_error_rate_refined:.5f}\")\nprint(f\"amino acid precision:      {aa_precision_refined:.5f}\")\nprint(f\"amino acid recall:         {aa_recall_refined:.5f}\")\nprint(f\"peptide precision:         {peptide_precision_refined:.5f}\")\nprint(f\"peptide recall:            {peptide_recall_refined:.5f}\")\nprint(f\"area under the ROC curve:  {auc_refined:.5f}\")\n</pre> (     aa_precision_refined,     aa_recall_refined,     peptide_recall_refined,     peptide_precision_refined, ) = metrics.compute_precision_recall(targs, predictions=predictions) aa_error_rate_refined = metrics.compute_aa_er(targs, predictions) auc_refined = metrics.calc_auc(targs, predictions, np.exp(pd.Series(log_probs)))  print(f\"amino acid error rate:     {aa_error_rate_refined:.5f}\") print(f\"amino acid precision:      {aa_precision_refined:.5f}\") print(f\"amino acid recall:         {aa_recall_refined:.5f}\") print(f\"peptide precision:         {peptide_precision_refined:.5f}\") print(f\"peptide recall:            {peptide_recall_refined:.5f}\") print(f\"area under the ROC curve:  {auc_refined:.5f}\") In\u00a0[\u00a0]: Copied! <pre>print(f\"Decrease in AA error rate:    {100 * (aa_error_rate - aa_error_rate_refined):.2f}%\")\nprint(f\"Increase in AA precision:     {100 * (aa_precision_refined - aa_precision):.2f}%\")\nprint(f\"Increase in AA recall:        {100 * (aa_recall_refined - aa_recall):.2f}%\")\nprint(f\"Increase in peptide precision:{100 * (peptide_precision_refined - peptide_precision):.2f}%\")\nprint(f\"Increase in peptide recall:   {100 * (peptide_recall_refined - peptide_recall):.2f}%\")\nprint(f\"Increase in AUC:              {100 * (auc_refined - auc):.2f}%\")\n</pre> print(f\"Decrease in AA error rate:    {100 * (aa_error_rate - aa_error_rate_refined):.2f}%\") print(f\"Increase in AA precision:     {100 * (aa_precision_refined - aa_precision):.2f}%\") print(f\"Increase in AA recall:        {100 * (aa_recall_refined - aa_recall):.2f}%\") print(f\"Increase in peptide precision:{100 * (peptide_precision_refined - peptide_precision):.2f}%\") print(f\"Increase in peptide recall:   {100 * (peptide_recall_refined - peptide_recall):.2f}%\") print(f\"Increase in AUC:              {100 * (auc_refined - auc):.2f}%\") In\u00a0[\u00a0]: Copied! <pre>diffusion_predictions = pd.DataFrame(\n    {\n        \"targets\": targs,\n        \"tokenized_predictions\": predictions,\n        \"predictions\": [\"\".join(x) for x in predictions],\n        \"log_probabilities\": log_probs,\n    }\n)\ndiffusion_predictions.head()\n</pre> diffusion_predictions = pd.DataFrame(     {         \"targets\": targs,         \"tokenized_predictions\": predictions,         \"predictions\": [\"\".join(x) for x in predictions],         \"log_probabilities\": log_probs,     } ) diffusion_predictions.head() In\u00a0[\u00a0]: Copied! <pre>diffusion_predictions.to_csv(\"diffusion_predictions.csv\", index=False)\n</pre> diffusion_predictions.to_csv(\"diffusion_predictions.csv\", index=False)"},{"location":"notebooks/getting_started_with_instanovo/#getting-started-with-instanovo","title":"Getting started with InstaNovo\u00b6","text":"<p>In this notebook, we demo InstaNovo, a transformer neural network with the ability to translate fragment ion peaks into the sequence of amino acids that make up the studied peptide(s). We evaluate the model on the yeast test fold of nine-species dataset.</p>"},{"location":"notebooks/getting_started_with_instanovo/#loading-the-instanovo-model","title":"Loading the InstaNovo model\u00b6","text":"<p>We first install the latest instanovo from PyPi</p>"},{"location":"notebooks/getting_started_with_instanovo/#loading-the-nine-species-dataset","title":"Loading the nine-species dataset\u00b6","text":"<p>Download the yeast test fold of the nine-species dataset dataset from HuggingFace.</p> <p>We can use our SpectrumDataFrame to download this directly. SpectrumDataFrame is a special data class used by InstaNovo to read and write from multiple formats, including mgf, mzml, mzxml, pandas, polars, HuggingFace, etc.</p>"},{"location":"notebooks/getting_started_with_instanovo/#decoding","title":"Decoding\u00b6","text":"<p>We have three options for decoding:</p> <ul> <li>Greedy Search</li> <li>Beam Search</li> <li>Knapsack Beam Search</li> </ul> <p>For the best results and highest peptide recall, use Knapsack Beam Search. For fastest results (over 10x speedup), use Greedy Search.</p> <p>We generally use a beam size of 5 for Beam Search and Knapsack Beam Search, a higher beam size should increase recall at the cost of performance and vice versa.</p> <p>Note: in our findings, greedy search has similar performance as knapsack beam search at 5% FDR. I.e. if you plan to filter at 5% FDR anyway, use greedy search for optimal performance.</p>"},{"location":"notebooks/getting_started_with_instanovo/#greedy-search-and-beam-search","title":"Greedy Search and Beam Search\u00b6","text":"<p>Greedy search is used when <code>num_beams=1</code>, and beam search is used when <code>num_beams&gt;1</code></p>"},{"location":"notebooks/getting_started_with_instanovo/#knapsack-beam-search","title":"Knapsack Beam Search\u00b6","text":"<p>Setup knapsack beam search decoder. This may take a few minutes.</p>"},{"location":"notebooks/getting_started_with_instanovo/#inference-time","title":"Inference time \ud83d\ude80\u00b6","text":""},{"location":"notebooks/getting_started_with_instanovo/#confidence-probabilities","title":"Confidence probabilities\u00b6","text":"<p>The model returns per-residue confidences in the form of token log-probabilities. We can visualize these or use them as part of a workflow.</p>"},{"location":"notebooks/getting_started_with_instanovo/#evaluation","title":"Evaluation\u00b6","text":""},{"location":"notebooks/getting_started_with_instanovo/#evaluation-metrics","title":"Evaluation metrics\u00b6","text":"<p>Model performance without filtering:</p>"},{"location":"notebooks/getting_started_with_instanovo/#we-can-find-a-threshold-to-ensure-a-desired-fdr","title":"We can find a threshold to ensure a desired FDR:\u00b6","text":"<p>Model performance at 5% FDR:</p>"},{"location":"notebooks/getting_started_with_instanovo/#saving-the-predictions","title":"Saving the predictions...\u00b6","text":""},{"location":"notebooks/getting_started_with_instanovo/#instanovo-iterative-refinement-with-a-diffusion-model","title":"InstaNovo+: Iterative Refinement with a Diffusion Model\u00b6","text":"<p>In this section, we show how to refine the predictions from the transformer model with a diffusion model.</p> <p>First, we download the model checkpoint.</p>"},{"location":"reference/cli/","title":"Reference: Command-Line Interface","text":"<p>InstaNovo provides a command-line interface (CLI) for accessing its main functionalities.</p>"},{"location":"reference/cli/#top-level-commands","title":"Top-level commands","text":"<p>To see the main commands, run:</p> <p><pre><code>instanovo --help\n</code></pre> </p> <p>This will show the following top-level commands:</p> <ul> <li><code>predict</code>: The main command for making predictions.</li> <li><code>transformer</code>: Commands related to the InstaNovo transformer model (train, predict, etc.).</li> <li><code>diffusion</code>: Commands related to the InstaNovo+ diffusion model (train, predict, etc.).</li> <li><code>convert</code>: A command for converting data to InstaNovo's native format.</li> <li><code>version</code>: Shows the version of InstaNovo and its dependencies.</li> </ul>"},{"location":"reference/cli/#version-info","title":"Version info","text":"<p>To see the version of InstaNovo, InstaNovo+ and some of the dependencies, run:</p> <pre><code>instanovo version\n</code></pre> <p></p>"},{"location":"reference/cli/#prediction-commands","title":"Prediction commands","text":""},{"location":"reference/cli/#instanovo-predict","title":"<code>instanovo predict</code>","text":"<p>This is the default prediction command that first makes a prediction with the transformer-based InstaNovo model and then iteratively refines the result with the diffusion-based InstaNovo+ model.</p> <p><pre><code>instanovo predict --help\n</code></pre> </p>"},{"location":"reference/cli/#instanovo-transformer-predict","title":"<code>instanovo transformer predict</code>","text":"<p>This command runs prediction with only the transformer model.</p> <p><pre><code>instanovo transformer predict --help\n</code></pre> </p>"},{"location":"reference/cli/#instanovo-diffusion-predict","title":"<code>instanovo diffusion predict</code>","text":"<p>This command runs prediction with only the diffusion model.</p> <p><pre><code>instanovo diffusion predict --help\n</code></pre> </p>"},{"location":"reference/cli/#training-commands","title":"Training commands","text":""},{"location":"reference/cli/#instanovo-transformer-train","title":"<code>instanovo transformer train</code>","text":"<p>This command trains the transformer model.</p> <p><pre><code>instanovo transformer train --help\n</code></pre> </p>"},{"location":"reference/cli/#instanovo-diffusion-train","title":"<code>instanovo diffusion train</code>","text":"<p>This command trains the diffusion model.</p> <p><pre><code>instanovo diffusion train --help\n</code></pre> </p>"},{"location":"reference/cli/#data-conversion","title":"Data conversion","text":""},{"location":"reference/cli/#instanovo-convert","title":"<code>instanovo convert</code>","text":"<p>This command converts data to InstaNovo's native <code>SpectrumDataFrame</code> format.</p> <p><pre><code>instanovo convert --help\n</code></pre> </p>"},{"location":"reference/models/","title":"Models","text":"<p>InstaNovo 1.1.0 includes two new models: <code>instanovo-v1.1.0.ckpt</code>, and <code>instanovoplus-v1.1.0.ckpt</code> trained on a larger dataset with more PTMs.</p> <p>Note: The InstaNovo Extended 1.0.0 training data mis-represented Cysteine as unmodified for the majority of the training data. Please update to the latest version of the model.</p>"},{"location":"reference/models/#training-datasets","title":"Training Datasets","text":"<ul> <li>ProteomeTools Part   I (PXD004732),   II (PXD010595), and   III (PXD021013) (referred to as the all-confidence ProteomeTools <code>AC-PT</code> dataset in our paper)</li> <li>Additional PRIDE dataset with more modifications:   (PXD000666, PXD000867,   PXD001839, PXD003155,   PXD004364, PXD004612,   PXD005230, PXD006692,   PXD011360, PXD011536,   PXD013543, PXD015928,   PXD016793, PXD017671,   PXD019431, PXD019852,   PXD026910, PXD027772)</li> <li>Massive-KB v1</li> <li>Additional phosphorylation dataset   (not yet publicly released)</li> </ul>"},{"location":"reference/models/#acknowledgements","title":"Acknowledgements","text":"<p>Big thanks to Pathmanaban Ramasamy, Tine Claeys, and Lennart Martens of the CompOmics research group for providing us with additional phosphorylation training data.</p>"},{"location":"reference/modifications/","title":"Reference: Natively Supported Modifications","text":"<p>InstaNovo has been trained to recognize a set of common post-translational modifications (PTMs). This document lists the modifications that are natively supported by the pre-trained models.</p> Amino Acid Single Letter Modification Mass Delta (Da) Unimod ID Methionine M Oxidation +15.9949 UNIMOD:35 Cysteine C Carboxyamidomethylation +57.0215 UNIMOD:4 Asparagine, Glutamine N, Q Deamidation +0.9840 UNIMOD:7 Serine, Threonine, Tyrosine S, T, Y Phosphorylation +79.9663 UNIMOD:21 N-terminal - Ammonia Loss -17.0265 UNIMOD:385 N-terminal - Carbamylation +43.0058 UNIMOD:5 N-terminal - Acetylation +42.0106 UNIMOD:1 <p>The residue configuration can be found in the <code>instanovo/configs/residues/extended.yaml</code> file.</p>"},{"location":"reference/prediction_output/","title":"Reference: Prediction Output","text":"<p>When you run predictions with InstaNovo and specify an output path, a CSV file is generated. This document describes the columns in that file.</p>"},{"location":"reference/prediction_output/#standard-columns","title":"Standard Columns","text":"Column Description Data Type Notes experiment_name Experiment name derived from input filename String Based on the input file name (mgf, mzml, or mzxml) scan_number Scan number of the MS/MS spectrum Integer Unique identifier from the input file spectrum_id Unique spectrum identifier String Combination of experiment name and scan number (e.g., <code>yeast:17738</code>) precursor_mz Precursor m/z (mass-to-charge ratio) Float The observed m/z of the precursor ion precursor_charge Precursor charge state Integer Charge state of the precursor ion prediction_id Unique prediction identifier String Internal identifier for the prediction group Data group identifier String Used when running predictions on grouped data targets Target peptide sequence String Ground truth peptide sequence (only present if running in evaluation mode) predictions Best predicted peptide sequence String The final predicted peptide sequence (from InstaNovo+ when using refinement) predictions_tokenised Best predicted peptide sequence (tokenised) String The predicted sequence as comma-separated tokens log_probs Log probability of the best predicted sequence Float Natural logarithm of the sequence confidence. Higher is better. token_log_probs Log probability of each token in the best prediction List[Float] Natural logarithm of the confidence for each amino acid in the sequence delta_mass_ppm Mass difference between precursor and predicted peptide in ppm Float The mass deviation in parts per million. Lower is better."},{"location":"reference/prediction_output/#instanovo-transformer-model-columns","title":"InstaNovo (Transformer) Model Columns","text":"<p>These columns are present when using InstaNovo+ (combined transformer + diffusion model).</p> Column Description Data Type Notes instanovo_predictions Predicted peptide sequence from InstaNovo String The initial peptide sequence from the transformer instanovo_log_probabilities Log probability from InstaNovo Float Natural logarithm of the sequence confidence instanovo_token_log_probabilities Token log probabilities from InstaNovo List[Float] Natural logarithm of the confidence for each token instanovo_predictions_beam_0-4 Predicted sequences from each beam String Beam search results when num_beams &gt; 1 instanovo_log_probabilities_beam_0-4 Log probabilities from each beam Float Confidence scores for each beam instanovo_token_log_probabilities_beam_0-4 Token log probabilities from each beam List[Float] Per-token confidence for each beam"},{"location":"reference/prediction_output/#instanovo-diffusion-model-columns","title":"InstaNovo+ (Diffusion) Model Columns","text":"<p>These columns are present when using InstaNovo+ (combined transformer + diffusion model).</p> Column Description Data Type Notes diffusion_predictions Predicted peptide sequence from InstaNovo+ String The refined peptide sequence from the diffusion diffusion_log_probabilities Log probability from InstaNovo+ Float Natural logarithm of the sequence confidence diffusion_token_log_probabilities Token log probabilities from InstaNovo+ List[Float] Natural logarithm of the confidence for each token diffusion_unrefined_predictions Unrefined predictions from InstaNovo+ String Predictions before refinement diffusion_predictions_beam_0-4 Predicted sequences from each beam String Beam search results when num_beams &gt; 1 diffusion_log_probabilities_beam_0-4 Log probabilities from each beam Float Confidence scores for each beam"},{"location":"reference/prediction_output/#usage-notes","title":"Usage Notes","text":"<ul> <li>When using InstaNovo+ with refinement, the <code>predictions</code> column contains the best prediction from the diffusion model.</li> <li>We recommend filtering the output based on the <code>diffusion_log_probabilities</code> and <code>delta_mass_ppm</code> columns to obtain a set of high-confidence predictions.</li> <li>Beam search columns (beam_0 through beam_4) are only present when running with <code>num_beams &gt; 1</code>.</li> <li>The transformer model columns are prefixed with <code>instanovo_</code> and diffusion model columns are prefixed with <code>diffusion_</code>.</li> </ul>"},{"location":"tutorials/getting_started/","title":"Quick overview","text":"<p>This tutorial will guide you through the first steps of using InstaNovo, from installation to making your first predictions.</p>"},{"location":"tutorials/getting_started/#what-is-de-novo-peptide-sequencing","title":"What is de novo peptide sequencing?","text":"<p>In proteomics, scientists study proteins, which are large, complex molecules made up of smaller units called amino acids. To understand a protein's function, we often need to know its amino acid sequence.</p> <p>Mass spectrometry is a technique used to measure the mass-to-charge ratio of ions. In a typical proteomics experiment, proteins are broken down into smaller pieces called peptides. These peptides are then analyzed by a mass spectrometer, which generates a spectrum of peaks. Each peak corresponds to a fragment of the peptide.</p> <p>De novo peptide sequencing is the process of determining the amino acid sequence of a peptide directly from its tandem mass spectrum (MS/MS) without relying on a sequence database. This is where InstaNovo comes in.</p>"},{"location":"tutorials/getting_started/#installation","title":"Installation","text":"<p>To use InstaNovo, you first need to install the Python package. You can do this using <code>pip</code>.</p> <p>If you have access to an NVIDIA GPU, we recommend installing InstaNovo with the GPU version of PyTorch for better performance:</p> <pre><code>pip install \"instanovo[cu126]\"\n</code></pre> <p>If you are on a machine without a GPU, or on macOS, you can install the CPU-only version:</p> <pre><code>pip install \"instanovo[cpu]\"\n</code></pre> <p>InstaNovo now has support for Metal Performance Shaders (MPS) for Apple silicon devices. See https://developer.apple.com/documentation/metalperformanceshaders for more information on MPS. If you would like to use InstaNovo with MPS, please set 'mps' to True in the configuration files (instanovo/configs/) and set the environment variable:</p> <pre><code>PYTORCH_ENABLE_MPS_FALLBACK=1\n</code></pre> <p>This allows the CPU to be used for functionality not yet supported on MPS. Note <code>torch&lt;2.8.0</code> is required if running on MPS.</p> <p>For more details on installation for development, see the development guide.</p>"},{"location":"tutorials/getting_started/#making-your-first-prediction","title":"Making your first prediction","text":"<p>Once InstaNovo is installed, you can use the command-line interface (CLI) to make predictions.</p> <p>Let's try predicting the peptide sequence from a sample spectrum file. InstaNovo comes with a sample data file (<code>spectra.mgf</code>) for this purpose.</p> <p>The following command runs prediction with the base InstaNovo model and iteratively refines the results with the InstaNovo+ model:</p> <pre><code>instanovo predict --data-path ./sample_data/spectra.mgf --output-path predictions.csv\n</code></pre> <p>For a full overview of how to make predictions with our different models, see our predicting how-to guide.</p>"},{"location":"tutorials/getting_started/#understanding-the-output","title":"Understanding the output","text":"<p>The <code>instanovo predict</code> command in the previous step created a file named <code>predictions.csv</code> with the predicted peptide sequences:</p> <pre><code>experiment_name,scan_number,spectrum_id,precursor_mz,precursor_charge,prediction_id,predictions,log_probs,token_log_probs,group,instanovo_predictions,instanovo_log_probabilities,instanovo_token_log_probabilities,instanovo_predictions_beam_0,instanovo_log_probabilities_beam_0,instanovo_token_log_probabilities_beam_0,instanovo_predictions_beam_1,instanovo_log_probabilities_beam_1,instanovo_token_log_probabilities_beam_1,instanovo_predictions_beam_2,instanovo_log_probabilities_beam_2,instanovo_token_log_probabilities_beam_2,instanovo_predictions_beam_3,instanovo_log_probabilities_beam_3,instanovo_token_log_probabilities_beam_3,instanovo_predictions_beam_4,instanovo_log_probabilities_beam_4,instanovo_token_log_probabilities_beam_4,diffusion_predictions,diffusion_log_probabilities,diffusion_token_log_probabilities,diffusion_unrefined_predictions,diffusion_predictions_beam_0,diffusion_log_probabilities_beam_0,diffusion_predictions_beam_1,diffusion_log_probabilities_beam_1,diffusion_predictions_beam_2,diffusion_log_probabilities_beam_2,diffusion_predictions_beam_3,diffusion_log_probabilities_beam_3,diffusion_predictions_beam_4,diffusion_log_probabilities_beam_4,predictions_tokenised,delta_mass_ppm\nspectra,0,spectra:0,451.25348,2,0,LAHYNKR,-0.04958329349756241,,no_group,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-1.4490094184875488,[0],LAHYNKR,-1.4490094184875488,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],LAHYNKR,-1.7640595436096191,[0],\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.04958329349756241,,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.260211318731308,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.5505515336990356,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.08841510117053986,\"['L', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.04958329349756241,\"['I', 'A', 'H', 'Y', 'N', 'K', 'R']\",-0.1989564299583435,\"L, A, H, Y, N, K, R\",0.6781111138830191\n</code></pre> <p>This output CSV file contains several columns. Here are some of the most important ones:</p> Column Description <code>scan_number</code> The scan number of the spectrum in the input file. <code>precursor_mz</code> The mass-to-charge ratio of the precursor ion. <code>precursor_charge</code> The charge of the precursor ion. <code>diffusion_predictions</code> The peptide sequence predicted by InstaNovo+. <code>transformer_predictions</code> The peptide sequence predicted by the base InstaNovo model. <code>log_probs</code> The log probability of the prediction. Higher (less negative) values indicate greater model confidence in the predicted output. <p>For a full description of the output, see the prediction output reference.</p>"},{"location":"tutorials/getting_started/#evaluating-performance","title":"Evaluating performance","text":"<p>If your input data is annotated with the true peptide sequences, you can evaluate InstaNovo's performance.</p> <p>Use the <code>--evaluation</code> flag to enable evaluation mode:</p> <pre><code>instanovo predict --evaluation --data-path ./sample_data/spectra.mgf --output-path predictions.csv\n</code></pre> <p>This will add a <code>targets</code> column to the output file with the ground truth sequences and will print performance metrics to the console.</p> <p>For more background regarding the metrics we use for evaluation, see our explanation on performance metrics.</p>"},{"location":"tutorials/getting_started/#huggingface-space","title":"HuggingFace Space","text":"<p>InstaNovo is available as a HuggingFace Space at hf.co/spaces/InstaDeepAI/InstaNovo for quick testing and evaluation. You can upload your own spectra files in <code>.mgf</code>, <code>.mzml</code>, or <code>.mzxml</code> format and run de novo predictions. The results will be displayed in a table format, and you can download the predictions as a CSV file. The HuggingFace Space is powered by the InstaNovo model and the InstaNovo+ model for iterative refinement.</p> <p></p>"},{"location":"tutorials/getting_started/#next-steps","title":"Next steps","text":"<p>Now that you've made your first predictions, you can explore more of what InstaNovo has to offer:</p> <ul> <li>Learn how to make predictions with different models and settings in the predicting how-to guide.</li> <li>Find out how to train your own models in the training how-to guide.</li> <li>Dive deeper into the concepts behind InstaNovo in the explanation section.</li> </ul>"},{"location":"development/coverage/","title":"Test Coverage","text":"<p>This page provides the test coverage report for InstaNovo.</p> <p> </p>"},{"location":"development/coverage/#running-coverage-locally","title":"Running Coverage Locally","text":"<p>To generate a new coverage report locally, run:</p> <pre><code>make coverage\n</code></pre> <p>This will generate an updated coverage report in the <code>docs/coverage/</code> directory.</p>"}]}