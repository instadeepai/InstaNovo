{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#de-novo-peptide-sequencing-with-instanovo","title":"De novo peptide sequencing with InstaNovo","text":"<p>The official code repository for InstaNovo. This repo contains the code for training and inference of InstaNovo and InstaNovo+. InstaNovo is a transformer neural network with the ability to translate fragment ion peaks into the sequence of amino acids that make up the studied peptide(s). InstaNovo+, inspired by human intuition, is a multinomial diffusion model that further improves performance by iterative refinement of predicted sequences.</p> <p></p> <p>Links:</p> <ul> <li>Publication in Nature Machine Intelligence:   InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale proteomics experiments</li> <li>InstaNovo blog: https://instanovo.ai/</li> <li>Documentation:   https://instadeepai.github.io/InstaNovo/</li> </ul> <p>Developed by:</p> <ul> <li>InstaDeep</li> <li>The Department of Biotechnology and Biomedicine -   Technical University of Denmark</li> </ul>"},{"location":"#usage","title":"Usage","text":""},{"location":"#huggingface-space","title":"HuggingFace Space","text":"<p>InstaNovo is available as a HuggingFace Space at hf.co/spaces/InstaDeepAI/InstaNovo for quick testing and evaluation. You can upload your own spectra files in <code>.mgf</code>, <code>.mzml</code>, or <code>.mzxml</code> format and run de novo predictions. The results will be displayed in a table format, and you can download the predictions as a CSV file. The HuggingFace Space is powered by the InstaNovo model and the InstaNovo+ model for iterative refinement.</p> <p></p>"},{"location":"#installation","title":"Installation","text":"<p>To use InstaNovo Python package with command line interface, we need to install the module via <code>pip</code>:</p> <pre><code>pip install instanovo\n</code></pre> <p>If you have access to an NVIDIA GPU, you can install InstaNovo with the GPU version of PyTorch (recommended):</p> <pre><code>pip install \"instanovo[cu124]\"\n</code></pre> <p>If you are on macOS, you can install the CPU-only version of PyTorch:</p> <pre><code>pip install \"instanovo[cpu]\"\n</code></pre>"},{"location":"#command-line-usage","title":"Command line usage","text":"<p>InstaNovo provides a comprehensive command line interface (CLI) for both prediction and training tasks.</p> <p>To get help and see the available commands:</p> <pre><code>instanovo --help\n</code></pre> <p></p> <p>To see the version of InstaNovo, InstaNovo+ and some of the dependencies:</p> <pre><code>instanovo version\n</code></pre> <p></p>"},{"location":"#predicting","title":"Predicting","text":"<p>To get help about the prediction command line options:</p> <pre><code>instanovo predict --help\n</code></pre> <p></p>"},{"location":"#running-predictions-with-both-instanovo-and-instanovo","title":"Running predictions with both InstaNovo and InstaNovo+","text":"<p>The default is to run predictions first with the transformer-based InstaNovo model, and then further improve the performance by iterative refinement of these predicted sequences by the diffusion-based InstaNov+ model.</p> <pre><code>instanovo predict --data-path ./sample_data/spectra.mgf --output-path predictions.csv\n</code></pre> <p>Which results in the following output:</p> <pre><code>scan_number,precursor_mz,precursor_charge,experiment_name,spectrum_id,diffusion_predictions_tokenised,diffusion_predictions,diffusion_log_probabilities,transformer_predictions,transformer_predictions_tokenised,transformer_log_probabilities,transformer_token_log_probabilities\n0,451.25348,2,spectra,spectra:0,\"['A', 'L', 'P', 'Y', 'T', 'P', 'K', 'K']\",ALPYTPKK,-0.03160184621810913,LAHYNKK,\"L, A, H, Y, N, K, K\",-424.5889587402344,\"[-0.5959059000015259, -0.0059959776699543, -0.01749008148908615, -0.03598890081048012, -0.48958998918533325, -1.5242897272109985, -0.656516432762146]\"\n</code></pre> <p>To evaluate InstaNovo performance on an annotated dataset:</p> <pre><code>instanovo predict --evaluation --data-path ./sample_data/spectra.mgf --output-path predictions.csv\n</code></pre> <p>Which results in the following output:</p> <pre><code>scan_number,precursor_mz,precursor_charge,experiment_name,spectrum_id,diffusion_predictions_tokenised,diffusion_predictions,diffusion_log_probabilities,targets,transformer_predictions,transformer_predictions_tokenised,transformer_log_probabilities,transformer_token_log_probabilities\n0,451.25348,2,spectra,spectra:0,\"['L', 'A', 'H', 'Y', 'N', 'K', 'K']\",LAHYNKK,-0.06637095659971237,IAHYNKR,LAHYNKK,\"L, A, H, Y, N, K, K\",-424.5889587402344,\"[-0.5959059000015259, -0.0059959776699543, -0.01749008148908615, -0.03598890081048012, -0.48958998918533325, -1.5242897272109985, -0.656516432762146]\"\n</code></pre> <p>Note that the <code>--evaluation</code> flag includes the <code>targets</code> column in the output, which contains the ground truth peptide sequence. Metrics will be calculated and displayed in the console.</p>"},{"location":"#command-line-arguments-and-overriding-config-values","title":"Command line arguments and overriding config values","text":"<p>The configuration file for inference may be found under instanovo/configs/inference/ folder. By default, the <code>default.yaml</code> file is used.</p> <p>InstaNovo uses command line arguments for commonly used parameters:</p> <ul> <li><code>--data-path</code> - Path to the dataset to be evaluated. Allows <code>.mgf</code>, <code>.mzml</code>, <code>.mzxml</code>, <code>.ipc</code> or a   directory. Glob notation is supported: eg.: <code>./experiment/*.mgf</code></li> <li><code>--output-path</code> - Path to output csv file.</li> <li><code>--instanovo-model</code> - Model to use for InstaNovo. Either a model ID (currently supported:   <code>instanovo-v1.1.0</code>) or a path to an Instanovo checkpoint file (.ckpt format).</li> <li><code>--instanovo-plus-model</code> - Model to use for InstaNovo+. Either a model ID (currently supported:   <code>instanovoplus-v1.1.0</code>) or a path to an Instanovo+ checkpoint file (.ckpt format).</li> <li><code>--denovo</code> - Whether to do de novo predictions. If you want to evaluate the model on annotated   data, use the flag <code>--evaluation</code> flag.</li> <li><code>--with-refinement</code> - Whether to use InstaNovo+ for iterative refinement of InstaNovo predictions.   Default is <code>True</code>. If you don't want to use refinement,use the flag <code>--no-refinement</code>.</li> </ul> <p>To override the configuration values in the config files, you can use command line arguments. For example, by default beam search with one beam is used. If you want to use beam search with 5 beams, you can use the following command:</p> <pre><code>instanovo predict --data-path ./sample_data/spectra.mgf --output-path predictions.csv num_beams=5\n</code></pre> <p>Note the lack of prefix <code>--</code> before <code>num_beams</code> in the command line argument because you are overriding the value of key defined in the config file.</p> <p>Output description</p> <p>When <code>output_path</code> is specified, a CSV file will be generated containing predictions for all the input spectra. The model will attempt to generate a peptide for every MS2 spectrum regardless of confidence. We recommend filtering the output using the log_probabilities and delta_mass_ppm columns.</p> Column Description Data Type Notes scan_number Scan number of the MS/MS spectrum Integer Unique identifier from the input file precursor_mz Precursor m/z (mass-to-charge ratio) Float The observed m/z of the precursor ion precursor_charge Precursor charge state Integer Charge state of the precursor ion experiment_name Experiment name derived from input filename String Based on the input file name (mgf, mzml, or mzxml) spectrum_id Unique spectrum identifier String Combination of experiment name and scan number (e.g., <code>yeast:17738</code>) targets Target peptide sequence String Ground truth peptide sequence (if available) predictions Predicted peptide sequences String Model-predicted peptide sequence predictions_tokenised Predicted peptide sequence tokenized by amino acids List[String] Each amino acid token separated by commas log_probabilities Log probability of the entire predicted sequence Float Natural logarithm of the sequence confidence, can be converted to probability with np.exp(log_probabilities). token_log_probabilities Log probability of each token in the predicted sequence List[Float] Natural logarithm of the sequence confidence per amino acid delta_mass_ppm Mass difference between precursor and predicted peptide in ppm Float Mass deviation in parts per million"},{"location":"#models","title":"Models","text":"<p>InstaNovo 1.1.0 includes new models <code>instanovo-v1.1.0.ckpt</code>, and <code>instanovoplus-v1.1.0.ckpt</code> trained on a larger dataset with more PTMs.</p> <p>Note: The InstaNovo Extended 1.0.0 training data mis-represented Cysteine as unmodified for the majority of the training data. Please update to the latest version of the model.</p> <p>Training Datasets</p> <ul> <li>ProteomeTools Part   I (PXD004732),   II (PXD010595), and   III (PXD021013) \\   (referred to as the all-confidence ProteomeTools <code>AC-PT</code> dataset in our paper)</li> <li>Additional PRIDE dataset with more modifications: \\   (PXD000666, PXD000867,   PXD001839, PXD003155,   PXD004364, PXD004612,   PXD005230, PXD006692,   PXD011360, PXD011536,   PXD013543, PXD015928,   PXD016793, PXD017671,   PXD019431, PXD019852,   PXD026910, PXD027772)</li> <li>Massive-KB v1</li> <li>Additional phosphorylation dataset \\   (not yet publicly released)</li> </ul> <p>Natively Supported Modifications</p> Amino Acid Single Letter Modification Mass Delta (Da) Unimod ID Methionine M Oxidation +15.9949 [UNIMOD:35] Cysteine C Carboxyamidomethylation +57.0215 [UNIMOD:4] Asparagine, Glutamine N, Q Deamidation +0.9840 [UNIMOD:7] Serine, Threonine, Tyrosine S, T, Y Phosphorylation +79.9663 [UNIMOD:21] N-terminal - Ammonia Loss -17.0265 [UNIMOD:385] N-terminal - Carbamylation +43.0058 [UNIMOD:5] N-terminal - Acetylation +42.0106 [UNIMOD:1] <p>See residue configuration under instanovo/configs/residues/extended.yaml</p>"},{"location":"#training","title":"Training","text":"<p>Data to train on may be provided in any format supported by the SpectrumDataHandler. See section on data conversion for preferred formatting.</p>"},{"location":"#training-instanovo","title":"Training InstaNovo","text":"<p>To train the auto-regressive transformer model InstaNovo using the config file instanovo/configs/instanovo.yaml, you can use the following command:</p> <pre><code>instanovo transformer train --help\n</code></pre> <p></p> <p>To update the InstaNovo model config, modify the config file under instanovo/configs/model/instanovo_base.yaml</p>"},{"location":"#training-instanovo_1","title":"Training InstaNovo+","text":"<p>To train the diffusion model InstaNovo+ using the config file instanovo/configs/instanovoplus.yaml, you can use the following command:</p> <pre><code>instanovo diffusion train --help\n</code></pre> <p></p> <p>To update the InstaNovo+ model config, modify the config file under instanovo/configs/model/instanovoplus_base.yaml</p>"},{"location":"#advanced-prediction-options","title":"Advanced prediction options","text":""},{"location":"#run-predictions-with-only-instanovo","title":"Run predictions with only InstaNovo","text":"<p>If you want to run predictions with only InstaNovo, you can use the following command:</p> <pre><code>instanovo transformer predict --help\n</code></pre> <p></p>"},{"location":"#run-predictions-with-only-instanovo_1","title":"Run predictions with only InstaNovo+","text":"<p>If you want to run predictions with only InstaNovo+, you can use the following command:</p> <pre><code>instanovo diffusion predict --help\n</code></pre> <p></p>"},{"location":"#run-predictions-with-instanovo-and-instanovo-in-separate-steps","title":"Run predictions with InstaNovo and InstaNovo+ in separate steps","text":"<p>You can first run predictions with InstaNovo</p> <pre><code>instanovo transformer predict --data-path ./sample_data/spectra.mgf --output-path instanovo_predictions.csv\n</code></pre> <p>and then use the predictions as input for InstaNovo+:</p> <pre><code>instanovo diffusion predict --data-path ./sample_data/spectra.mgf --output-path instanovo_plus_predictions.csv instanovo_predictions_path=instanovo_predictions.csv\n</code></pre>"},{"location":"#performance","title":"Performance","text":"<p>We have benchmarked our latest models InstaNovo v1.1 and InstaNovo+ v1.1 against our previous models. For all results below, InstaNovo decoding was performed with knapsack beam search decoding. InstaNovo+ then refined these results. We present peptide accuracy as the metric of comparison. Peptide accuracy is a measure of precision at full coverage (no filtering).</p>"},{"location":"#nine-species-dataset","title":"Nine-species dataset","text":"Dataset InstaNovo v0.1 InstaNovo+ v0.1 InstaNovo v1.1 InstaNovo+ v1.1 Bacillus 0.624 0.674 0.652 0.684 Mouse 0.466 0.490 0.524 0.542 Yeast 0.559 0.624 0.618 0.645 <p>InstaNovo and InstaNovo+ v0.1 were fine-tuned on the eight species dataset, excluding the test species, whereas InstaNovo and InstaNovo+ v1.1 were evaluated zero-shot on these datasets.</p>"},{"location":"#biological-validation-datasets","title":"Biological validation datasets","text":"Dataset InstaNovo v0.1 InstaNovo+ v0.1 InstaNovo v1.1 InstaNovo+ v1.1 HeLa degradome 0.695 0.719 0.813 0.821 HeLa single-shot 0.503 0.517 0.642 0.647 Herceptin 0.494 0.562 0.710 0.720 Immunopeptidomics 0.581 0.697 0.707 0.748 Candidatus \"Scalindua brodae\" 0.724 0.736 0.748 0.762 Snake venoms 0.196 0.198 0.221 0.238 Nanobodies 0.447 0.464 0.492 0.508 Wound fluids 0.225 0.229 0.354 0.364"},{"location":"#additional-features","title":"Additional features","text":""},{"location":"#spectrum-data-class","title":"Spectrum Data Class","text":"<p>InstaNovo introduces a Spectrum Data Class: SpectrumDataFrame. This class acts as an interface between many common formats used for storing mass spectrometry, including <code>.mgf</code>, <code>.mzml</code>, <code>.mzxml</code>, and <code>.csv</code>. This class also supports reading directly from HuggingFace, Pandas, and Polars.</p> <p>When using InstaNovo, these formats are natively supported and automatically converted to the internal SpectrumDataFrame supported by InstaNovo for training and inference. Any data path may be specified using glob notation. For example you could use the following command to get de novo predictions from all the files in the folder <code>./experiment</code>:</p> <pre><code>instanovo predict --data_path=./experiment/*.mgf\n</code></pre> <p>Alternatively, a list of files may be specified in the inference config.</p> <p>The SpectrumDataFrame also allows for loading of much larger datasets in a lazy way. To do this, the data is loaded and stored as <code>.parquet</code> files in a temporary directory. Alternatively, the data may be saved permanently natively as <code>.parquet</code> for optimal loading.</p> <p>Example usage:</p> <p>Converting mgf files to the native format:</p> <pre><code>from instanovo.utils import SpectrumDataFrame\n\n# Convert mgf files native parquet:\nsdf = SpectrumDataFrame.load(\"/path/to/data.mgf\", lazy=False, is_annotated=True)\nsdf.save(\"path/to/parquet/folder\", partition=\"train\", chunk_size=1e6)\n</code></pre> <p>Loading the native format in shuffle mode:</p> <pre><code># Load a native parquet dataset:\nsdf = SpectrumDataFrame.load(\"path/to/parquet/folder\", partition=\"train\", shuffle=True, lazy=True, is_annotated=True)\n</code></pre> <p>Using the loaded SpectrumDataFrame in a PyTorch DataLoader:</p> <pre><code>from instanovo.transformer.dataset import SpectrumDataset\nfrom torch.utils.data import DataLoader\n\nds = SpectrumDataset(sdf)\n# Note: Shuffle and workers is handled by the SpectrumDataFrame\ndl = DataLoader(\n    ds,\n    collate_fn=SpectrumDataset.collate_batch,\n    shuffle=False,\n    num_workers=0,\n)\n</code></pre> <p>Some more examples using the SpectrumDataFrame:</p> <pre><code>sdf = SpectrumDataFrame.load(\"/path/to/experiment/*.mzml\", lazy=True)\n\n# Remove rows with a charge value &gt; 3:\nsdf.filter_rows(lambda row: row[\"precursor_charge\"]&lt;=2)\n\n# Sample a subset of the data:\nsdf.sample_subset(fraction=0.5, seed=42)\n\n# Convert to pandas\ndf = sdf.to_pandas() # Returns a pd.DataFrame\n\n# Convert to polars LazyFrame\nlazy_df = sdf.to_polars(return_lazy=True) # Returns a pl.LazyFrame\n\n# Save as an `.mgf` file\nsdf.write_mgf(\"path/to/output.mgf\")\n</code></pre> <p>SpectrumDataFrame Features:</p> <ul> <li>The SpectrumDataFrame supports lazy loading with asynchronous prefetching, mitigating wait times   between files.</li> <li>Filtering and sampling may be performed non-destructively through on file loading</li> <li>A two-fold shuffling strategy is introduced to optimise sampling during training (shuffling files   and shuffling within files).</li> </ul>"},{"location":"#using-your-own-datasets","title":"Using your own datasets","text":"<p>To use your own datasets, you simply need to tabulate your data in either Pandas or Polars with the following schema:</p> <p>The dataset is tabular, where each row corresponds to a labelled MS2 spectra.</p> <ul> <li><code>sequence (string)</code> \\   The target peptide sequence including post-translational modifications</li> <li><code>modified_sequence (string) [legacy]</code> \\   The target peptide sequence including post-translational modifications</li> <li><code>precursor_mz (float64)</code> \\   The mass-to-charge of the precursor (from MS1)</li> <li><code>charge (int64)</code> \\   The charge of the precursor (from MS1)</li> <li><code>mz_array (list[float64])</code> \\   The mass-to-charge values of the MS2 spectrum</li> <li><code>intensity_array (list[float32])</code> \\   The intensity values of the MS2 spectrum</li> </ul> <p>For example, the DataFrame for the nine species benchmark dataset (introduced in Tran et al. 2017) looks as follows:</p> sequence precursor_mz precursor_charge mz_array intensity_array 0 GRVEGMEAR 335.502 3 [102.05527 104.052956 113.07079 ...] [ 767.38837 2324.8787 598.8512 ...] 1 IGEYK 305.165 2 [107.07023 110.071236 111.11693 ...] [ 1055.4957 2251.3171 35508.96 ...] 2 GVSREEIQR 358.528 3 [103.039444 109.59844 112.08704 ...] [801.19995 460.65268 808.3431 ...] 3 SSYHADEQVNEASK 522.234 3 [101.07095 102.0552 110.07163 ...] [ 989.45154 2332.653 1170.6191 ...] 4 DTFNTSSTSN[UNIMOD:7]STSSSSSNSK 676.282 3 [119.82458 120.08073 120.2038 ...] [ 487.86942 4806.1377 516.8846 ...] <p>For de novo prediction, the <code>sequence</code> column is not required.</p> <p>We also provide a conversion script for converting to native SpectrumDataFrame (sdf) format:</p> <pre><code>instanovo convert --help\n</code></pre> <p></p>"},{"location":"#development","title":"Development","text":""},{"location":"#uv-setup","title":"<code>uv</code> setup","text":"<p>This project is set up to use uv to manage Python and dependencies. First, be sure you have uv installed on your system.</p> <p>On Linux and macOS:</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <p>On Windows:</p> <pre><code>powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre> <p>Note: InstaNovo is built for Python &gt;=3.10, &lt;3.13 and tested on Linux.</p>"},{"location":"#fork-and-clone-the-repository","title":"Fork and clone the repository","text":"<p>Then fork this repo (having your own fork will make it easier to contribute) and clone it.</p> <pre><code>git clone https://github.com/YOUR-USERNAME/InstaNovo.git\ncd InstaNovo\n</code></pre> <p>And install the dependencies. If you do have access to an NVIDIA GPU, you can install the GPU version of PyTorch (recommended):</p> <pre><code>uv sync --extra cu124\nuv run pre-commit install\n</code></pre> <p>If you don't have access to a GPU, you can install the CPU-only version of PyTorch:</p> <pre><code>uv sync --extra cpu\nuv run pre-commit install\n</code></pre> <p>Both approaches above also install the development dependencies. If you also want to install the documentation dependencies, you can do so with:</p> <pre><code>uv sync --extra cu124 --group docs\n</code></pre> <p>Activate the virtual environment:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>To upgrade all packages to the latest versions, you can run:</p> <pre><code>uv lock --upgrade\nuv sync --extra cu124\n</code></pre>"},{"location":"#basic-development-workflows","title":"Basic development workflows","text":""},{"location":"#testing","title":"Testing","text":"<p>InstaNovo uses <code>pytest</code> for testing. To run the tests, you can use the following command:</p> <pre><code>uv run instanovo/scripts/get_zenodo_record.py # Download the test data\npython -m pytest --cov-report=html --cov --random-order --verbose .\n</code></pre> <p>To see the coverage report, run:</p> <pre><code>python -m coverage report -m\n</code></pre> <p>To view the coverage report in a browser, run:</p> <pre><code>python -m http.server --directory ./coverage\n</code></pre> <p>and navigate to <code>http://0.0.0.0:8000/</code> in your browser.</p>"},{"location":"#linting","title":"Linting","text":"<p>InstaNovo uses pre-commit hooks to ensure code quality. To run the linters, you can use the following command:</p> <pre><code>pre-commit run --all-files\n</code></pre>"},{"location":"#building-the-documentation","title":"Building the documentation","text":"<p>To build the documentation locally, you can use the following commands:</p> <pre><code>uv sync --extra cu124 --group docs\ngit config --global --add safe.directory \"$(dirname \"$(pwd)\")\"\nrm -rf docs/reference\npython ./docs/gen_ref_nav.py\nmkdocs build --verbose --site-dir docs_public\nmkdocs serve\n</code></pre>"},{"location":"#generating-a-requirementstxt-file","title":"Generating a requirements.txt file","text":"<p>If you have a <code>pip</code> or <code>conda</code> based workflow and want to generate a <code>requirements.txt</code> file, you can use the following command:</p> <pre><code>uv export --format requirements-txt &gt; requirements.txt\n</code></pre>"},{"location":"#setting-python-interpreter-in-vscode","title":"Setting Python interpreter in VSCode","text":"<p>To set the Python interpreter in VSCode, open the Command Palette (<code>Ctrl+Shift+P</code>), search for <code>Python: Select Interpreter</code>, and select <code>./.venv/bin/python</code>.</p>"},{"location":"#license","title":"License","text":"<p>Code is licensed under the Apache License, Version 2.0 (see LICENSE)</p> <p>The model checkpoints are licensed under Creative Commons Non-Commercial (CC BY-NC-SA 4.0)</p>"},{"location":"#bibtex-entry-and-citation-info","title":"BibTeX entry and citation info","text":"<p>If you use InstaNovo in your research, please cite the following paper:</p> <pre><code>@article{eloff_kalogeropoulos_2025_instanovo,\n        title        = {InstaNovo enables diffusion-powered de novo peptide sequencing in large-scale\n                        proteomics experiments},\n        author       = {Eloff, Kevin and Kalogeropoulos, Konstantinos and Mabona, Amandla and Morell,\n                        Oliver and Catzel, Rachel and Rivera-de-Torre, Esperanza and Berg Jespersen,\n                        Jakob and Williams, Wesley and van Beljouw, Sam P. B. and Skwark, Marcin J.\n                        and Laustsen, Andreas Hougaard and Brouns, Stan J. J. and Ljungars,\n                        Anne and Schoof, Erwin M. and Van Goey, Jeroen and auf dem Keller, Ulrich and\n                        Beguir, Karim and Lopez Carranza, Nicolas and Jenkins, Timothy P.},\n        year         = 2025,\n        month        = {Mar},\n        day          = 31,\n        journal      = {Nature Machine Intelligence},\n        doi          = {10.1038/s42256-025-01019-5},\n        issn         = {2522-5839},\n        url          = {https://doi.org/10.1038/s42256-025-01019-5}\n}\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Big thanks to Pathmanaban Ramasamy, Tine Claeys, and Lennart Martens of the CompOmics research group for providing us with additional phosphorylation training data.</p>"},{"location":"LICENSE/","title":"Apache License","text":"<p>Version 2.0, January 2004 &lt;http://www.apache.org/licenses/&gt;</p>"},{"location":"LICENSE/#terms-and-conditions-for-use-reproduction-and-distribution","title":"Terms and Conditions for use, reproduction, and distribution","text":""},{"location":"LICENSE/#1-definitions","title":"1. Definitions","text":"<p>\u201cLicense\u201d shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.</p> <p>\u201cLicensor\u201d shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.</p> <p>\u201cLegal Entity\u201d shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \u201ccontrol\u201d means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\u201cYou\u201d (or \u201cYour\u201d) shall mean an individual or Legal Entity exercising permissions granted by this License.</p> <p>\u201cSource\u201d form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.</p> <p>\u201cObject\u201d form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.</p> <p>\u201cWork\u201d shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).</p> <p>\u201cDerivative Works\u201d shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.</p> <p>\u201cContribution\u201d shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \u201csubmitted\u201d means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \u201cNot a Contribution.\u201d</p> <p>\u201cContributor\u201d shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.</p>"},{"location":"LICENSE/#2-grant-of-copyright-license","title":"2. Grant of Copyright License","text":"<p>Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.</p>"},{"location":"LICENSE/#3-grant-of-patent-license","title":"3. Grant of Patent License","text":"<p>Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.</p>"},{"location":"LICENSE/#4-redistribution","title":"4. Redistribution","text":"<p>You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:</p> <ul> <li>(a) You must give any other recipients of the Work or Derivative Works a copy of this License;   and</li> <li>(b) You must cause any modified files to carry prominent notices stating that You changed the   files; and</li> <li>(c) You must retain, in the Source form of any Derivative Works that You distribute, all   copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding   those notices that do not pertain to any part of the Derivative Works; and</li> <li>(d) If the Work includes a \u201cNOTICE\u201d text file as part of its distribution, then any Derivative   Works that You distribute must include a readable copy of the attribution notices contained within   such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works,   in at least one of the following places: within a NOTICE text file distributed as part of the   Derivative Works; within the Source form or documentation, if provided along with the Derivative   Works; or, within a display generated by the Derivative Works, if and wherever such third-party   notices normally appear. The contents of the NOTICE file are for informational purposes only and   do not modify the License. You may add Your own attribution notices within Derivative Works that   You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such   additional attribution notices cannot be construed as modifying the License.</li> </ul> <p>You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.</p>"},{"location":"LICENSE/#5-submission-of-contributions","title":"5. Submission of Contributions","text":"<p>Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.</p>"},{"location":"LICENSE/#6-trademarks","title":"6. Trademarks","text":"<p>This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.</p>"},{"location":"LICENSE/#7-disclaimer-of-warranty","title":"7. Disclaimer of Warranty","text":"<p>Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \u201cAS IS\u201d BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.</p>"},{"location":"LICENSE/#8-limitation-of-liability","title":"8. Limitation of Liability","text":"<p>In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.</p>"},{"location":"LICENSE/#9-accepting-warranty-or-additional-liability","title":"9. Accepting Warranty or Additional Liability","text":"<p>While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.</p> <p>END OF TERMS AND CONDITIONS</p>"},{"location":"LICENSE/#appendix-how-to-apply-the-apache-license-to-your-work","title":"APPENDIX: How to apply the Apache License to your work","text":"<p>To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets <code>[]</code> replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \u201cprinted page\u201d as the copyright notice for easier identification within third-party archives.</p> <pre><code>Copyright [yyyy] [name of copyright owner]\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"}]}