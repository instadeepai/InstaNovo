stages:
  - build
  - lint
  - test
  - deploy
  - publish

variables:
  PRE_COMMIT_VERSION: "2.20.0"
  PROJECT_NAME: dtu_denovo_sequencing
  DOCKER_IMAGE_NAME: registry.gitlab.com/instadeep/dtu-denovo-sequencing
  COOKIECUTTER_VERSION: "2.1.1"

workflow:
  rules:
    # Skip job if commit message starts with 'exp'
    # Add check on $CI_PIPELINE_SOURCE to avoid duplicated pipelines
    # i.e. for both push + merge_request_event in case of opened MR
    - if: $CI_COMMIT_MESSAGE !~ '/^exp.*/' && $CI_PIPELINE_SOURCE == "push"

.docker-login:
  image: eu.gcr.io/int-infra-harborbackup-gcp/docker-hub/docker:19.03
  variables:
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  cache:
    paths:
      - .cache/pip
      - venv/
  tags:
    # Use Kao runners (i.e. our infra) to have access to grc registry
    - kao-k8s-runner
  services:
    - eu.gcr.io/int-infra-harborbackup-gcp/docker-hub/docker:19.03-dind
  before_script:
    - echo "$CI_REGISTRY_PASSWORD" | docker login -u "$CI_REGISTRY_USER" --password-stdin
      "$CI_REGISTRY"

linters:
  extends: .docker-login
  stage: lint
  script:
    - pip install pre-commit==$PRE_COMMIT_VERSION
    # hack to be able to use pre-commit without all the .git directory available in the docker
    # cf https://github.com/pre-commit/pre-commit/issues/1152
    - pre-commit install -t pre-commit
    - pre-commit run --all-files

test:
  extends: .docker-login
  stage: test
  script:
    - pip install -r requirements-dev.txt
    - pytest --cov=$PROJECT_NAME --cov-report=term-missing --junit-xml=test-results.xml -vv
      $PROJECT_NAME
    - coverage html --directory=coverage_html_report
    - coverage report --fail-under=1
  coverage: '/TOTAL.+ (\d+\.?\d+)%/'
  artifacts:
    name: "Test Results"
    when: always
    paths:
      - ./test-results.xml
      - ./coverage_html_report
    reports:
      junit: ./test-results.xml
    expire_in: 1 day

build_image:
  extends: .docker-login
  stage: build
  script:
    - apk add --no-cache make git
    - make build-ci
    - make push-ci

test_docs:
  extends: .docker-login
  stage: test
  script:
    - pip install -r requirements-dev.txt
    - git config --global --add safe.directory "$(dirname "$(pwd)")"
    - mkdocs build --verbose --site-dir docs_public
  artifacts:
    paths:
      - docs_public

pages:
  extends: .docker-login
  stage: deploy
  script:
    - pip install -r requirements-dev.txt
    - git config --global --add safe.directory "$(dirname "$(pwd)")"
    - mkdocs build --verbose
  artifacts:
    paths:
      - public
  only:
    - main

publish:
  extends: .docker-login
  stage: publish
  only:
    variables:
      - $PUBLISH == "true"
  script:
    - pip install python-semantic-release twine
    - rm -rf .git/hooks
    - git config --global user.email $GITLAB_USER_EMAIL
    - git config --global user.name "python-semantic-release"
    - git tag -d $(git tag -l)
    - semantic-release publish
    - python setup.py sdist bdist_wheel
    - TWINE_PASSWORD=${CI_JOB_TOKEN} TWINE_USERNAME=gitlab-ci-token python -m twine upload
      --repository-url ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi dist/*
